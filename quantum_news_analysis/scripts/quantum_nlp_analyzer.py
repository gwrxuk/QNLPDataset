#!/usr/bin/env python3
"""
é‡å­è‡ªç„¶èªè¨€è™•ç†åˆ†æå™¨
Quantum Natural Language Processing Analyzer

åŸºæ–¼IBM Qiskitå¯¦ç¾çœŸå¯¦çš„é‡å­è‡ªç„¶èªè¨€è™•ç†ï¼Œåˆ†æAIç”Ÿæˆæ–°èä¸­çš„ã€Œå¤šé‡ç¾å¯¦ã€ç¾è±¡ã€‚
Real quantum NLP implementation using IBM Qiskit to analyze "multiple realities" in AI-generated news.
"""

import pandas as pd
import numpy as np
from qiskit import QuantumCircuit, execute, Aer, IBMQ
from qiskit.quantum_info import entropy, Statevector, DensityMatrix
from qiskit.circuit.library import RYGate, CXGate, HGate
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import networkx as nx
from collections import Counter
import json
import time
from typing import List, Dict, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

class QuantumNewsAnalyzer:
    """é‡å­æ–°èåˆ†æå™¨ - å¯¦ç¾QNLPåˆ†æAIç”Ÿæˆæ–°èçš„å¤šé‡ç¾å¯¦ç¾è±¡"""
    
    def __init__(self, max_qubits: int = 8):
        """
        åˆå§‹åŒ–é‡å­åˆ†æå™¨
        
        Args:
            max_qubits: æœ€å¤§é‡å­æ¯”ç‰¹æ•¸
        """
        self.max_qubits = max_qubits
        self.backend = Aer.get_backend('statevector_simulator')
        self.qasm_backend = Aer.get_backend('qasm_simulator')
        
        # é‡å­åˆ†æçµæœå­˜å„²
        self.quantum_states = {}
        self.narrative_circuits = {}
        self.analysis_results = {}
        
        print(f"âœ… é‡å­åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ (æœ€å¤§ {max_qubits} é‡å­æ¯”ç‰¹)")
    
    def create_narrative_quantum_circuit(self, words: List[str], field_type: str) -> Tuple[QuantumCircuit, int]:
        """
        å‰µå»ºæ•˜äº‹é‡å­é›»è·¯ - å°‡æ–‡æœ¬ç·¨ç¢¼ç‚ºé‡å­æ…‹
        
        Args:
            words: åˆ†è©çµæœ
            field_type: æ¬„ä½é¡å‹ (æ–°èæ¨™é¡Œ/å½±ç‰‡å°è©±/å½±ç‰‡æè¿°)
            
        Returns:
            Tuple[QuantumCircuit, int]: é‡å­é›»è·¯å’Œé‡å­æ¯”ç‰¹æ•¸
        """
        if not words:
            return None, 0
        
        # é™åˆ¶é‡å­æ¯”ç‰¹æ•¸
        n_qubits = min(len(words), self.max_qubits)
        qc = QuantumCircuit(n_qubits, name=f"narrative_{field_type}")
        
        # 1. åˆå§‹åŒ–ç–ŠåŠ æ…‹ - æ¨¡æ“¬æ•˜äº‹çš„å¤šé‡å¯èƒ½æ€§
        for i in range(n_qubits):
            qc.h(i)
        
        # 2. åŸºæ–¼è©é »å’Œèªç¾©æ¬Šé‡çš„æ—‹è½‰ - ç·¨ç¢¼èªç¾©å¼·åº¦
        word_weights = self._calculate_semantic_weights(words[:n_qubits])
        
        for i, (word, weight) in enumerate(zip(words[:n_qubits], word_weights)):
            # ä½¿ç”¨TF-IDFæ¬Šé‡èª¿åˆ¶æ—‹è½‰è§’åº¦
            theta = weight * np.pi + np.pi/4
            phi = len(word) / 10 * np.pi  # è©é•·å½±éŸ¿ç›¸ä½
            
            qc.ry(theta, i)
            qc.rz(phi, i)
        
        # 3. å‰µå»ºèªç¾©ç³¾çº - æ¨¡æ“¬è©å½™é–“çš„èªç¾©é—œè¯
        self._create_semantic_entanglement(qc, n_qubits, words[:n_qubits])
        
        # 4. æ ¹æ“šæ¬„ä½é¡å‹æ·»åŠ ç‰¹å®šçš„é‡å­æ“ä½œ
        self._add_field_specific_operations(qc, n_qubits, field_type)
        
        return qc, n_qubits
    
    def _calculate_semantic_weights(self, words: List[str]) -> List[float]:
        """è¨ˆç®—èªç¾©æ¬Šé‡"""
        # ä½¿ç”¨è©é »å’Œè©é•·è¨ˆç®—æ¬Šé‡
        word_freq = Counter(words)
        max_freq = max(word_freq.values()) if word_freq else 1
        
        weights = []
        for word in words:
            # çµåˆé »ç‡å’Œé•·åº¦çš„æ¬Šé‡
            freq_weight = word_freq[word] / max_freq
            length_weight = min(len(word) / 10, 1.0)
            semantic_weight = (freq_weight + length_weight) / 2
            weights.append(semantic_weight)
        
        return weights
    
    def _create_semantic_entanglement(self, qc: QuantumCircuit, n_qubits: int, words: List[str]):
        """å‰µå»ºèªç¾©ç³¾çº - æ¨¡æ“¬è©å½™é–“çš„èªç¾©é—œè¯"""
        # åŸºæ–¼è©å½™ç›¸ä¼¼æ€§å‰µå»ºç³¾çº
        for i in range(n_qubits - 1):
            for j in range(i + 1, n_qubits):
                # è¨ˆç®—è©å½™ç›¸ä¼¼æ€§
                similarity = self._calculate_word_similarity(words[i], words[j])
                
                if similarity > 0.3:  # ç›¸ä¼¼æ€§é–¾å€¼
                    # å‰µå»ºå—æ§æ—‹è½‰ç³¾çº
                    angle = similarity * np.pi / 2
                    qc.cry(angle, i, j)
                    
                    # æ·»åŠ ç›¸ä½ç³¾çº
                    if similarity > 0.6:
                        qc.cz(i, j)
    
    def _calculate_word_similarity(self, word1: str, word2: str) -> float:
        """è¨ˆç®—è©å½™ç›¸ä¼¼æ€§"""
        # ç°¡å–®çš„å­—ç¬¦é‡ç–Šç›¸ä¼¼æ€§
        set1, set2 = set(word1), set(word2)
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        if union == 0:
            return 0
        
        return intersection / union
    
    def _add_field_specific_operations(self, qc: QuantumCircuit, n_qubits: int, field_type: str):
        """æ ¹æ“šæ¬„ä½é¡å‹æ·»åŠ ç‰¹å®šçš„é‡å­æ“ä½œ"""
        if field_type == "æ–°èæ¨™é¡Œ":
            # æ–°èæ¨™é¡Œé€šå¸¸ç°¡æ½”ï¼Œæ·»åŠ æ›´å¤šçš„ç›¸ä½æ“ä½œ
            for i in range(n_qubits):
                qc.s(i)  # Sé–€å¢åŠ ç›¸ä½
                
        elif field_type == "å½±ç‰‡å°è©±":
            # å°è©±å…·æœ‰äº’å‹•æ€§ï¼Œæ·»åŠ æ›´å¤šç³¾çº
            for i in range(0, n_qubits - 1, 2):
                if i + 1 < n_qubits:
                    qc.cx(i, i + 1)
                    
        elif field_type == "å½±ç‰‡æè¿°":
            # æè¿°æ€§æ–‡æœ¬ï¼Œæ·»åŠ Té–€å¢åŠ è¤‡é›œæ€§
            for i in range(n_qubits):
                qc.t(i)
    
    def measure_quantum_narrative_properties(self, qc: QuantumCircuit, n_qubits: int, 
                                           words: List[str], field_type: str) -> Dict:
        """
        æ¸¬é‡é‡å­æ•˜äº‹ç‰¹æ€§ - åˆ†ææ•˜äº‹çš„é‡å­ç‰¹å¾µ
        
        Args:
            qc: é‡å­é›»è·¯
            n_qubits: é‡å­æ¯”ç‰¹æ•¸
            words: è©å½™åˆ—è¡¨
            field_type: æ¬„ä½é¡å‹
            
        Returns:
            Dict: é‡å­ç‰¹æ€§æ¸¬é‡çµæœ
        """
        if qc is None or n_qubits == 0:
            return self._empty_quantum_result()
        
        try:
            # åŸ·è¡Œé‡å­æ¨¡æ“¬
            job = execute(qc, self.backend)
            result = job.result()
            statevector = result.get_statevector()
            
            # è¨ˆç®—é‡å­æŒ‡æ¨™
            quantum_metrics = self._calculate_quantum_metrics(statevector, n_qubits)
            
            # è¨ˆç®—æ•˜äº‹ç‰¹ç•°æ€§æŒ‡æ¨™
            narrative_metrics = self._calculate_narrative_metrics(statevector, words, field_type)
            
            # è¨ˆç®—æ¡†æ¶è¡çªæŒ‡æ¨™
            framing_metrics = self._calculate_framing_conflict_metrics(statevector, words)
            
            # ç¶œåˆçµæœ
            return {
                **quantum_metrics,
                **narrative_metrics,
                **framing_metrics,
                'circuit_depth': qc.depth(),
                'gate_count': len(qc.data),
                'field_type': field_type,
                'word_count': len(words),
                'qubit_count': n_qubits
            }
            
        except Exception as e:
            print(f"é‡å­æ¸¬é‡éŒ¯èª¤: {e}")
            return self._empty_quantum_result()
    
    def _calculate_quantum_metrics(self, statevector: Statevector, n_qubits: int) -> Dict:
        """è¨ˆç®—åŸºç¤é‡å­æŒ‡æ¨™"""
        # von Neumannç†µ - æ•˜äº‹è¤‡é›œåº¦
        vn_entropy = entropy(statevector)
        
        # é‡å­é€£è²«æ€§ - èªç¾©ä¸€è‡´æ€§
        amplitudes = np.abs(statevector.data)
        coherence = 1 - np.sum(amplitudes**4)  # åƒèˆ‡æ¯”
        
        # é‡å­ç³¾çºåº¦ - èªç¾©é—œè¯å¼·åº¦
        if n_qubits > 1:
            # è¨ˆç®—é›™åˆ†å‰²ç³¾çºç†µ
            mid = n_qubits // 2
            entanglement = self._calculate_bipartite_entanglement(statevector, mid, n_qubits - mid)
        else:
            entanglement = 0
        
        # é‡å­å¹²æ¶‰ - æ•˜äº‹ä¸€è‡´æ€§
        phases = np.angle(statevector.data)
        phase_variance = np.var(phases)
        interference = 1 - (phase_variance / (np.pi**2)) if phase_variance > 0 else 1
        
        # ç–ŠåŠ å¼·åº¦ - å¤šé‡ç¾å¯¦ç¨‹åº¦
        prob_dist = amplitudes**2
        superposition_strength = 1 - np.max(prob_dist)
        
        return {
            'von_neumann_entropy': float(vn_entropy),
            'quantum_coherence': float(coherence),
            'quantum_entanglement': float(entanglement),
            'quantum_interference': float(interference),
            'superposition_strength': float(superposition_strength)
        }
    
    def _calculate_bipartite_entanglement(self, statevector: Statevector, 
                                        subsystem_a_size: int, subsystem_b_size: int) -> float:
        """è¨ˆç®—é›™åˆ†å‰²ç³¾çºåº¦"""
        try:
            # å‰µå»ºå¯†åº¦çŸ©é™£
            rho = DensityMatrix(statevector)
            
            # è¨ˆç®—ç´„åŒ–å¯†åº¦çŸ©é™£çš„ç†µ
            subsystem_indices = list(range(subsystem_a_size))
            rho_a = rho.partial_trace(subsystem_indices)
            
            # è¨ˆç®—ç³¾çºç†µ
            entanglement_entropy = entropy(rho_a)
            
            return float(entanglement_entropy)
            
        except:
            return 0.0
    
    def _calculate_narrative_metrics(self, statevector: Statevector, 
                                   words: List[str], field_type: str) -> Dict:
        """è¨ˆç®—æ•˜äº‹ç‰¹ç•°æ€§æŒ‡æ¨™"""
        # æ•˜äº‹åˆ†æ­§åº¦ - åŸºæ–¼ç‹€æ…‹åˆ†å¸ƒçš„åˆ†æ•£ç¨‹åº¦
        amplitudes = np.abs(statevector.data)
        prob_dist = amplitudes**2
        narrative_divergence = -np.sum(prob_dist * np.log2(prob_dist + 1e-10))
        
        # èªç¾©å¯†åº¦ - è©å½™èªç¾©ä¿¡æ¯å¯†åº¦
        unique_words = len(set(words))
        total_words = len(words)
        semantic_density = unique_words / total_words if total_words > 0 else 0
        
        # æ¡†æ¶ç©©å®šæ€§ - åŸºæ–¼ç›¸ä½ä¸€è‡´æ€§
        phases = np.angle(statevector.data)
        phase_coherence = 1 - np.std(phases) / np.pi
        
        # æ•˜äº‹å¼µåŠ› - åŸºæ–¼å¹…åº¦æ–¹å·®
        amplitude_tension = np.var(amplitudes)
        
        return {
            'narrative_divergence': float(narrative_divergence),
            'semantic_density': float(semantic_density),
            'frame_stability': float(phase_coherence),
            'narrative_tension': float(amplitude_tension)
        }
    
    def _calculate_framing_conflict_metrics(self, statevector: Statevector, words: List[str]) -> Dict:
        """è¨ˆç®—æ¡†æ¶è¡çªæŒ‡æ¨™"""
        amplitudes = np.abs(statevector.data)
        
        # æ¡†æ¶ç«¶çˆ­åº¦ - åŸºæ–¼ç‹€æ…‹ç«¶çˆ­
        prob_dist = amplitudes**2
        max_prob = np.max(prob_dist)
        frame_competition = 1 - max_prob
        
        # æ„ç¾©è¡çªåº¦ - åŸºæ–¼å¹…åº¦åˆ†å¸ƒçš„ä¸å‡å‹»æ€§
        gini_coefficient = self._calculate_gini_coefficient(prob_dist)
        meaning_conflict = 1 - gini_coefficient
        
        # èªç¾©æ¨¡ç³Šåº¦ - åŸºæ–¼è©å½™å¤šæ¨£æ€§å’Œé‡å­ä¸ç¢ºå®šæ€§
        word_diversity = len(set(words)) / len(words) if words else 0
        quantum_uncertainty = entropy(statevector)
        semantic_ambiguity = (word_diversity + quantum_uncertainty / np.log(len(amplitudes))) / 2
        
        return {
            'frame_competition': float(frame_competition),
            'meaning_conflict': float(meaning_conflict),
            'semantic_ambiguity': float(semantic_ambiguity)
        }
    
    def _calculate_gini_coefficient(self, prob_dist: np.ndarray) -> float:
        """è¨ˆç®—åŸºå°¼ä¿‚æ•¸"""
        sorted_probs = np.sort(prob_dist)
        n = len(sorted_probs)
        
        if n == 0:
            return 0
        
        cumsum = np.cumsum(sorted_probs)
        return (n + 1 - 2 * np.sum(cumsum) / cumsum[-1]) / n
    
    def _empty_quantum_result(self) -> Dict:
        """è¿”å›ç©ºçš„é‡å­çµæœ"""
        return {
            'von_neumann_entropy': 0,
            'quantum_coherence': 0,
            'quantum_entanglement': 0,
            'quantum_interference': 0,
            'superposition_strength': 0,
            'narrative_divergence': 0,
            'semantic_density': 0,
            'frame_stability': 0,
            'narrative_tension': 0,
            'frame_competition': 0,
            'meaning_conflict': 0,
            'semantic_ambiguity': 0,
            'circuit_depth': 0,
            'gate_count': 0,
            'field_type': '',
            'word_count': 0,
            'qubit_count': 0
        }
    
    def analyze_news_dataset(self, segmentation_results: pd.DataFrame) -> Dict:
        """
        åˆ†ææ•´å€‹æ–°èæ•¸æ“šé›†çš„é‡å­ç‰¹æ€§
        
        Args:
            segmentation_results: æ–·è©çµæœæ•¸æ“šæ¡†
            
        Returns:
            Dict: å®Œæ•´çš„é‡å­åˆ†æçµæœ
        """
        print("ğŸ”¬ é–‹å§‹é‡å­è‡ªç„¶èªè¨€è™•ç†åˆ†æ")
        print("=" * 60)
        
        start_time = time.time()
        
        # æŒ‰æ¬„ä½åˆ†çµ„åˆ†æ
        field_results = {}
        all_quantum_results = []
        
        for field_type in segmentation_results['field'].unique():
            print(f"\nğŸ“Š åˆ†æ {field_type} æ¬„ä½çš„é‡å­ç‰¹æ€§...")
            
            field_data = segmentation_results[segmentation_results['field'] == field_type]
            field_quantum_results = []
            
            for idx, row in field_data.iterrows():
                if pd.notna(row['words_list']) and row['words_list'].strip():
                    # è§£æè©å½™
                    words = [w.strip() for w in str(row['words_list']).split(',') if w.strip()]
                    
                    if words:
                        # å‰µå»ºé‡å­é›»è·¯
                        qc, n_qubits = self.create_narrative_quantum_circuit(words, field_type)
                        
                        if qc is not None:
                            # æ¸¬é‡é‡å­ç‰¹æ€§
                            quantum_props = self.measure_quantum_narrative_properties(
                                qc, n_qubits, words, field_type
                            )
                            
                            # æ·»åŠ è¨˜éŒ„ä¿¡æ¯
                            quantum_result = {
                                'record_id': row['record_id'],
                                'field': field_type,
                                'original_text': row['original_text'][:100] + '...' if len(row['original_text']) > 100 else row['original_text'],
                                **quantum_props
                            }
                            
                            field_quantum_results.append(quantum_result)
                            all_quantum_results.append(quantum_result)
                
                # é¡¯ç¤ºé€²åº¦
                if (len(field_quantum_results) + 1) % 50 == 0:
                    print(f"  è™•ç†é€²åº¦: {len(field_quantum_results)}/{len(field_data)}")
            
            # è¨ˆç®—æ¬„ä½çµ±è¨ˆ
            if field_quantum_results:
                field_stats = self._calculate_field_quantum_statistics(field_quantum_results, field_type)
                field_results[field_type] = {
                    'statistics': field_stats,
                    'sample_count': len(field_quantum_results),
                    'individual_results': field_quantum_results
                }
                
                print(f"âœ… {field_type} é‡å­åˆ†æå®Œæˆ: {len(field_quantum_results)} ç­†è¨˜éŒ„")
                self._print_field_quantum_summary(field_stats, field_type)
        
        # è¨ˆç®—è·¨æ¬„ä½æ¯”è¼ƒ
        cross_field_analysis = self._calculate_cross_field_analysis(field_results)
        
        # ç”Ÿæˆå¤šé‡ç¾å¯¦åˆ†æ
        multiple_reality_analysis = self._analyze_multiple_realities(all_quantum_results)
        
        # ç¶œåˆçµæœ
        complete_analysis = {
            'analysis_timestamp': pd.Timestamp.now().isoformat(),
            'processing_time_seconds': time.time() - start_time,
            'total_records_analyzed': len(all_quantum_results),
            'field_results': field_results,
            'cross_field_analysis': cross_field_analysis,
            'multiple_reality_analysis': multiple_reality_analysis,
            'quantum_framework': 'IBM Qiskit',
            'max_qubits_used': self.max_qubits
        }
        
        print(f"\nğŸ‰ é‡å­è‡ªç„¶èªè¨€è™•ç†åˆ†æå®Œæˆ!")
        print(f"â±ï¸  ç¸½è™•ç†æ™‚é–“: {time.time() - start_time:.1f} ç§’")
        print(f"ğŸ“Š åˆ†æè¨˜éŒ„æ•¸: {len(all_quantum_results)}")
        
        return complete_analysis
    
    def _calculate_field_quantum_statistics(self, field_results: List[Dict], field_type: str) -> Dict:
        """è¨ˆç®—æ¬„ä½é‡å­çµ±è¨ˆ"""
        if not field_results:
            return {}
        
        # æå–å„é …æŒ‡æ¨™
        metrics = [
            'von_neumann_entropy', 'quantum_coherence', 'quantum_entanglement',
            'quantum_interference', 'superposition_strength', 'narrative_divergence',
            'semantic_density', 'frame_stability', 'narrative_tension',
            'frame_competition', 'meaning_conflict', 'semantic_ambiguity'
        ]
        
        stats = {}
        for metric in metrics:
            values = [r[metric] for r in field_results if metric in r]
            if values:
                stats[f'avg_{metric}'] = np.mean(values)
                stats[f'std_{metric}'] = np.std(values)
                stats[f'min_{metric}'] = np.min(values)
                stats[f'max_{metric}'] = np.max(values)
        
        # ç‰¹æ®Šçµ±è¨ˆ
        stats['avg_circuit_depth'] = np.mean([r['circuit_depth'] for r in field_results])
        stats['avg_gate_count'] = np.mean([r['gate_count'] for r in field_results])
        stats['avg_qubit_count'] = np.mean([r['qubit_count'] for r in field_results])
        
        return stats
    
    def _print_field_quantum_summary(self, stats: Dict, field_type: str):
        """æ‰“å°æ¬„ä½é‡å­æ‘˜è¦"""
        print(f"  ğŸ“ˆ {field_type} é‡å­æŒ‡æ¨™æ‘˜è¦:")
        print(f"    æ•˜äº‹è¤‡é›œåº¦ (von Neumannç†µ): {stats.get('avg_von_neumann_entropy', 0):.4f}")
        print(f"    èªç¾©ä¸€è‡´æ€§ (é‡å­é€£è²«æ€§): {stats.get('avg_quantum_coherence', 0):.4f}")
        print(f"    å¤šé‡ç¾å¯¦ç¨‹åº¦ (ç–ŠåŠ å¼·åº¦): {stats.get('avg_superposition_strength', 0):.4f}")
        print(f"    æ¡†æ¶ç«¶çˆ­åº¦: {stats.get('avg_frame_competition', 0):.4f}")
        print(f"    èªç¾©æ¨¡ç³Šåº¦: {stats.get('avg_semantic_ambiguity', 0):.4f}")
    
    def _calculate_cross_field_analysis(self, field_results: Dict) -> Dict:
        """è¨ˆç®—è·¨æ¬„ä½åˆ†æ"""
        cross_analysis = {}
        
        fields = list(field_results.keys())
        
        # æ¬„ä½é–“æ¯”è¼ƒ
        for i, field1 in enumerate(fields):
            for j, field2 in enumerate(fields[i+1:], i+1):
                stats1 = field_results[field1]['statistics']
                stats2 = field_results[field2]['statistics']
                
                comparison_key = f"{field1}_vs_{field2}"
                cross_analysis[comparison_key] = {}
                
                # æ¯”è¼ƒä¸»è¦æŒ‡æ¨™
                key_metrics = [
                    'avg_von_neumann_entropy', 'avg_quantum_coherence', 
                    'avg_superposition_strength', 'avg_frame_competition'
                ]
                
                for metric in key_metrics:
                    if metric in stats1 and metric in stats2:
                        diff = stats2[metric] - stats1[metric]
                        cross_analysis[comparison_key][f'{metric}_difference'] = diff
        
        return cross_analysis
    
    def _analyze_multiple_realities(self, all_results: List[Dict]) -> Dict:
        """åˆ†æå¤šé‡ç¾å¯¦ç¾è±¡"""
        if not all_results:
            return {}
        
        # é«˜ç–ŠåŠ å¼·åº¦è¨˜éŒ„ - å¤šé‡ç¾å¯¦ç¾è±¡æ˜é¡¯
        high_superposition = [r for r in all_results if r['superposition_strength'] > 0.5]
        
        # é«˜æ¡†æ¶ç«¶çˆ­è¨˜éŒ„ - æ¡†æ¶è¡çªæ˜é¡¯
        high_frame_competition = [r for r in all_results if r['frame_competition'] > 0.6]
        
        # é«˜èªç¾©æ¨¡ç³Šè¨˜éŒ„ - æ„ç¾©ä¸ç¢ºå®šæ€§é«˜
        high_ambiguity = [r for r in all_results if r['semantic_ambiguity'] > 0.7]
        
        # è¨ˆç®—å¤šé‡ç¾å¯¦æŒ‡æ¨™
        avg_superposition = np.mean([r['superposition_strength'] for r in all_results])
        avg_frame_competition = np.mean([r['frame_competition'] for r in all_results])
        avg_meaning_conflict = np.mean([r['meaning_conflict'] for r in all_results])
        
        return {
            'multiple_reality_prevalence': len(high_superposition) / len(all_results),
            'frame_conflict_prevalence': len(high_frame_competition) / len(all_results),
            'semantic_ambiguity_prevalence': len(high_ambiguity) / len(all_results),
            'avg_multiple_reality_strength': avg_superposition,
            'avg_frame_competition_strength': avg_frame_competition,
            'avg_meaning_conflict_strength': avg_meaning_conflict,
            'high_superposition_examples': len(high_superposition),
            'high_frame_competition_examples': len(high_frame_competition),
            'high_ambiguity_examples': len(high_ambiguity)
        }

def main():
    """ä¸»å‡½æ•¸ - åŸ·è¡Œé‡å­æ–°èåˆ†æ"""
    print("ğŸš€ é‡å­è‡ªç„¶èªè¨€è™•ç† - å¤šé‡ç¾å¯¦åˆ†æ")
    print("=" * 60)
    
    try:
        # è®€å–æ–·è©çµæœ
        print("ğŸ“Š è®€å–æ–·è©åˆ†æçµæœ...")
        segmentation_df = pd.read_csv('../results/complete_segmentation_results.csv')
        print(f"æ–·è©çµæœ: {len(segmentation_df)} ç­†è¨˜éŒ„")
        
        # åˆå§‹åŒ–é‡å­åˆ†æå™¨
        analyzer = QuantumNewsAnalyzer(max_qubits=8)
        
        # åŸ·è¡Œé‡å­åˆ†æ
        quantum_results = analyzer.analyze_news_dataset(segmentation_df)
        
        # ä¿å­˜å®Œæ•´çµæœ
        with open('../results/quantum_analysis_results.json', 'w', encoding='utf-8') as f:
            json.dump(quantum_results, f, ensure_ascii=False, indent=2, default=str)
        
        # ä¿å­˜ç°¡åŒ–çš„CSVçµæœ
        all_individual_results = []
        for field_data in quantum_results['field_results'].values():
            all_individual_results.extend(field_data['individual_results'])
        
        if all_individual_results:
            results_df = pd.DataFrame(all_individual_results)
            results_df.to_csv('../results/quantum_analysis_detailed.csv', 
                            index=False, encoding='utf-8-sig')
        
        print(f"\nğŸ’¾ é‡å­åˆ†æçµæœå·²ä¿å­˜:")
        print(f"  å®Œæ•´çµæœ: ../results/quantum_analysis_results.json")
        print(f"  è©³ç´°æ•¸æ“š: ../results/quantum_analysis_detailed.csv")
        
        # é¡¯ç¤ºé—œéµç™¼ç¾
        print(f"\nğŸ” é—œéµç™¼ç¾:")
        mra = quantum_results['multiple_reality_analysis']
        print(f"  å¤šé‡ç¾å¯¦ç¾è±¡æ™®åŠåº¦: {mra['multiple_reality_prevalence']:.1%}")
        print(f"  æ¡†æ¶è¡çªæ™®åŠåº¦: {mra['frame_conflict_prevalence']:.1%}")
        print(f"  èªç¾©æ¨¡ç³Šæ™®åŠåº¦: {mra['semantic_ambiguity_prevalence']:.1%}")
        
        print(f"\nâœ… é‡å­è‡ªç„¶èªè¨€è™•ç†åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

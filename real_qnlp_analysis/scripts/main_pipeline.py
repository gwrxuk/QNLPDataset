#!/usr/bin/env python3
"""
ä¸»è¦åˆ†ææµç¨‹ç®¡é“
Main Analysis Pipeline for Real QNLP Analysis
"""

import os
import sys
import subprocess
import time
from pathlib import Path
import pandas as pd

class QNLPAnalysisPipeline:
    """QNLPåˆ†ææµç¨‹ç®¡é“"""
    
    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.scripts_dir = self.base_dir / "scripts"
        self.data_dir = self.base_dir / "data"
        self.results_dir = self.base_dir / "results"
        self.viz_dir = self.base_dir / "visualizations"
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        for dir_path in [self.data_dir, self.results_dir, self.viz_dir]:
            dir_path.mkdir(exist_ok=True)
    
    def check_prerequisites(self) -> bool:
        """æª¢æŸ¥å…ˆæ±ºæ¢ä»¶"""
        print("ğŸ” æª¢æŸ¥åˆ†æå…ˆæ±ºæ¢ä»¶...")
        
        # æª¢æŸ¥APIå¯†é‘°
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            print("âŒ è«‹è¨­å®šOPENAI_API_KEYç’°å¢ƒè®Šæ•¸")
            return False
        print(f"âœ… OpenAI APIå¯†é‘°å·²è¨­å®š: {api_key[:10]}...")
        
        # æª¢æŸ¥æ•¸æ“šæª”æ¡ˆ
        dataset_path = self.base_dir.parent / "dataseet.xlsx"
        if not dataset_path.exists():
            print(f"âŒ æœªæ‰¾åˆ°æ•¸æ“šæª”æ¡ˆ: {dataset_path}")
            return False
        print(f"âœ… æ•¸æ“šæª”æ¡ˆå­˜åœ¨: {dataset_path}")
        
        # æª¢æŸ¥jiebaçµæœ
        jieba_results_path = self.base_dir.parent / "jieba_segmentation_results.csv"
        if not jieba_results_path.exists():
            print(f"âŒ æœªæ‰¾åˆ°jiebaæ–·è©çµæœ: {jieba_results_path}")
            print("è«‹å…ˆé‹è¡Œjiebaæ–·è©åˆ†æ")
            return False
        print(f"âœ… jiebaçµæœå­˜åœ¨: {jieba_results_path}")
        
        return True
    
    def copy_existing_data(self):
        """è¤‡è£½ç¾æœ‰æ•¸æ“šåˆ°åˆ†æç›®éŒ„"""
        print("ğŸ“‹ è¤‡è£½ç¾æœ‰æ•¸æ“š...")
        
        # è¤‡è£½æ•¸æ“šæª”æ¡ˆ
        source_dataset = self.base_dir.parent / "dataseet.xlsx"
        target_dataset = self.data_dir / "dataseet.xlsx"
        
        if source_dataset.exists():
            import shutil
            shutil.copy2(source_dataset, target_dataset)
            print(f"âœ… è¤‡è£½æ•¸æ“šé›†: {target_dataset}")
        
        # è¤‡è£½jiebaçµæœ
        jieba_files = [
            "jieba_segmentation_results.csv",
            "jieba_vocabulary_stats.csv", 
            "jieba_field_vocabulary.csv",
            "jieba_summary_stats.csv"
        ]
        
        for filename in jieba_files:
            source_file = self.base_dir.parent / filename
            target_file = self.data_dir / filename
            
            if source_file.exists():
                import shutil
                shutil.copy2(source_file, target_file)
                print(f"âœ… è¤‡è£½jiebaçµæœ: {filename}")
    
    def run_chatgpt_segmentation(self, max_records: int = None) -> bool:
        """é‹è¡ŒChatGPTæ–·è©åˆ†æ"""
        print("\nğŸ¤– é‹è¡ŒChatGPTæ–·è©åˆ†æ...")
        
        script_path = self.scripts_dir / "real_chatgpt_segmentation.py"
        
        try:
            # åˆ‡æ›åˆ°è…³æœ¬ç›®éŒ„
            original_dir = os.getcwd()
            os.chdir(self.scripts_dir)
            
            # é‹è¡Œè…³æœ¬
            if max_records:
                # æ¨¡æ“¬ç”¨æˆ¶è¼¸å…¥é™åˆ¶è¨˜éŒ„æ•¸
                process = subprocess.Popen(
                    [sys.executable, str(script_path)],
                    stdin=subprocess.PIPE,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True
                )
                stdout, stderr = process.communicate(input=str(max_records))
            else:
                # é‹è¡Œå…¨éƒ¨è¨˜éŒ„
                process = subprocess.Popen(
                    [sys.executable, str(script_path)],
                    stdin=subprocess.PIPE,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True
                )
                stdout, stderr = process.communicate(input="\\n")  # æŒ‰Enterä½¿ç”¨é»˜èªè¨­å®š
            
            os.chdir(original_dir)
            
            if process.returncode == 0:
                print("âœ… ChatGPTæ–·è©åˆ†æå®Œæˆ")
                print(stdout)
                return True
            else:
                print(f"âŒ ChatGPTæ–·è©åˆ†æå¤±æ•—: {stderr}")
                return False
                
        except Exception as e:
            os.chdir(original_dir)
            print(f"âŒ é‹è¡ŒChatGPTåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def run_qnlp_analysis(self) -> bool:
        """é‹è¡ŒQNLPæ¯”è¼ƒåˆ†æ"""
        print("\nğŸ”¬ é‹è¡ŒQNLPæ¯”è¼ƒåˆ†æ...")
        
        script_path = self.scripts_dir / "enhanced_qnlp_analyzer.py"
        
        try:
            original_dir = os.getcwd()
            os.chdir(self.scripts_dir)
            
            result = subprocess.run(
                [sys.executable, str(script_path)],
                capture_output=True,
                text=True
            )
            
            os.chdir(original_dir)
            
            if result.returncode == 0:
                print("âœ… QNLPåˆ†æå®Œæˆ")
                print(result.stdout)
                return True
            else:
                print(f"âŒ QNLPåˆ†æå¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            os.chdir(original_dir)
            print(f"âŒ é‹è¡ŒQNLPåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def run_visualization(self) -> bool:
        """é‹è¡Œè¦–è¦ºåŒ–åˆ†æ"""
        print("\nğŸ¨ é‹è¡Œè¦–è¦ºåŒ–åˆ†æ...")
        
        script_path = self.scripts_dir / "comprehensive_visualizer.py"
        
        try:
            original_dir = os.getcwd()
            os.chdir(self.scripts_dir)
            
            result = subprocess.run(
                [sys.executable, str(script_path)],
                capture_output=True,
                text=True
            )
            
            os.chdir(original_dir)
            
            if result.returncode == 0:
                print("âœ… è¦–è¦ºåŒ–åˆ†æå®Œæˆ")
                print(result.stdout)
                return True
            else:
                print(f"âŒ è¦–è¦ºåŒ–åˆ†æå¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            os.chdir(original_dir)
            print(f"âŒ é‹è¡Œè¦–è¦ºåŒ–åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def generate_final_report(self):
        """ç”Ÿæˆæœ€çµ‚å ±å‘Š"""
        print("\nğŸ“„ ç”Ÿæˆæœ€çµ‚å ±å‘Š...")
        
        report_content = f"""# çœŸå¯¦QNLPåˆ†æå ±å‘Š
# Real QNLP Analysis Report

## åˆ†ææ¦‚è¿°
æœ¬å ±å‘ŠåŸºæ–¼jiebaå’ŒChatGPTå…©ç¨®ä¸­æ–‡æ–·è©æ–¹æ³•ï¼Œé€²è¡Œé‡å­è‡ªç„¶èªè¨€è™•ç†(QNLP)æ¯”è¼ƒåˆ†æã€‚

## åˆ†ææ™‚é–“
{time.strftime('%Y-%m-%d %H:%M:%S')}

## ç›®éŒ„çµæ§‹
```
real_qnlp_analysis/
â”œâ”€â”€ data/                    # æ•¸æ“šæª”æ¡ˆ
â”‚   â”œâ”€â”€ dataseet.xlsx       # åŸå§‹æ•¸æ“š
â”‚   â”œâ”€â”€ jieba_*.csv         # jiebaæ–·è©çµæœ
â”‚   â””â”€â”€ real_chatgpt_*.csv  # ChatGPTæ–·è©çµæœ
â”œâ”€â”€ results/                # åˆ†æçµæœ
â”‚   â”œâ”€â”€ qnlp_comparative_analysis.json
â”‚   â””â”€â”€ statistical_summary.json
â”œâ”€â”€ visualizations/         # è¦–è¦ºåŒ–åœ–è¡¨
â”‚   â”œâ”€â”€ quantum_metrics_comparison.png
â”‚   â”œâ”€â”€ word_count_analysis.png
â”‚   â”œâ”€â”€ radar_chart_comparison.png
â”‚   â””â”€â”€ insights_summary.png
â””â”€â”€ scripts/               # åˆ†æè…³æœ¬
    â”œâ”€â”€ real_chatgpt_segmentation.py
    â”œâ”€â”€ enhanced_qnlp_analyzer.py
    â”œâ”€â”€ comprehensive_visualizer.py
    â””â”€â”€ main_pipeline.py
```

## ä¸»è¦ç™¼ç¾
è©³ç´°çš„åˆ†æçµæœè«‹æŸ¥çœ‹ï¼š
- `results/qnlp_comparative_analysis.json` - å®Œæ•´åˆ†æçµæœ
- `results/statistical_summary.json` - çµ±è¨ˆæ‘˜è¦
- `visualizations/` ç›®éŒ„ä¸‹çš„å„ç¨®åœ–è¡¨

## ä½¿ç”¨æ–¹æ³•
1. è¨­å®šOpenAI APIå¯†é‘°: `export OPENAI_API_KEY="your-key"`
2. é‹è¡Œå®Œæ•´åˆ†æ: `python scripts/main_pipeline.py`
3. æŸ¥çœ‹çµæœå’Œåœ–è¡¨

## æ³¨æ„äº‹é …
- ChatGPTåˆ†æéœ€è¦æ¶ˆè€—API tokensï¼Œè«‹æ³¨æ„æˆæœ¬
- åˆ†æçµæœåŸºæ–¼é‡å­è¨ˆç®—åŸç†ï¼Œå…·æœ‰ç†è«–æ¢ç´¢æ€§è³ª
- å»ºè­°åœ¨ç†è§£é‡å­èªè¨€å­¸ç†è«–çš„åŸºç¤ä¸Šè§£è®€çµæœ

---
ç”Ÿæˆæ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        report_path = self.base_dir / "README.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… æœ€çµ‚å ±å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    def run_full_pipeline(self, max_records: int = None):
        """é‹è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸš€ é–‹å§‹çœŸå¯¦QNLPåˆ†æå®Œæ•´æµç¨‹")
        print("=" * 50)
        
        # æª¢æŸ¥å…ˆæ±ºæ¢ä»¶
        if not self.check_prerequisites():
            print("âŒ å…ˆæ±ºæ¢ä»¶æª¢æŸ¥å¤±æ•—ï¼Œåˆ†æçµ‚æ­¢")
            return False
        
        # è¤‡è£½ç¾æœ‰æ•¸æ“š
        self.copy_existing_data()
        
        # è©¢å•åˆ†æç¯„åœ
        if max_records is None:
            print(f"\\nâš™ï¸  åˆ†æè¨­å®š:")
            user_input = input("æ¯å€‹æ¬„ä½åˆ†æå¤šå°‘ç­†è¨˜éŒ„ï¼Ÿ(Enter=å…¨éƒ¨, æ•¸å­—=é™åˆ¶ç­†æ•¸): ").strip()
            if user_input.isdigit():
                max_records = int(user_input)
                print(f"ğŸ“ å°‡åˆ†ææ¯å€‹æ¬„ä½çš„å‰ {max_records} ç­†è¨˜éŒ„")
            else:
                print("ğŸ“ å°‡åˆ†æå…¨éƒ¨è¨˜éŒ„")
        
        # ä¼°ç®—æˆæœ¬
        if max_records:
            estimated_records = max_records * 3  # 3å€‹æ¬„ä½
        else:
            # è®€å–æ•¸æ“šä¼°ç®—
            try:
                df = pd.read_excel(self.data_dir / "dataseet.xlsx")
                estimated_records = len(df) * 3
            except:
                estimated_records = 299 * 3  # é è¨­å€¼
        
        estimated_cost = (estimated_records * 400 / 1000) * 0.002  # ä¼°ç®—tokenså’Œæˆæœ¬
        print(f"\\nğŸ’° ä¼°ç®—æˆæœ¬: ${estimated_cost:.3f} ({estimated_records} ç­†è¨˜éŒ„)")
        
        confirm = input("ç¢ºèªç¹¼çºŒï¼Ÿ(y/N): ").strip().lower()
        if confirm not in ['y', 'yes']:
            print("âŒ ç”¨æˆ¶å–æ¶ˆåˆ†æ")
            return False
        
        # é–‹å§‹åˆ†ææµç¨‹
        start_time = time.time()
        
        # 1. ChatGPTæ–·è©åˆ†æ
        if not self.run_chatgpt_segmentation(max_records):
            print("âŒ ChatGPTåˆ†æå¤±æ•—ï¼Œæµç¨‹çµ‚æ­¢")
            return False
        
        # 2. QNLPæ¯”è¼ƒåˆ†æ
        if not self.run_qnlp_analysis():
            print("âŒ QNLPåˆ†æå¤±æ•—ï¼Œæµç¨‹çµ‚æ­¢")
            return False
        
        # 3. è¦–è¦ºåŒ–åˆ†æ
        if not self.run_visualization():
            print("âš ï¸  è¦–è¦ºåŒ–åˆ†æå¤±æ•—ï¼Œä½†ç¹¼çºŒæµç¨‹")
        
        # 4. ç”Ÿæˆæœ€çµ‚å ±å‘Š
        self.generate_final_report()
        
        # åˆ†æå®Œæˆ
        elapsed_time = time.time() - start_time
        print(f"\\nğŸ‰ å®Œæ•´QNLPåˆ†ææµç¨‹å®Œæˆï¼")
        print(f"â±ï¸  ç¸½è€—æ™‚: {elapsed_time/60:.1f} åˆ†é˜")
        print(f"ğŸ“ çµæœç›®éŒ„: {self.base_dir}")
        print(f"\\nğŸ“Š ä¸»è¦è¼¸å‡ºæª”æ¡ˆ:")
        print(f"  - data/real_chatgpt_segmentation_complete.csv")
        print(f"  - results/qnlp_comparative_analysis.json")
        print(f"  - visualizations/*.png")
        print(f"  - README.md")
        
        return True

def main():
    """ä¸»å‡½æ•¸"""
    pipeline = QNLPAnalysisPipeline()
    
    if len(sys.argv) > 1:
        try:
            max_records = int(sys.argv[1])
            pipeline.run_full_pipeline(max_records)
        except ValueError:
            print("âŒ è«‹æä¾›æœ‰æ•ˆçš„è¨˜éŒ„æ•¸é‡")
    else:
        pipeline.run_full_pipeline()

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
AI vs è¨˜è€…æ–°èé‡å­ç‰¹å¾µæ¯”è¼ƒå¯è¦–åŒ– - ä¿®å¾©ä¸­æ–‡é¡¯ç¤ºç‰ˆæœ¬
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import matplotlib.font_manager as fm
import warnings
warnings.filterwarnings('ignore')

def setup_chinese_fonts():
    """è¨­ç½®ä¸­æ–‡å­—é«”"""
    print("ğŸ”§ è¨­ç½®ä¸­æ–‡å­—é«”...")
    
    # ç²å–ç³»çµ±æ‰€æœ‰å­—é«”
    font_list = [f.name for f in fm.fontManager.ttflist]
    
    # macOS å¸¸è¦‹ä¸­æ–‡å­—é«”
    mac_fonts = ['Arial Unicode MS', 'PingFang SC', 'Helvetica Neue', 'STHeiti', 'STSong']
    # Windows å¸¸è¦‹ä¸­æ–‡å­—é«”  
    win_fonts = ['Microsoft YaHei', 'SimHei', 'SimSun', 'KaiTi']
    # Linux å¸¸è¦‹ä¸­æ–‡å­—é«”
    linux_fonts = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'Source Han Sans SC']
    
    all_chinese_fonts = mac_fonts + win_fonts + linux_fonts
    
    # æ‰¾åˆ°å¯ç”¨çš„ä¸­æ–‡å­—é«”
    available_chinese = [font for font in all_chinese_fonts if font in font_list]
    
    if available_chinese:
        selected_font = available_chinese[0]
        plt.rcParams['font.sans-serif'] = [selected_font]
        plt.rcParams['axes.unicode_minus'] = False
        print(f"âœ… ä½¿ç”¨ä¸­æ–‡å­—é«”: {selected_font}")
        return selected_font
    else:
        # å¦‚æœæ²’æœ‰ä¸­æ–‡å­—é«”ï¼Œä½¿ç”¨è‹±æ–‡æ›¿ä»£
        print("âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œä½¿ç”¨è‹±æ–‡æ¨™ç±¤")
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        return None

def get_labels(has_chinese_font):
    """æ ¹æ“šå­—é«”æ”¯æ´æƒ…æ³è¿”å›æ¨™ç±¤"""
    if has_chinese_font:
        return {
            'metrics': ['èªæ³•ç–ŠåŠ å¼·åº¦', 'æ¡†æ¶ç«¶çˆ­å¼·åº¦', 'å¤šé‡ç¾å¯¦å¼·åº¦', 'æ¡†æ¶è¡çªå¼·åº¦', 'èªç¾©å¹²æ¶‰', 'é¦®ç´æ›¼ç†µ'],
            'categories': ['æ–°èæ¨™é¡Œ', 'å…§å®¹/å°è©±'],
            'ai_label': 'AIæ–°è',
            'journalist_label': 'è¨˜è€…æ–°è',
            'titles': {
                'radar': 'æ–°èæ¨™é¡Œé‡å­ç‰¹å¾µé›·é”åœ–',
                'interference': 'èªç¾©å¹²æ¶‰å¼·åº¦å°æ¯”ï¼ˆå·®ç•°é”386å€ï¼‰',
                'competition_conflict': 'æ¡†æ¶ç«¶çˆ­ vs æ¡†æ¶è¡çªæ¨¡å¼', 
                'reality': 'å¤šé‡ç¾å¯¦å¼·åº¦åˆ†ä½ˆå°æ¯”',
                'entropy': 'è³‡è¨Šå¯†åº¦å°æ¯”ï¼ˆé¦®ç´æ›¼ç†µï¼‰',
                'fingerprint': 'é‡å­ç‰¹å¾µæŒ‡ç´‹å°æ¯”',
                'main': 'AIç”Ÿæˆæ–°è vs è¨˜è€…æ’°å¯«æ–°èï¼šé‡å­ç‰¹å¾µå…¨é¢å°æ¯”'
            }
        }
    else:
        return {
            'metrics': ['Grammar Superposition', 'Frame Competition', 'Multiple Reality', 'Frame Conflict', 'Semantic Interference', 'Von Neumann Entropy'],
            'categories': ['News Title', 'Content/Dialog'],
            'ai_label': 'AI News',
            'journalist_label': 'Journalist News', 
            'titles': {
                'radar': 'News Title Quantum Features Radar Chart',
                'interference': 'Semantic Interference Comparison (386x Difference)',
                'competition_conflict': 'Frame Competition vs Frame Conflict Pattern',
                'reality': 'Multiple Reality Strength Distribution',
                'entropy': 'Information Density Comparison (Von Neumann Entropy)',
                'fingerprint': 'Quantum Feature Fingerprint Comparison',
                'main': 'AI Generated News vs Journalist Written News: Quantum Features Comparison'
            }
        }

def load_comparison_data():
    """è¼‰å…¥æ¯”è¼ƒæ•¸æ“š"""
    
    # AIæ–°èæ•¸æ“š
    with open('../results/final_discocat_analysis_summary.json', 'r', encoding='utf-8') as f:
        ai_data = json.load(f)
    
    # è¨˜è€…æ–°èæ•¸æ“š
    with open('../results/cna_final_discocat_analysis_summary.json', 'r', encoding='utf-8') as f:
        journalist_data = json.load(f)
    
    return ai_data, journalist_data

def create_comparison_charts():
    """å‰µå»ºæ¯”è¼ƒåœ–è¡¨"""
    
    print("ğŸ¨ é–‹å§‹å‰µå»ºé‡å­ç‰¹å¾µæ¯”è¼ƒåœ–è¡¨...")
    
    # è¨­ç½®ä¸­æ–‡å­—é«”
    chinese_font = setup_chinese_fonts()
    labels = get_labels(chinese_font is not None)
    
    ai_data, journalist_data = load_comparison_data()
    
    # è¨­ç½®åœ–è¡¨æ¨£å¼
    plt.style.use('default')  # ä½¿ç”¨é»˜èªæ¨£å¼ï¼Œæ›´ç©©å®š
    fig = plt.figure(figsize=(20, 24))
    
    # ä¸»è¦é‡å­æŒ‡æ¨™
    quantum_metrics = [
        'grammatical_superposition',
        'frame_competition', 
        'multiple_reality_strength',
        'frame_conflict_strength',
        'semantic_interference',
        'von_neumann_entropy'
    ]
    
    # 1. é›·é”åœ–æ¯”è¼ƒ (æ–°èæ¨™é¡Œ)
    ax1 = plt.subplot(3, 2, 1, projection='polar')
    
    # æº–å‚™é›·é”åœ–æ•¸æ“š
    ai_title_values = []
    journalist_title_values = []
    
    for metric in quantum_metrics:
        ai_val = ai_data['æ–°èæ¨™é¡Œ'][metric]['mean']
        journalist_val = journalist_data['æ–°èæ¨™é¡Œ'][metric]['mean']
        
        # æ­£è¦åŒ–åˆ°0-1ç¯„åœï¼ˆé¦®ç´æ›¼ç†µéœ€è¦ç‰¹æ®Šè™•ç†ï¼‰
        if metric == 'von_neumann_entropy':
            ai_val = min(1.0, ai_val / 5.0)  # å‡è¨­æœ€å¤§å€¼ç‚º5
            journalist_val = min(1.0, journalist_val / 5.0)
        
        ai_title_values.append(ai_val)
        journalist_title_values.append(journalist_val)
    
    # é›·é”åœ–è§’åº¦
    angles = np.linspace(0, 2*np.pi, len(quantum_metrics), endpoint=False).tolist()
    ai_title_values += ai_title_values[:1]  # é–‰åˆ
    journalist_title_values += journalist_title_values[:1]
    angles += angles[:1]
    
    ax1.plot(angles, ai_title_values, 'o-', linewidth=2, label=labels['ai_label'], color='#FF6B6B')
    ax1.fill(angles, ai_title_values, alpha=0.25, color='#FF6B6B')
    ax1.plot(angles, journalist_title_values, 'o-', linewidth=2, label=labels['journalist_label'], color='#4ECDC4')
    ax1.fill(angles, journalist_title_values, alpha=0.25, color='#4ECDC4')
    
    ax1.set_xticks(angles[:-1])
    ax1.set_xticklabels(labels['metrics'], fontsize=10)
    ax1.set_ylim(0, 1)
    ax1.set_title(labels['titles']['radar'], fontsize=14, fontweight='bold', pad=20)
    ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
    
    # 2. æŸ±ç‹€åœ–æ¯”è¼ƒ - èªç¾©å¹²æ¶‰
    ax2 = plt.subplot(3, 2, 2)
    
    ai_interference = [
        ai_data['æ–°èæ¨™é¡Œ']['semantic_interference']['mean'],
        ai_data['å½±ç‰‡å°è©±']['semantic_interference']['mean']
    ]
    journalist_interference = [
        journalist_data['æ–°èæ¨™é¡Œ']['semantic_interference']['mean'],
        journalist_data['æ–°èå…§å®¹']['semantic_interference']['mean']
    ]
    
    x = np.arange(len(labels['categories']))
    width = 0.35
    
    bars1 = ax2.bar(x - width/2, ai_interference, width, label=labels['ai_label'], color='#FF6B6B', alpha=0.8)
    bars2 = ax2.bar(x + width/2, journalist_interference, width, label=labels['journalist_label'], color='#4ECDC4', alpha=0.8)
    
    ax2.set_xlabel('Text Type', fontsize=12)
    ax2.set_ylabel('Semantic Interference', fontsize=12)
    ax2.set_title(labels['titles']['interference'], fontsize=14, fontweight='bold')
    ax2.set_xticks(x)
    ax2.set_xticklabels(labels['categories'])
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for bar in bars1:
        height = bar.get_height()
        ax2.annotate(f'{height:.4f}', xy=(bar.get_x() + bar.get_width()/2, height),
                    xytext=(0, 3), textcoords="offset points", ha='center', va='bottom')
    
    for bar in bars2:
        height = bar.get_height()
        ax2.annotate(f'{height:.4f}', xy=(bar.get_x() + bar.get_width()/2, height),
                    xytext=(0, 3), textcoords="offset points", ha='center', va='bottom')
    
    # 3. æ¡†æ¶ç«¶çˆ­ vs æ¡†æ¶è¡çªæ•£é»åœ–
    ax3 = plt.subplot(3, 2, 3)
    
    # AIæ•¸æ“šé»
    ai_competition = [ai_data['æ–°èæ¨™é¡Œ']['frame_competition']['mean'], ai_data['å½±ç‰‡å°è©±']['frame_competition']['mean']]
    ai_conflict = [ai_data['æ–°èæ¨™é¡Œ']['frame_conflict_strength']['mean'], ai_data['å½±ç‰‡å°è©±']['frame_conflict_strength']['mean']]
    
    # è¨˜è€…æ•¸æ“šé»
    journalist_competition = [journalist_data['æ–°èæ¨™é¡Œ']['frame_competition']['mean'], journalist_data['æ–°èå…§å®¹']['frame_competition']['mean']]
    journalist_conflict = [journalist_data['æ–°èæ¨™é¡Œ']['frame_conflict_strength']['mean'], journalist_data['æ–°èå…§å®¹']['frame_conflict_strength']['mean']]
    
    ax3.scatter(ai_competition, ai_conflict, s=200, alpha=0.7, c='#FF6B6B', label=labels['ai_label'], edgecolors='black', linewidth=1)
    ax3.scatter(journalist_competition, journalist_conflict, s=200, alpha=0.7, c='#4ECDC4', label=labels['journalist_label'], edgecolors='black', linewidth=1)
    
    ax3.set_xlabel('Frame Competition', fontsize=12)
    ax3.set_ylabel('Frame Conflict', fontsize=12)
    ax3.set_title(labels['titles']['competition_conflict'], fontsize=14, fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # æ·»åŠ è±¡é™æ¨™ç±¤
    ax3.axhline(y=0.25, color='gray', linestyle='--', alpha=0.5)
    ax3.axvline(x=0.95, color='gray', linestyle='--', alpha=0.5)
    
    if chinese_font:
        ax3.text(0.85, 0.35, 'AIæ¨¡å¼:\né«˜ç«¶çˆ­ä½è¡çª', fontsize=10, ha='center', va='center', 
                 bbox=dict(boxstyle='round', facecolor='#FFE5E5', alpha=0.8))
        ax3.text(0.995, 0.29, 'è¨˜è€…æ¨¡å¼:\næ¥µé«˜ç«¶çˆ­ä¸­è¡çª', fontsize=10, ha='center', va='center',
                 bbox=dict(boxstyle='round', facecolor='#E5F9F6', alpha=0.8))
    else:
        ax3.text(0.85, 0.35, 'AI Pattern:\nHigh Competition\nLow Conflict', fontsize=10, ha='center', va='center', 
                 bbox=dict(boxstyle='round', facecolor='#FFE5E5', alpha=0.8))
        ax3.text(0.995, 0.29, 'Journalist Pattern:\nVery High Competition\nMedium Conflict', fontsize=10, ha='center', va='center',
                 bbox=dict(boxstyle='round', facecolor='#E5F9F6', alpha=0.8))
    
    # 4. å¤šé‡ç¾å¯¦å¼·åº¦ç®±ç·šåœ–
    ax4 = plt.subplot(3, 2, 4)
    
    # æ¨¡æ“¬æ•¸æ“šåˆ†ä½ˆï¼ˆåŸºæ–¼å‡å€¼å’Œæ¨™æº–å·®ï¼‰
    np.random.seed(42)
    ai_reality_title = np.random.normal(ai_data['æ–°èæ¨™é¡Œ']['multiple_reality_strength']['mean'], 
                                       ai_data['æ–°èæ¨™é¡Œ']['multiple_reality_strength']['std'], 100)
    journalist_reality_title = np.random.normal(journalist_data['æ–°èæ¨™é¡Œ']['multiple_reality_strength']['mean'],
                                               journalist_data['æ–°èæ¨™é¡Œ']['multiple_reality_strength']['std'], 100)
    
    box_data = [ai_reality_title, journalist_reality_title]
    box_labels = [labels['ai_label'], labels['journalist_label']]
    
    bp = ax4.boxplot(box_data, labels=box_labels, patch_artist=True)
    bp['boxes'][0].set_facecolor('#FF6B6B')
    bp['boxes'][0].set_alpha(0.7)
    bp['boxes'][1].set_facecolor('#4ECDC4')
    bp['boxes'][1].set_alpha(0.7)
    
    ax4.set_ylabel('Multiple Reality Strength', fontsize=12)
    ax4.set_title(labels['titles']['reality'], fontsize=14, fontweight='bold')
    ax4.grid(True, alpha=0.3)
    
    # 5. é¦®ç´æ›¼ç†µå°æ¯”
    ax5 = plt.subplot(3, 2, 5)
    
    ai_entropy = [ai_data['æ–°èæ¨™é¡Œ']['von_neumann_entropy']['mean'], ai_data['å½±ç‰‡å°è©±']['von_neumann_entropy']['mean']]
    journalist_entropy = [journalist_data['æ–°èæ¨™é¡Œ']['von_neumann_entropy']['mean'], journalist_data['æ–°èå…§å®¹']['von_neumann_entropy']['mean']]
    
    x = np.arange(len(labels['categories']))
    width = 0.35
    bars1 = ax5.bar(x - width/2, ai_entropy, width, label=labels['ai_label'], color='#FF6B6B', alpha=0.8)
    bars2 = ax5.bar(x + width/2, journalist_entropy, width, label=labels['journalist_label'], color='#4ECDC4', alpha=0.8)
    
    ax5.set_xlabel('Text Type', fontsize=12)
    ax5.set_ylabel('Von Neumann Entropy', fontsize=12)
    ax5.set_title(labels['titles']['entropy'], fontsize=14, fontweight='bold')
    ax5.set_xticks(x)
    ax5.set_xticklabels(labels['categories'])
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for bar in bars1:
        height = bar.get_height()
        ax5.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),
                    xytext=(0, 3), textcoords="offset points", ha='center', va='bottom')
    
    for bar in bars2:
        height = bar.get_height()
        ax5.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),
                    xytext=(0, 3), textcoords="offset points", ha='center', va='bottom')
    
    # 6. ç¶œåˆé‡å­æŒ‡ç´‹å°æ¯”
    ax6 = plt.subplot(3, 2, 6)
    
    # å‰µå»ºé‡å­æŒ‡ç´‹ç†±åœ–æ•¸æ“š
    if chinese_font:
        metrics_short = ['èªæ³•ç–ŠåŠ ', 'æ¡†æ¶ç«¶çˆ­', 'å¤šé‡ç¾å¯¦', 'æ¡†æ¶è¡çª', 'èªç¾©å¹²æ¶‰']
    else:
        metrics_short = ['Grammar', 'Competition', 'Reality', 'Conflict', 'Interference']
    
    ai_fingerprint = [
        ai_data['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean'],
        ai_data['æ–°èæ¨™é¡Œ']['frame_competition']['mean'],
        ai_data['æ–°èæ¨™é¡Œ']['multiple_reality_strength']['mean'],
        ai_data['æ–°èæ¨™é¡Œ']['frame_conflict_strength']['mean'],
        min(1.0, ai_data['æ–°èæ¨™é¡Œ']['semantic_interference']['mean'])  # æ­£è¦åŒ–
    ]
    
    journalist_fingerprint = [
        journalist_data['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean'],
        journalist_data['æ–°èæ¨™é¡Œ']['frame_competition']['mean'],
        journalist_data['æ–°èæ¨™é¡Œ']['multiple_reality_strength']['mean'],
        journalist_data['æ–°èæ¨™é¡Œ']['frame_conflict_strength']['mean'],
        min(1.0, journalist_data['æ–°èæ¨™é¡Œ']['semantic_interference']['mean'] * 100)  # æ”¾å¤§é¡¯ç¤º
    ]
    
    fingerprint_data = np.array([ai_fingerprint, journalist_fingerprint])
    
    im = ax6.imshow(fingerprint_data, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)
    ax6.set_xticks(range(len(metrics_short)))
    ax6.set_xticklabels(metrics_short, rotation=45, ha='right')
    ax6.set_yticks([0, 1])
    ax6.set_yticklabels([labels['ai_label'], labels['journalist_label']])
    ax6.set_title(labels['titles']['fingerprint'], fontsize=14, fontweight='bold')
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for i in range(2):
        for j in range(len(metrics_short)):
            text = ax6.text(j, i, f'{fingerprint_data[i, j]:.3f}', 
                           ha="center", va="center", color="white" if fingerprint_data[i, j] > 0.5 else "black",
                           fontweight='bold')
    
    # æ·»åŠ é¡è‰²æ¢
    cbar = plt.colorbar(im, ax=ax6, shrink=0.8)
    if chinese_font:
        cbar.set_label('ç‰¹å¾µå¼·åº¦', fontsize=10)
    else:
        cbar.set_label('Feature Strength', fontsize=10)
    
    plt.tight_layout()
    plt.suptitle(labels['titles']['main'], fontsize=18, fontweight='bold', y=0.98)
    
    # ä¿å­˜åœ–è¡¨
    output_file = '../visualizations/ai_vs_journalist_quantum_comparison_fixed.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"ğŸ“Š ä¿®å¾©ç‰ˆæ¯”è¼ƒåœ–è¡¨å·²ä¿å­˜: {output_file}")
    
    plt.show()

def main():
    """ä¸»å‡½æ•¸"""
    
    print("ğŸš€ é–‹å§‹AI vs è¨˜è€…æ–°èé‡å­ç‰¹å¾µæ¯”è¼ƒåˆ†æï¼ˆä¿®å¾©ä¸­æ–‡é¡¯ç¤ºç‰ˆæœ¬ï¼‰")
    print("=" * 70)
    
    # å‰µå»ºå¯è¦–åŒ–
    create_comparison_charts()
    
    print("\nâœ… ä¿®å¾©ç‰ˆæ¯”è¼ƒåˆ†æå®Œæˆ!")
    print("ğŸ“Š åœ–è¡¨æ–‡ä»¶: ../visualizations/ai_vs_journalist_quantum_comparison_fixed.png")

if __name__ == "__main__":
    main()

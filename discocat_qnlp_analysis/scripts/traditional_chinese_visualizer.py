#!/usr/bin/env python3
"""
ç¹é«”ä¸­æ–‡å¯è¦–åŒ–åˆ†æå™¨
é‡æ–°ç”Ÿæˆæ‰€æœ‰åœ–è¡¨ï¼Œç¢ºä¿ä½¿ç”¨ç¹é«”ä¸­æ–‡é¡¯ç¤º
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import os
from pathlib import Path
import platform

def setup_traditional_chinese_font():
    """è¨­ç½®ç¹é«”ä¸­æ–‡å­—é«”ä»¥ç¢ºä¿æ­£ç¢ºé¡¯ç¤º"""
    print("ğŸ”§ è¨­ç½®ç¹é«”ä¸­æ–‡å­—é«”...")
    
    # æª¢æ¸¬æ“ä½œç³»çµ±ä¸¦è¨­ç½®ç›¸æ‡‰çš„ç¹é«”ä¸­æ–‡å­—é«”
    system = platform.system()
    
    if system == 'Darwin':  # macOS
        fonts = ['Arial Unicode MS', 'PingFang TC', 'Heiti TC', 'STSong', 'LiHei Pro']
        print("ğŸ æª¢æ¸¬åˆ°macOSç³»çµ±")
    elif system == 'Windows':
        fonts = ['Microsoft JhengHei', 'PMingLiU', 'MingLiU', 'DFKai-SB']
        print("ğŸªŸ æª¢æ¸¬åˆ°Windowsç³»çµ±")
    else:  # Linux
        fonts = ['WenQuanYi Micro Hei', 'Noto Sans CJK TC', 'AR PL UMing TW']
        print("ğŸ§ æª¢æ¸¬åˆ°Linuxç³»çµ±")
    
    # è¨­ç½®matplotlibåƒæ•¸
    plt.rcParams['axes.unicode_minus'] = False
    
    # å˜—è©¦è¨­ç½®å­—é«”
    for font in fonts:
        try:
            plt.rcParams['font.sans-serif'] = [font] + plt.rcParams['font.sans-serif']
            print(f"âœ… è¨­ç½®å­—é«”: {font}")
            break
        except:
            continue
    
    # é©—è­‰ç¹é«”ä¸­æ–‡å­—é«”è¨­ç½®
    plt.rcParams['font.family'] = 'sans-serif'
    
    # æ¸¬è©¦ç¹é«”ä¸­æ–‡å­—ç¬¦
    fig, ax = plt.subplots(figsize=(10, 6))
    test_text = "æ¸¬è©¦ç¹é«”ä¸­æ–‡å­—ç¬¦é¡¯ç¤ºï¼šé‡å­è‡ªç„¶èªè¨€è™•ç†åˆ†æ\né¦®ç´æ›¼ç†µã€èªç¾©å¹²æ¶‰ã€æ¡†æ¶ç«¶çˆ­å¼·åº¦"
    ax.text(0.5, 0.5, test_text, ha='center', va='center', fontsize=16)
    ax.set_title('ç¹é«”ä¸­æ–‡å­—é«”æ¸¬è©¦åœ–è¡¨', fontsize=18, fontweight='bold')
    ax.axis('off')
    
    # ä¿å­˜æ¸¬è©¦åœ–
    test_path = '../20250927-image/traditional_chinese_font_test.png'
    plt.savefig(test_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print(f"ğŸ“Š ç¹é«”ä¸­æ–‡å­—é«”æ¸¬è©¦åœ–å·²ä¿å­˜: {test_path}")

def load_full_dataset_results():
    """è¼‰å…¥å®Œæ•´è³‡æ–™é›†çš„åˆ†æçµæœ"""
    print("ğŸ“‚ è¼‰å…¥å®Œæ•´è³‡æ–™é›†åˆ†æçµæœ...")
    
    # è¼‰å…¥çµ±è¨ˆæ‘˜è¦
    ai_summary_path = '../results/full_qiskit_ai_analysis_summary.json'
    journalist_summary_path = '../results/full_qiskit_journalist_analysis_summary.json'
    field_level_path = '../results/full_field_level_quantum_analysis.json'
    
    with open(ai_summary_path, 'r', encoding='utf-8') as f:
        ai_summary = json.load(f)
    
    with open(journalist_summary_path, 'r', encoding='utf-8') as f:
        journalist_summary = json.load(f)
        
    with open(field_level_path, 'r', encoding='utf-8') as f:
        field_level_data = json.load(f)
    
    print("âœ… è³‡æ–™è¼‰å…¥å®Œæˆ")
    return ai_summary, journalist_summary, field_level_data

def create_comprehensive_comparison_tc(ai_summary, journalist_summary, field_level_data):
    """å‰µå»ºç¶œåˆå°æ¯”åœ–è¡¨ï¼ˆç¹é«”ä¸­æ–‡ï¼‰"""
    print("ğŸ“Š ç”Ÿæˆç¶œåˆå°æ¯”åœ–è¡¨ï¼ˆç¹é«”ä¸­æ–‡ï¼‰...")
    
    # é‡å­æŒ‡æ¨™ï¼ˆç¹é«”ä¸­æ–‡ï¼‰
    metrics = ['von_neumann_entropy', 'superposition_strength', 'quantum_coherence', 
               'semantic_interference', 'frame_competition', 'multiple_reality_strength']
    
    metric_names = {
        'von_neumann_entropy': 'é¦®ç´æ›¼ç†µ',
        'superposition_strength': 'é‡å­ç–ŠåŠ å¼·åº¦',
        'quantum_coherence': 'é‡å­ç›¸å¹²æ€§',
        'semantic_interference': 'èªç¾©å¹²æ¶‰',
        'frame_competition': 'æ¡†æ¶ç«¶çˆ­',
        'multiple_reality_strength': 'å¤šé‡ç¾å¯¦å¼·åº¦'
    }
    
    # å‰µå»º2x3çš„å­åœ–å¸ƒå±€
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('å®Œæ•´è³‡æ–™é›†é‡å­ç‰¹å¾µå°æ¯”åˆ†æ\n(åŸºæ–¼934å€‹æ–‡æœ¬ç‰‡æ®µçš„Qiskité‡å­é›»è·¯åˆ†æ)', 
                 fontsize=20, fontweight='bold')
    
    axes = axes.flatten()
    
    for i, metric in enumerate(metrics):
        ax = axes[i]
        
        # è³‡æ–™æº–å‚™
        ai_mean = ai_summary[metric]['mean']
        ai_std = ai_summary[metric]['std']
        journalist_mean = journalist_summary[metric]['mean']
        journalist_std = journalist_summary[metric]['std']
        
        # æŸ±ç‹€åœ–
        categories = ['AIç”Ÿæˆæ–°è\n(298æ¢è¨˜éŒ„)', 'è¨˜è€…æ’°å¯«æ–°è\n(20æ¢è¨˜éŒ„)']
        means = [ai_mean, journalist_mean]
        stds = [ai_std, journalist_std]
        colors = ['#FF6B6B', '#4ECDC4']
        
        bars = ax.bar(categories, means, yerr=stds, capsize=8, 
                     color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar, mean, std in zip(bars, means, stds):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + std + 0.01,
                   f'{mean:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        ax.set_title(f'{metric_names[metric]}', fontsize=14, fontweight='bold')
        ax.set_ylabel('æ•¸å€¼', fontsize=12)
        ax.grid(True, alpha=0.3)
        
        # è¨­ç½®Yè»¸ç¯„åœ
        max_val = max(means) + max(stds)
        min_val = min(means) - max(stds)
        margin = (max_val - min_val) * 0.15
        ax.set_ylim(max(0, min_val - margin), max_val + margin)
    
    plt.tight_layout()
    plt.savefig('../20250927-image/comprehensive_quantum_comparison_tc.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… ç¶œåˆå°æ¯”åœ–è¡¨ï¼ˆç¹é«”ä¸­æ–‡ï¼‰å·²ä¿å­˜")

def create_field_level_heatmap_tc(field_level_data):
    """å‰µå»ºæ¬„ä½ç´šåˆ¥ç†±åŠ›åœ–ï¼ˆç¹é«”ä¸­æ–‡ï¼‰"""
    print("ğŸ”¥ ç”Ÿæˆæ¬„ä½ç´šåˆ¥ç†±åŠ›åœ–ï¼ˆç¹é«”ä¸­æ–‡ï¼‰...")
    
    # æº–å‚™è³‡æ–™
    metrics = ['von_neumann_entropy', 'superposition_strength', 'quantum_coherence', 
               'semantic_interference', 'multiple_reality_strength']
    
    # AIè³‡æ–™
    ai_fields = ['æ–°èæ¨™é¡Œ', 'å½±ç‰‡å°è©±', 'å½±ç‰‡æè¿°']
    ai_data = []
    ai_labels = []
    
    for field in ai_fields:
        row = []
        for metric in metrics:
            mean_val = field_level_data['AI_Generated'][field][metric]['mean']
            row.append(mean_val)
        ai_data.append(row)
        ai_labels.append(f'AI-{field}')
    
    # è¨˜è€…è³‡æ–™
    journalist_fields = ['æ–°èæ¨™é¡Œ', 'æ–°èå…§å®¹']
    journalist_data = []
    journalist_labels = []
    
    for field in journalist_fields:
        row = []
        for metric in metrics:
            mean_val = field_level_data['Journalist_Written'][field][metric]['mean']
            row.append(mean_val)
        journalist_data.append(row)
        journalist_labels.append(f'è¨˜è€…-{field}')
    
    # åˆä½µè³‡æ–™
    all_data = np.array(ai_data + journalist_data)
    all_labels = ai_labels + journalist_labels
    
    # å‰µå»ºç†±åŠ›åœ–
    fig, ax = plt.subplots(figsize=(12, 8))
    
    metric_names = ['é¦®ç´æ›¼ç†µ', 'é‡å­ç–ŠåŠ å¼·åº¦', 'é‡å­ç›¸å¹²æ€§', 'èªç¾©å¹²æ¶‰', 'å¤šé‡ç¾å¯¦å¼·åº¦']
    
    # ä½¿ç”¨seabornå‰µå»ºç†±åŠ›åœ–
    sns.heatmap(all_data, 
                xticklabels=metric_names,
                yticklabels=all_labels,
                annot=True, 
                fmt='.4f',
                cmap='RdYlBu_r',
                center=None,
                ax=ax,
                cbar_kws={'label': 'é‡å­ç‰¹å¾µå€¼'})
    
    ax.set_title('æ¬„ä½ç´šåˆ¥é‡å­ç‰¹å¾µç†±åŠ›åœ–\n(å®Œæ•´è³‡æ–™é›†åˆ†æ)', fontsize=16, fontweight='bold')
    ax.set_xlabel('é‡å­æŒ‡æ¨™', fontsize=12)
    ax.set_ylabel('è³‡æ–™ä¾†æºèˆ‡æ¬„ä½', fontsize=12)
    
    plt.tight_layout()
    plt.savefig('../20250927-image/field_level_heatmap_tc.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… æ¬„ä½ç´šåˆ¥ç†±åŠ›åœ–ï¼ˆç¹é«”ä¸­æ–‡ï¼‰å·²ä¿å­˜")

def create_radar_chart_tc(field_level_data):
    """å‰µå»ºé›·é”åœ–å°æ¯”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰"""
    print("ğŸ¯ ç”Ÿæˆé›·é”åœ–å°æ¯”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰...")
    
    metrics = ['von_neumann_entropy', 'superposition_strength', 'quantum_coherence', 
               'semantic_interference', 'multiple_reality_strength']
    metric_names = ['é¦®ç´æ›¼ç†µ', 'é‡å­ç–ŠåŠ å¼·åº¦', 'é‡å­ç›¸å¹²æ€§', 'èªç¾©å¹²æ¶‰', 'å¤šé‡ç¾å¯¦å¼·åº¦']
    
    # è³‡æ–™æº–å‚™ - é¸æ“‡ä»£è¡¨æ€§æ¬„ä½é€²è¡Œå°æ¯”
    ai_dialogue = []  # AIå½±ç‰‡å°è©±
    journalist_content = []  # è¨˜è€…æ–°èå…§å®¹
    
    for metric in metrics:
        ai_val = field_level_data['AI_Generated']['å½±ç‰‡å°è©±'][metric]['mean']
        journalist_val = field_level_data['Journalist_Written']['æ–°èå…§å®¹'][metric]['mean']
        
        # æ­¸ä¸€åŒ–åˆ°0-1ç¯„åœç”¨æ–¼é›·é”åœ–é¡¯ç¤º
        max_val = max(ai_val, journalist_val)
        if max_val > 0:
            ai_dialogue.append(ai_val / max_val)
            journalist_content.append(journalist_val / max_val)
        else:
            ai_dialogue.append(0)
            journalist_content.append(0)
    
    # å‰µå»ºé›·é”åœ–
    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
    angles += angles[:1]  # é–‰åˆé›·é”åœ–
    
    ai_dialogue += ai_dialogue[:1]
    journalist_content += journalist_content[:1]
    
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
    
    # ç¹ªè£½é›·é”åœ–
    ax.plot(angles, ai_dialogue, 'o-', linewidth=3, label='AIå½±ç‰‡å°è©± (298æ¢)', color='#FF6B6B')
    ax.fill(angles, ai_dialogue, alpha=0.25, color='#FF6B6B')
    
    ax.plot(angles, journalist_content, 'o-', linewidth=3, label='è¨˜è€…æ–°èå…§å®¹ (20æ¢)', color='#4ECDC4')
    ax.fill(angles, journalist_content, alpha=0.25, color='#4ECDC4')
    
    # è¨­ç½®æ¨™ç±¤
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(metric_names, fontsize=12)
    
    ax.set_ylim(0, 1)
    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=10)
    ax.grid(True)
    
    plt.title('é‡å­ç‰¹å¾µé›·é”åœ–å°æ¯”\n(é•·æ–‡æœ¬æ¬„ä½ä»£è¡¨æ€§åˆ†æ)', fontsize=16, fontweight='bold', pad=30)
    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
    
    plt.savefig('../20250927-image/quantum_radar_comparison_tc.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… é›·é”åœ–å°æ¯”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰å·²ä¿å­˜")

def create_distribution_analysis_tc(field_level_data):
    """å‰µå»ºåˆ†ä½ˆåˆ†æåœ–ï¼ˆç¹é«”ä¸­æ–‡ï¼‰"""
    print("ğŸ“ˆ ç”Ÿæˆåˆ†ä½ˆåˆ†æåœ–ï¼ˆç¹é«”ä¸­æ–‡ï¼‰...")
    
    # é¸æ“‡é—œéµæŒ‡æ¨™é€²è¡Œåˆ†ä½ˆåˆ†æ
    key_metrics = ['von_neumann_entropy', 'semantic_interference', 'multiple_reality_strength']
    metric_names = ['é¦®ç´æ›¼ç†µ', 'èªç¾©å¹²æ¶‰', 'å¤šé‡ç¾å¯¦å¼·åº¦']
    
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    fig.suptitle('é—œéµé‡å­æŒ‡æ¨™çš„æ¬„ä½åˆ†ä½ˆåˆ†æ\n(å®Œæ•´è³‡æ–™é›†)', fontsize=16, fontweight='bold')
    
    for i, (metric, name) in enumerate(zip(key_metrics, metric_names)):
        ax = axes[i]
        
        # æ”¶é›†æ‰€æœ‰æ¬„ä½çš„è³‡æ–™
        field_names = []
        values = []
        colors = []
        
        # AIè³‡æ–™
        for field in ['æ–°èæ¨™é¡Œ', 'å½±ç‰‡å°è©±', 'å½±ç‰‡æè¿°']:
            mean_val = field_level_data['AI_Generated'][field][metric]['mean']
            std_val = field_level_data['AI_Generated'][field][metric]['std']
            count = field_level_data['AI_Generated'][field][metric]['count']
            
            field_names.append(f'AI-{field}\n({count}æ¢)')
            values.append(mean_val)
            colors.append('#FF6B6B')
        
        # è¨˜è€…è³‡æ–™
        for field in ['æ–°èæ¨™é¡Œ', 'æ–°èå…§å®¹']:
            mean_val = field_level_data['Journalist_Written'][field][metric]['mean']
            std_val = field_level_data['Journalist_Written'][field][metric]['std']
            count = field_level_data['Journalist_Written'][field][metric]['count']
            
            field_names.append(f'è¨˜è€…-{field}\n({count}æ¢)')
            values.append(mean_val)
            colors.append('#4ECDC4')
        
        # å‰µå»ºæŸ±ç‹€åœ–
        bars = ax.bar(range(len(field_names)), values, color=colors, alpha=0.8, edgecolor='black')
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                   f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        
        ax.set_title(name, fontsize=14, fontweight='bold')
        ax.set_ylabel('æ•¸å€¼', fontsize=12)
        ax.set_xticks(range(len(field_names)))
        ax.set_xticklabels(field_names, rotation=45, ha='right')
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('../20250927-image/distribution_analysis_tc.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… åˆ†ä½ˆåˆ†æåœ–ï¼ˆç¹é«”ä¸­æ–‡ï¼‰å·²ä¿å­˜")

def create_summary_statistics_table_tc():
    """å‰µå»ºçµ±è¨ˆæ‘˜è¦è¡¨æ ¼ï¼ˆç¹é«”ä¸­æ–‡ï¼‰"""
    print("ğŸ“‹ ç”Ÿæˆçµ±è¨ˆæ‘˜è¦è¡¨æ ¼ï¼ˆç¹é«”ä¸­æ–‡ï¼‰...")
    
    fig, ax = plt.subplots(figsize=(16, 10))
    ax.axis('tight')
    ax.axis('off')
    
    # è¡¨æ ¼è³‡æ–™ï¼ˆç¹é«”ä¸­æ–‡ï¼‰
    table_data = [
        ['è³‡æ–™ä¾†æº', 'æ¬„ä½', 'è¨˜éŒ„æ•¸', 'é¦®ç´æ›¼ç†µ', 'é‡å­ç–ŠåŠ å¼·åº¦', 'é‡å­ç›¸å¹²æ€§', 'èªç¾©å¹²æ¶‰', 'å¤šé‡ç¾å¯¦å¼·åº¦'],
        ['AIç”Ÿæˆ', 'æ–°èæ¨™é¡Œ', '298', '3.9967Â±0.0579', '3.7492Â±0.0145', '0.9373Â±0.0036', '0.0014Â±0.0026', '1.7001Â±0.0059'],
        ['AIç”Ÿæˆ', 'å½±ç‰‡å°è©±', '298', '4.0000Â±0.0000', '3.7500Â±0.0000', '0.9375Â±0.0000', '0.0178Â±0.0042', '1.7054Â±0.0013'],
        ['AIç”Ÿæˆ', 'å½±ç‰‡æè¿°', '298', '4.0000Â±0.0000', '3.7500Â±0.0000', '0.9375Â±0.0000', '0.0111Â±0.0039', '1.7033Â±0.0012'],
        ['è¨˜è€…æ’°å¯«', 'æ–°èæ¨™é¡Œ', '20', '3.8500Â±0.3663', '3.7125Â±0.0916', '0.9281Â±0.0229', '0.0008Â±0.0022', '1.6856Â±0.0369'],
        ['è¨˜è€…æ’°å¯«', 'æ–°èå…§å®¹', '20', '4.0000Â±0.0000', '3.7500Â±0.0000', '0.9375Â±0.0000', '0.0177Â±0.0060', '1.7054Â±0.0018']
    ]
    
    # å‰µå»ºè¡¨æ ¼
    table = ax.table(cellText=table_data[1:], colLabels=table_data[0], 
                     loc='center', cellLoc='center')
    
    # è¨­ç½®è¡¨æ ¼æ¨£å¼
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 2.5)
    
    # è¨­ç½®æ¨™é¡Œè¡Œæ¨£å¼
    for i in range(len(table_data[0])):
        table[(0, i)].set_facecolor('#4ECDC4')
        table[(0, i)].set_text_props(weight='bold', color='white')
    
    # è¨­ç½®è³‡æ–™è¡Œæ¨£å¼
    for i in range(1, len(table_data)):
        color = '#FFE5E5' if 'AIç”Ÿæˆ' in table_data[i][0] else '#E5F9F6'
        for j in range(len(table_data[0])):
            table[(i, j)].set_facecolor(color)
    
    plt.title('å®Œæ•´è³‡æ–™é›†é‡å­ç‰¹å¾µçµ±è¨ˆæ‘˜è¦è¡¨\n(å¹³å‡å€¼Â±æ¨™æº–å·®)', fontsize=16, fontweight='bold', pad=20)
    
    plt.savefig('../20250927-image/statistics_summary_table_tc.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… çµ±è¨ˆæ‘˜è¦è¡¨æ ¼ï¼ˆç¹é«”ä¸­æ–‡ï¼‰å·²ä¿å­˜")

def create_qubit_distribution_chart_tc():
    """å‰µå»ºé‡å­ä½å…ƒåˆ†ä½ˆåœ–è¡¨ï¼ˆç¹é«”ä¸­æ–‡ï¼‰"""
    print("ğŸ“Š ç”Ÿæˆé‡å­ä½å…ƒåˆ†ä½ˆåœ–è¡¨ï¼ˆç¹é«”ä¸­æ–‡ï¼‰...")
    
    # è¼‰å…¥é‡å­ä½å…ƒåˆ†ä½ˆè³‡æ–™
    with open('../20250927-image/qubit_distribution_data.json', 'r', encoding='utf-8') as f:
        qubit_data = json.load(f)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    fig.suptitle('é‡å­ä½å…ƒåˆ†ä½ˆçµ±è¨ˆ\n(åŸºæ–¼934å€‹æ–‡æœ¬ç‰‡æ®µ)', fontsize=18, fontweight='bold')
    
    # AIç”Ÿæˆæ–°èåˆ†ä½ˆ
    ai_dist = qubit_data['ai_stats']['qubit_distribution']
    ai_qubits = list(ai_dist.keys())
    ai_counts = list(ai_dist.values())
    ai_total = sum(ai_counts)
    ai_percentages = [count/ai_total*100 for count in ai_counts]
    
    colors1 = ['#FF9999', '#FF6B6B', '#FF4444']
    bars1 = ax1.bar([f'{q}å€‹é‡å­ä½å…ƒ' for q in ai_qubits], ai_counts, 
                   color=colors1[:len(ai_qubits)], alpha=0.8, edgecolor='black')
    
    # æ·»åŠ ç™¾åˆ†æ¯”æ¨™ç±¤
    for bar, count, pct in zip(bars1, ai_counts, ai_percentages):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 10,
                f'{count}æ¢\n({pct:.1f}%)', ha='center', va='bottom', fontweight='bold')
    
    ax1.set_title('AIç”Ÿæˆæ–°è (894æ¢è¨˜éŒ„)', fontsize=14, fontweight='bold')
    ax1.set_ylabel('è¨˜éŒ„æ•¸é‡', fontsize=12)
    ax1.grid(True, alpha=0.3)
    
    # è¨˜è€…æ’°å¯«æ–°èåˆ†ä½ˆ
    journalist_dist = qubit_data['journalist_stats']['qubit_distribution']
    journalist_qubits = list(journalist_dist.keys())
    journalist_counts = list(journalist_dist.values())
    journalist_total = sum(journalist_counts)
    journalist_percentages = [count/journalist_total*100 for count in journalist_counts]
    
    colors2 = ['#99E5E5', '#4ECDC4', '#44C4C4']
    bars2 = ax2.bar([f'{q}å€‹é‡å­ä½å…ƒ' for q in journalist_qubits], journalist_counts, 
                   color=colors2[:len(journalist_qubits)], alpha=0.8, edgecolor='black')
    
    # æ·»åŠ ç™¾åˆ†æ¯”æ¨™ç±¤
    for bar, count, pct in zip(bars2, journalist_counts, journalist_percentages):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{count}æ¢\n({pct:.1f}%)', ha='center', va='bottom', fontweight='bold')
    
    ax2.set_title('è¨˜è€…æ’°å¯«æ–°è (40æ¢è¨˜éŒ„)', fontsize=14, fontweight='bold')
    ax2.set_ylabel('è¨˜éŒ„æ•¸é‡', fontsize=12)
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('../20250927-image/qubit_distribution_chart_tc.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… é‡å­ä½å…ƒåˆ†ä½ˆåœ–è¡¨ï¼ˆç¹é«”ä¸­æ–‡ï¼‰å·²ä¿å­˜")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹å®Œæ•´è³‡æ–™é›†å¯è¦–åŒ–åˆ†æï¼ˆç¹é«”ä¸­æ–‡ï¼‰...")
    print(f"ğŸ“Š åˆ†æè¦æ¨¡: 934å€‹æ–‡æœ¬ç‰‡æ®µ")
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    Path('../20250927-image').mkdir(exist_ok=True)
    
    # è¨­ç½®ç¹é«”ä¸­æ–‡å­—é«”
    setup_traditional_chinese_font()
    
    # è¼‰å…¥è³‡æ–™
    ai_summary, journalist_summary, field_level_data = load_full_dataset_results()
    
    # ç”Ÿæˆå„ç¨®å¯è¦–åŒ–åœ–è¡¨ï¼ˆç¹é«”ä¸­æ–‡ç‰ˆæœ¬ï¼‰
    create_comprehensive_comparison_tc(ai_summary, journalist_summary, field_level_data)
    create_field_level_heatmap_tc(field_level_data)
    create_radar_chart_tc(field_level_data)
    create_distribution_analysis_tc(field_level_data)
    create_summary_statistics_table_tc()
    create_qubit_distribution_chart_tc()
    
    print("\nğŸ‰ å®Œæ•´è³‡æ–™é›†å¯è¦–åŒ–åˆ†æï¼ˆç¹é«”ä¸­æ–‡ï¼‰å®Œæˆï¼")
    print("ğŸ“‚ æ‰€æœ‰åœ–è¡¨å·²ä¿å­˜åˆ°: ../20250927-image/")
    print("ğŸ“Š ç”Ÿæˆçš„ç¹é«”ä¸­æ–‡åœ–è¡¨:")
    print("   1. traditional_chinese_font_test.png - ç¹é«”ä¸­æ–‡å­—é«”æ¸¬è©¦")
    print("   2. comprehensive_quantum_comparison_tc.png - ç¶œåˆé‡å­ç‰¹å¾µå°æ¯”")
    print("   3. field_level_heatmap_tc.png - æ¬„ä½ç´šåˆ¥ç†±åŠ›åœ–")
    print("   4. quantum_radar_comparison_tc.png - é‡å­ç‰¹å¾µé›·é”åœ–")
    print("   5. distribution_analysis_tc.png - åˆ†ä½ˆåˆ†æåœ–")
    print("   6. statistics_summary_table_tc.png - çµ±è¨ˆæ‘˜è¦è¡¨æ ¼")
    print("   7. qubit_distribution_chart_tc.png - é‡å­ä½å…ƒåˆ†ä½ˆåœ–è¡¨")

if __name__ == "__main__":
    main()

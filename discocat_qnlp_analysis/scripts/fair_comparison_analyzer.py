#!/usr/bin/env python3
"""
å…¬å¹³å¯¹æ¯”åˆ†æå™¨ - ç¡®ä¿AIæ–°é—»å’Œè®°è€…æ–°é—»çš„å­—æ®µå¯¹æ¯”å…¬å¹³æ€§
AIæ•°æ®: æ–°èæ¨™é¡Œ, å½±ç‰‡æè¿°, å½±ç‰‡å°è©±
CNAæ•°æ®: title, content (åˆ†åˆ«å¯¹åº”æ ‡é¢˜å’Œå†…å®¹)
"""

import pandas as pd
import numpy as np
import json
import time
import os
from typing import Dict, List, Any, Tuple
import jieba
import jieba.posseg as pseg
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡åˆ†è¯
jieba.set_dictionary('../data/dict.txt.big') if os.path.exists('../data/dict.txt.big') else None

class FairComparisonAnalyzer:
    """å…¬å¹³å¯¹æ¯”åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        print("ğŸ”§ åˆå§‹åŒ–å…¬å¹³å¯¹æ¯”åˆ†æå™¨...")
        
        # æƒ…æ„Ÿè¯å…¸
        self.emotion_lexicon = {
            'positive': ['æˆåŠŸ', 'è·å¾—', 'ä¼˜ç§€', 'çªç ´', 'åˆ›æ–°', 'å‘å±•', 'æ”¹å–„', 'æå‡', 'è£è·', 
                        'å“è¶Š', 'é¢†å…ˆ', 'è¿›æ­¥', 'å¢é•¿', 'è·å¥–', 'è‚¯å®š', 'æ”¯æŒ', 'åˆä½œ', 'å…±èµ¢'],
            'negative': ['å¤±è´¥', 'é—®é¢˜', 'å›°éš¾', 'å±æœº', 'å†²çª', 'äº‰è®®', 'æ‰¹è¯„', 'è´¨ç–‘', 'æ‹…å¿§',
                        'ä¸‹é™', 'å‡å°‘', 'æŸå¤±', 'é£é™©', 'å¨èƒ', 'æŒ‘æˆ˜', 'é˜»ç¢', 'å»¶è¿Ÿ', 'å–æ¶ˆ']
        }
        
        print("âœ… å…¬å¹³å¯¹æ¯”åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def segment_and_pos_tag(self, text: str) -> Tuple[List[str], List[str]]:
        """åˆ†è¯å’Œè¯æ€§æ ‡æ³¨"""
        words = []
        pos_tags = []
        
        for word, flag in pseg.cut(text):
            if len(word.strip()) > 0:
                words.append(word)
                pos_tags.append(flag)
        
        return words, pos_tags

    def calculate_quantum_metrics(self, words: List[str], pos_tags: List[str], use_restrictions: bool = True) -> Dict[str, float]:
        """è®¡ç®—é‡å­æŒ‡æ ‡ï¼ˆå¯é€‰æ‹©æ˜¯å¦ä½¿ç”¨é™åˆ¶ï¼‰"""
        
        # åŸºæœ¬ç»Ÿè®¡
        word_count = len(words)
        unique_words = len(set(words))
        pos_diversity = len(set(pos_tags))
        
        if word_count == 0:
            return self._get_zero_metrics()
        
        # è®¡ç®—è¯é¢‘åˆ†å¸ƒ
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # æ­£è§„åŒ–é¢‘ç‡
        total_words = sum(word_freq.values())
        probabilities = np.array([freq/total_words for freq in word_freq.values()])
        
        # 1. å†¯çº½æ›¼ç†µ
        von_neumann_entropy = -np.sum(probabilities * np.log2(probabilities + 1e-12))
        
        # 2. ç±»åˆ«ä¸€è‡´æ€§
        pos_freq = {}
        for pos in pos_tags:
            pos_freq[pos] = pos_freq.get(pos, 0) + 1
        
        total_pos = sum(pos_freq.values())
        pos_probs = np.array([freq/total_pos for freq in pos_freq.values()])
        category_coherence = np.max(pos_probs)
        
        # 3. ç»„åˆçº ç¼ å¼ºåº¦
        compositional_entanglement = pos_diversity / word_count
        if use_restrictions:
            compositional_entanglement = min(1.0, compositional_entanglement)
        
        # 4. è¯­æ³•å åŠ æ€ (å…³é”®å·®å¼‚ï¼)
        superposition_measure = 4 * np.sum(probabilities * (1 - probabilities))
        if use_restrictions:
            grammatical_superposition = min(1.0, superposition_measure)  # å—é™åˆ¶ç‰ˆæœ¬
        else:
            grammatical_superposition = superposition_measure  # æ— é™åˆ¶ç‰ˆæœ¬
        
        # 5. è¯­ä¹‰å¹²æ¶‰
        repetition_variance = np.var(list(word_freq.values()))
        semantic_interference = repetition_variance / word_count
        if use_restrictions:
            semantic_interference = min(1.0, semantic_interference)
        
        # 6. æ¡†æ¶ç«äº‰
        if len(probabilities) > 1:
            uniform_prob = 1.0 / len(probabilities)
            kl_divergence = np.sum(probabilities * np.log2((probabilities + 1e-12) / uniform_prob))
            max_kl = np.log2(len(probabilities))
            frame_competition = float(1.0 - (kl_divergence / max_kl))
        else:
            frame_competition = 0.0
        
        # 7. ç±»åˆ«ä¸€è‡´æ€§å˜å¼‚
        categorical_coherence_variance = np.var(pos_probs)
        
        return {
            'von_neumann_entropy': float(von_neumann_entropy),
            'category_coherence': float(category_coherence),
            'compositional_entanglement': float(compositional_entanglement),
            'grammatical_superposition': float(grammatical_superposition),
            'semantic_interference': float(semantic_interference),
            'frame_competition': float(frame_competition),
            'categorical_coherence_variance': float(categorical_coherence_variance)
        }

    def _get_zero_metrics(self):
        """è¿”å›é›¶å€¼æŒ‡æ ‡"""
        return {
            'von_neumann_entropy': 0.0,
            'category_coherence': 0.0,
            'compositional_entanglement': 0.0,
            'grammatical_superposition': 0.0,
            'semantic_interference': 0.0,
            'frame_competition': 0.0,
            'categorical_coherence_variance': 0.0
        }

    def analyze_multiple_realities(self, quantum_metrics: Dict, words: List[str], use_restrictions: bool = True) -> Dict[str, float]:
        """åˆ†æå¤šé‡ç°å®ç°è±¡"""
        
        # è®¡ç®—è¯­è¨€å¤æ‚æ€§å› å­
        word_count = len(words)
        unique_words = len(set(words))
        word_diversity = unique_words / max(word_count, 1)
        
        # æƒ…æ„Ÿè¯ç»Ÿè®¡
        positive_count = sum(1 for word in words if word in self.emotion_lexicon['positive'])
        negative_count = sum(1 for word in words if word in self.emotion_lexicon['negative'])
        emotional_intensity = (positive_count + negative_count) / max(word_count, 1)
        
        # å¤šé‡ç°å®å¼ºåº¦
        reality_strength = (
            quantum_metrics['grammatical_superposition'] * 0.35 +
            quantum_metrics['semantic_interference'] * 0.25 +
            quantum_metrics['frame_competition'] * 0.20 +
            word_diversity * 0.20
        )
        
        # æ¡†æ¶å†²çªå¼ºåº¦
        conflict_strength = (
            quantum_metrics['compositional_entanglement'] * 0.40 +
            quantum_metrics['categorical_coherence_variance'] * 0.30 +
            emotional_intensity * 0.20 +
            (1.0 - quantum_metrics['category_coherence']) * 0.10
        )
        
        # è¯­ä¹‰æ¨¡ç³Šåº¦
        ambiguity = (
            quantum_metrics['von_neumann_entropy'] * 0.40 +
            quantum_metrics['semantic_interference'] * 0.30 +
            (1.0 - quantum_metrics['category_coherence']) * 0.20 +
            word_diversity * 0.10
        )
        
        # æ˜¯å¦åº”ç”¨é™åˆ¶
        if use_restrictions:
            return {
                'multiple_reality_strength': min(1.0, max(0.0, reality_strength)),
                'frame_conflict_strength': min(1.0, max(0.0, conflict_strength)),
                'semantic_ambiguity': min(1.0, max(0.0, ambiguity))
            }
        else:
            return {
                'multiple_reality_strength': float(reality_strength),
                'frame_conflict_strength': float(conflict_strength),
                'semantic_ambiguity': float(ambiguity)
            }

    def process_text(self, text: str, field: str, record_id: int, use_restrictions: bool = True) -> Dict[str, Any]:
        """å¤„ç†æ–‡æœ¬"""
        try:
            # åˆ†è¯å’Œè¯æ€§æ ‡æ³¨
            words, pos_tags = self.segment_and_pos_tag(text)
            
            if len(words) == 0:
                return None
            
            # è®¡ç®—é‡å­æŒ‡æ ‡
            quantum_metrics = self.calculate_quantum_metrics(words, pos_tags, use_restrictions)
            
            # åˆ†æå¤šé‡ç°å®
            reality_metrics = self.analyze_multiple_realities(quantum_metrics, words, use_restrictions)
            
            # åŸºæœ¬ç»Ÿè®¡
            word_count = len(words)
            unique_words = len(set(words))
            categorical_diversity = len(set(pos_tags))
            compositional_complexity = sum(1 for pos in pos_tags if pos.startswith('V'))
            semantic_density = unique_words / max(word_count, 1) * 10
            
            # ç»„åˆç»“æœ
            result = {
                'record_id': record_id,
                'field': field,
                'original_text': text[:200] + '...' if len(text) > 200 else text,
                'word_count': word_count,
                'unique_words': unique_words,
                'categorical_diversity': categorical_diversity,
                'compositional_complexity': compositional_complexity,
                'semantic_density': float(semantic_density),
                **quantum_metrics,
                **reality_metrics,
                'analysis_version': f'fair_comparison_{"restricted" if use_restrictions else "unrestricted"}_v1.0'
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡æœ¬æ—¶å‡ºé”™: {e}")
            return None

def analyze_ai_news(use_restrictions: bool = True):
    """åˆ†æAIæ–°é—»"""
    version_name = "å—é™åˆ¶" if use_restrictions else "æ— é™åˆ¶"
    print(f"ğŸ“° å¼€å§‹åˆ†æAIæ–°é—»ï¼ˆ{version_name}ç‰ˆæœ¬ï¼‰...")
    
    analyzer = FairComparisonAnalyzer()
    
    # åŠ è½½AIæ–°é—»æ•°æ®
    data_file = '../data/dataseet.xlsx'
    if not os.path.exists(data_file):
        print(f"âŒ æ‰¾ä¸åˆ°AIæ–°é—»æ•°æ®æ–‡ä»¶: {data_file}")
        return None
    
    df = pd.read_excel(data_file)
    df = df.dropna(subset=['æ–°èæ¨™é¡Œ', 'å½±ç‰‡å°è©±', 'å½±ç‰‡æè¿°'])
    df['record_id'] = range(len(df))
    
    print(f"ğŸ“Š AIæ–°é—»æ€»è®°å½•æ•°: {len(df)}")
    
    # å¤„ç†æ•°æ®
    all_results = []
    for idx, record in df.iterrows():
        try:
            record_dict = record.to_dict()
            record_id = record_dict.get('record_id', 0)
            
            # å¤„ç†ä¸‰ä¸ªå­—æ®µ
            title = str(record_dict.get('æ–°èæ¨™é¡Œ', ''))
            dialogue = str(record_dict.get('å½±ç‰‡å°è©±', ''))
            description = str(record_dict.get('å½±ç‰‡æè¿°', ''))
            
            if title and len(title.strip()) > 0:
                title_result = analyzer.process_text(title, 'æ–°èæ¨™é¡Œ', record_id, use_restrictions)
                if title_result:
                    all_results.append(title_result)
            
            if dialogue and len(dialogue.strip()) > 10:
                dialogue_result = analyzer.process_text(dialogue, 'å½±ç‰‡å°è©±', record_id, use_restrictions)
                if dialogue_result:
                    all_results.append(dialogue_result)
            
            if description and len(description.strip()) > 10:
                description_result = analyzer.process_text(description, 'å½±ç‰‡æè¿°', record_id, use_restrictions)
                if description_result:
                    all_results.append(description_result)
            
            if (idx + 1) % 50 == 0:
                print(f"ğŸ”„ å·²å¤„ç† {idx + 1}/{len(df)} æ¡AIæ–°é—»è®°å½•")
                
        except Exception as e:
            print(f"âŒ å¤„ç†AIæ–°é—»è®°å½• {idx} æ—¶å‡ºé”™: {e}")
            continue
    
    return pd.DataFrame(all_results) if all_results else pd.DataFrame()

def analyze_journalist_news(use_restrictions: bool = True):
    """åˆ†æè®°è€…æ–°é—»"""
    version_name = "å—é™åˆ¶" if use_restrictions else "æ— é™åˆ¶"
    print(f"ğŸ‘¨â€ğŸ’¼ å¼€å§‹åˆ†æè®°è€…æ–°é—»ï¼ˆ{version_name}ç‰ˆæœ¬ï¼‰...")
    
    analyzer = FairComparisonAnalyzer()
    
    # åŠ è½½è®°è€…æ–°é—»æ•°æ®
    data_file = '../data/cna.csv'
    if not os.path.exists(data_file):
        print(f"âŒ æ‰¾ä¸åˆ°è®°è€…æ–°é—»æ•°æ®æ–‡ä»¶: {data_file}")
        return None
    
    df = pd.read_csv(data_file)
    df = df.dropna(subset=['title', 'content'])
    df['record_id'] = range(len(df))
    
    print(f"ğŸ“Š è®°è€…æ–°é—»æ€»è®°å½•æ•°: {len(df)}")
    
    # å¤„ç†æ•°æ®
    all_results = []
    for idx, record in df.iterrows():
        try:
            record_dict = record.to_dict()
            record_id = record_dict.get('record_id', 0)
            
            # å¤„ç†ä¸¤ä¸ªå­—æ®µ
            title = str(record_dict.get('title', ''))
            content = str(record_dict.get('content', ''))
            
            if title and len(title.strip()) > 0:
                title_result = analyzer.process_text(title, 'æ–°èæ¨™é¡Œ', record_id, use_restrictions)
                if title_result:
                    all_results.append(title_result)
            
            if content and len(content.strip()) > 10:
                content_result = analyzer.process_text(content, 'æ–°èå…§å®¹', record_id, use_restrictions)
                if content_result:
                    all_results.append(content_result)
            
            if (idx + 1) % 5 == 0:
                print(f"ğŸ”„ å·²å¤„ç† {idx + 1}/{len(df)} æ¡è®°è€…æ–°é—»è®°å½•")
                
        except Exception as e:
            print(f"âŒ å¤„ç†è®°è€…æ–°é—»è®°å½• {idx} æ—¶å‡ºé”™: {e}")
            continue
    
    return pd.DataFrame(all_results) if all_results else pd.DataFrame()

def calculate_summary_stats(df: pd.DataFrame, data_type: str, version: str) -> Dict:
    """è®¡ç®—ç»Ÿè®¡æ‘˜è¦"""
    
    numeric_columns = [
        'von_neumann_entropy', 'category_coherence', 'compositional_entanglement',
        'grammatical_superposition', 'semantic_interference', 'frame_competition',
        'multiple_reality_strength', 'frame_conflict_strength', 'semantic_ambiguity'
    ]
    
    summary_stats = {}
    
    # æŒ‰å­—æ®µç»Ÿè®¡
    for field in df['field'].unique():
        field_data = df[df['field'] == field]
        if not field_data.empty:
            field_stats = {}
            for col in numeric_columns:
                if col in field_data.columns:
                    field_stats[col] = {
                        'mean': float(field_data[col].mean()),
                        'std': float(field_data[col].std()),
                        'min': float(field_data[col].min()),
                        'max': float(field_data[col].max())
                    }
            summary_stats[field] = field_stats
    
    # æ•´ä½“ç»Ÿè®¡
    overall_stats = {}
    for col in numeric_columns:
        if col in df.columns:
            overall_stats[col] = {
                'mean': float(df[col].mean()),
                'std': float(df[col].std()),
                'min': float(df[col].min()),
                'max': float(df[col].max())
            }
    summary_stats['overall'] = overall_stats
    
    return summary_stats

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ å¼€å§‹å…¬å¹³å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    print("ğŸ“‹ åˆ†æå¯¹æ¯”:")
    print("   AIæ•°æ®: æ–°èæ¨™é¡Œ, å½±ç‰‡å°è©±, å½±ç‰‡æè¿°")
    print("   CNAæ•°æ®: title (æ–°èæ¨™é¡Œ), content (æ–°èå…§å®¹)")
    print("   ç‰ˆæœ¬: å—é™åˆ¶ç‰ˆæœ¬ + æ— é™åˆ¶ç‰ˆæœ¬")
    print("=" * 80)
    
    start_time = time.time()
    
    # åˆ†ææ‰€æœ‰ç‰ˆæœ¬
    versions = [
        (True, "restricted", "å—é™åˆ¶"),
        (False, "unrestricted", "æ— é™åˆ¶")
    ]
    
    all_results = {}
    
    for use_restrictions, version_key, version_name in versions:
        print(f"\nğŸ”„ å¼€å§‹{version_name}ç‰ˆæœ¬åˆ†æ...")
        
        # åˆ†æAIæ–°é—»
        ai_results = analyze_ai_news(use_restrictions)
        if ai_results is not None and not ai_results.empty:
            print(f"âœ… AIæ–°é—»{version_name}åˆ†æå®Œæˆ: {len(ai_results)} æ¡è®°å½•")
            
            # ä¿å­˜AIæ–°é—»ç»“æœ
            ai_file = f'../results/fair_comparison_ai_{version_key}_results.csv'
            ai_results.to_csv(ai_file, index=False, encoding='utf-8')
            
            # è®¡ç®—AIæ–°é—»ç»Ÿè®¡
            ai_stats = calculate_summary_stats(ai_results, 'ai', version_key)
            ai_stats_file = f'../results/fair_comparison_ai_{version_key}_summary.json'
            with open(ai_stats_file, 'w', encoding='utf-8') as f:
                json.dump(ai_stats, f, ensure_ascii=False, indent=2)
            
            all_results[f'ai_{version_key}'] = {
                'data': ai_results,
                'stats': ai_stats,
                'file': ai_file,
                'stats_file': ai_stats_file
            }
        
        # åˆ†æè®°è€…æ–°é—»
        journalist_results = analyze_journalist_news(use_restrictions)
        if journalist_results is not None and not journalist_results.empty:
            print(f"âœ… è®°è€…æ–°é—»{version_name}åˆ†æå®Œæˆ: {len(journalist_results)} æ¡è®°å½•")
            
            # ä¿å­˜è®°è€…æ–°é—»ç»“æœ
            journalist_file = f'../results/fair_comparison_journalist_{version_key}_results.csv'
            journalist_results.to_csv(journalist_file, index=False, encoding='utf-8')
            
            # è®¡ç®—è®°è€…æ–°é—»ç»Ÿè®¡
            journalist_stats = calculate_summary_stats(journalist_results, 'journalist', version_key)
            journalist_stats_file = f'../results/fair_comparison_journalist_{version_key}_summary.json'
            with open(journalist_stats_file, 'w', encoding='utf-8') as f:
                json.dump(journalist_stats, f, ensure_ascii=False, indent=2)
            
            all_results[f'journalist_{version_key}'] = {
                'data': journalist_results,
                'stats': journalist_stats,
                'file': journalist_file,
                'stats_file': journalist_stats_file
            }
    
    # æ˜¾ç¤ºå…³é”®ç»“æœå¯¹æ¯”
    print("\nğŸ” å…³é”®ç»“æœå¯¹æ¯”é¢„è§ˆ:")
    print("=" * 80)
    
    if 'ai_restricted' in all_results and 'journalist_restricted' in all_results:
        ai_restricted_title = all_results['ai_restricted']['stats']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
        journalist_restricted_title = all_results['journalist_restricted']['stats']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
        
        print(f"ğŸ“ˆ å—é™åˆ¶ç‰ˆæœ¬ - è¯­æ³•å åŠ å¼ºåº¦ï¼ˆæ–°èæ¨™é¡Œï¼‰:")
        print(f"   AIæ–°é—»:     {ai_restricted_title:.6f}")
        print(f"   è®°è€…æ–°é—»:   {journalist_restricted_title:.6f}")
        print(f"   å·®å¼‚å€æ•°:   {ai_restricted_title/journalist_restricted_title:.2f}Ã—")
    
    if 'ai_unrestricted' in all_results and 'journalist_unrestricted' in all_results:
        ai_unrestricted_title = all_results['ai_unrestricted']['stats']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
        journalist_unrestricted_title = all_results['journalist_unrestricted']['stats']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
        
        print(f"\nğŸ“ˆ æ— é™åˆ¶ç‰ˆæœ¬ - è¯­æ³•å åŠ å¼ºåº¦ï¼ˆæ–°èæ¨™é¡Œï¼‰:")
        print(f"   AIæ–°é—»:     {ai_unrestricted_title:.6f}")
        print(f"   è®°è€…æ–°é—»:   {journalist_unrestricted_title:.6f}")
        print(f"   å·®å¼‚å€æ•°:   {ai_unrestricted_title/journalist_unrestricted_title:.2f}Ã—")
    
    # ä¿å­˜ç»¼åˆç»“æœæ‘˜è¦
    summary = {
        'analysis_info': {
            'ai_fields': ['æ–°èæ¨™é¡Œ', 'å½±ç‰‡å°è©±', 'å½±ç‰‡æè¿°'],
            'journalist_fields': ['æ–°èæ¨™é¡Œ', 'æ–°èå…§å®¹'],
            'versions': ['restricted', 'unrestricted'],
            'analysis_date': '2024-09-26'
        },
        'file_mapping': {key: val['file'] for key, val in all_results.items()},
        'stats_mapping': {key: val['stats_file'] for key, val in all_results.items()}
    }
    
    summary_file = '../results/fair_comparison_analysis_summary.json'
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    # æ€§èƒ½ç»Ÿè®¡
    total_time = time.time() - start_time
    total_records = sum(len(result['data']) for result in all_results.values())
    
    print(f"\nâœ… å…¬å¹³å¯¹æ¯”åˆ†æå®Œæˆ!")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
    print(f"ğŸš€ å¤„ç†é€Ÿåº¦: {total_records/total_time:.1f} è®°å½•/ç§’")
    print(f"ğŸ“ˆ æ€»å¤„ç†è®°å½•: {total_records} æ¡")
    print(f"ğŸ“„ ç»¼åˆæ‘˜è¦: {summary_file}")

if __name__ == "__main__":
    main()

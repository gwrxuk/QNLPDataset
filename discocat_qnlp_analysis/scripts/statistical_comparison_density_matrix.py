#!/usr/bin/env python3
"""
çµ±è¨ˆæ¯”è¼ƒåˆ†æå™¨ - å¯†åº¦çŸ©é™£ç‰ˆæœ¬çµæœ
è¨ˆç®— Cohen's d å’Œçµ±è¨ˆé¡¯è‘—æ€§
"""

import pandas as pd
import numpy as np
import json
import scipy.stats as stats
from pathlib import Path
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# å°å…¥çµ±è¨ˆæ¯”è¼ƒåˆ†æå™¨é¡
import sys
sys.path.append(str(Path(__file__).parent))
from statistical_comparison_analyzer import StatisticalComparisonAnalyzer

def main():
    """ä¸»å‡½æ•¸ - åˆ†æå¯†åº¦çŸ©é™£ç‰ˆæœ¬çµæœ"""
    print("ğŸš€ é–‹å§‹çµ±è¨ˆæ¯”è¼ƒåˆ†æï¼ˆå¯†åº¦çŸ©é™£ç‰ˆæœ¬ï¼‰...")
    print("=" * 80)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = StatisticalComparisonAnalyzer()
    
    # è®€å–æ•¸æ“š
    print("ğŸ“Š è®€å–æ•¸æ“š...")
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    output_dir = project_root / '20251113_densityMatrix'
    
    ai_data_path = output_dir / 'results' / 'density_matrix_ai_analysis_results.csv'
    journalist_data_path = output_dir / 'results' / 'density_matrix_journalist_analysis_results.csv'
    
    if not ai_data_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ° AI æ•¸æ“šæ–‡ä»¶: {ai_data_path}")
        return
    
    if not journalist_data_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è¨˜è€…æ•¸æ“šæ–‡ä»¶: {journalist_data_path}")
        return
    
    ai_data = pd.read_csv(ai_data_path)
    journalist_data = pd.read_csv(journalist_data_path)
    
    print(f"âœ… AI æ•¸æ“š: {len(ai_data)} æ¢è¨˜éŒ„")
    print(f"âœ… è¨˜è€…æ•¸æ“š: {len(journalist_data)} æ¢è¨˜éŒ„")
    
    # å­—æ®µæ˜ å°„ï¼šå°‡è¨˜è€…çš„ã€Œæ–°èå…§å®¹ã€å°æ‡‰åˆ°å¤šå€‹ AI å­—æ®µé€²è¡Œæ¯”è¼ƒ
    # æ˜ å°„ 1: æ–°èå…§å®¹ -> å½±ç‰‡æè¿°
    # æ˜ å°„ 2: æ–°èå…§å®¹ -> å½±ç‰‡å°è©± (éœ€è¦å‰µå»ºé¡å¤–çš„æ˜ å°„)
    field_mapping = {
        'æ–°èå…§å®¹': 'å½±ç‰‡æè¿°'  # è¨˜è€…å­—æ®µ -> AI å­—æ®µï¼ˆä¸»è¦æ˜ å°„ï¼‰
    }
    
    # å‰µå»ºè¨˜è€…æ•¸æ“šçš„å‰¯æœ¬ä¸¦æ‡‰ç”¨å­—æ®µæ˜ å°„
    journalist_data_mapped = journalist_data.copy()
    journalist_data_mapped['field'] = journalist_data_mapped['field'].replace(field_mapping)
    
    # ç‚ºã€Œå½±ç‰‡å°è©± vs æ–°èå…§å®¹ã€å‰µå»ºé¡å¤–çš„æ˜ å°„æ•¸æ“š
    # å‰µå»ºç¬¬äºŒå€‹å‰¯æœ¬ï¼Œå°‡ã€Œæ–°èå…§å®¹ã€æ˜ å°„åˆ°ã€Œå½±ç‰‡å°è©±ã€
    journalist_data_mapped_dialogue = journalist_data.copy()
    journalist_data_mapped_dialogue['field'] = journalist_data_mapped_dialogue['field'].replace({
        'æ–°èå…§å®¹': 'å½±ç‰‡å°è©±'  # æ–°èå…§å®¹ -> å½±ç‰‡å°è©±
    })
    
    print(f"\nğŸ“‹ å­—æ®µæ˜ å°„:")
    for old_field, new_field in field_mapping.items():
        print(f"  {old_field} â†’ {new_field}")
    
    print(f"\nğŸ“Š æ˜ å°„å¾Œçš„è¨˜è€…æ•¸æ“šå­—æ®µï¼ˆæ˜ å°„1: æ–°èå…§å®¹â†’å½±ç‰‡æè¿°ï¼‰: {sorted(journalist_data_mapped['field'].unique())}")
    print(f"ğŸ“Š æ˜ å°„å¾Œçš„è¨˜è€…æ•¸æ“šå­—æ®µï¼ˆæ˜ å°„2: æ–°èå…§å®¹â†’å½±ç‰‡å°è©±ï¼‰: {sorted(journalist_data_mapped_dialogue['field'].unique())}")
    print(f"ğŸ“Š AI æ•¸æ“šå­—æ®µ: {sorted(ai_data['field'].unique())}")
    
    # æ•´é«”æ¯”è¼ƒï¼ˆä½¿ç”¨æ˜ å°„å¾Œçš„æ•¸æ“šï¼‰
    print("\nğŸ“ˆ åŸ·è¡Œæ•´é«”æ¯”è¼ƒ...")
    overall_results = analyzer.compare_groups(ai_data, journalist_data_mapped)
    
    # æŒ‰å­—æ®µæ¯”è¼ƒï¼ˆä½¿ç”¨æ˜ å°„å¾Œçš„æ•¸æ“šï¼‰
    print("ğŸ“ˆ åŸ·è¡ŒæŒ‰å­—æ®µæ¯”è¼ƒ...")
    field_results = {}
    
    # æ˜ å°„1: æ–°èå…§å®¹ -> å½±ç‰‡æè¿°
    for field in ai_data['field'].unique():
        if field in journalist_data_mapped['field'].values:
            print(f"  - æ¯”è¼ƒå­—æ®µ: {field} (å°æ‡‰è¨˜è€…: {[k for k, v in field_mapping.items() if v == field] if field in field_mapping.values() else 'æ–°èæ¨™é¡Œ'})")
            field_results[field] = analyzer.compare_groups(ai_data, journalist_data_mapped, field=field)
    
    # æ˜ å°„2: æ–°èå…§å®¹ -> å½±ç‰‡å°è©±ï¼ˆç‰¹æ®Šè™•ç†ï¼‰
    dialogue_field = 'å½±ç‰‡å°è©±'
    if dialogue_field in ai_data['field'].values and 'æ–°èå…§å®¹' in journalist_data['field'].values:
        print(f"  - æ¯”è¼ƒå­—æ®µ: {dialogue_field} (å°æ‡‰è¨˜è€…: æ–°èå…§å®¹)")
        field_results[f'{dialogue_field}_vs_æ–°èå…§å®¹'] = analyzer.compare_groups(
            ai_data, journalist_data_mapped_dialogue, field=dialogue_field
        )
    
    # ç”Ÿæˆå ±å‘Š
    print("\nğŸ“„ ç”Ÿæˆå ±å‘Š...")
    reports_dir = output_dir / 'reports'
    reports_dir.mkdir(exist_ok=True)
    
    # æ•´é«”å ±å‘Š
    overall_report_path = reports_dir / 'statistical_comparison_report.md'
    analyzer.generate_report(overall_results, str(overall_report_path))
    
    # æŒ‰å­—æ®µå ±å‘Š
    for field, results in field_results.items():
        # è™•ç†ç‰¹æ®Šå‘½åçš„å­—æ®µï¼ˆå¦‚ å½±ç‰‡å°è©±_vs_æ–°èå…§å®¹ï¼‰
        report_field_name = field.replace('_vs_', '_vs_').replace(' ', '_')
        field_report_path = reports_dir / f'statistical_comparison_report_{report_field_name}.md'
        analyzer.generate_report(results, str(field_report_path))
    
    # ä¿å­˜ JSON çµæœ
    json_output = {
        'overall': overall_results,
        'by_field': field_results,
        'field_mapping': {
            'æ–°èå…§å®¹â†’å½±ç‰‡æè¿°': 'ä¸»è¦æ˜ å°„',
            'æ–°èå…§å®¹â†’å½±ç‰‡å°è©±': 'é¡å¤–æ˜ å°„ï¼ˆAI å½±ç‰‡å°è©± vs è¨˜è€…æ–°èå…§å®¹ï¼‰'
        },
        'analysis_method': 'density_matrix',
        'description': 'ä½¿ç”¨å¯†åº¦çŸ©é™£ (Ï = |ÏˆâŸ©âŸ¨Ïˆ|) è¨ˆç®— von Neumann ç†µ'
    }
    
    json_output_path = reports_dir / 'statistical_comparison_results.json'
    with open(json_output_path, 'w', encoding='utf-8') as f:
        json.dump(json_output, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"âœ… JSON çµæœå·²ä¿å­˜: {json_output_path}")
    
    # é¡¯ç¤ºé—œéµçµæœ
    print("\nğŸ” é—œéµçµæœ:")
    print("=" * 80)
    for metric, result in overall_results.items():
        print(f"\n{result['metric_name']}:")
        print(f"  Cohen's d = {result['cohens_d']:.4f} ({result['effect_size_interpretation']}æ•ˆæ‡‰)")
        print(f"  t æª¢é©—: p = {result['t_test']['p_value']:.4e}, é¡¯è‘— = {result['t_test']['significant']}")
        print(f"  è®Šç•°æ€§æ¯”ç‡ = {result['variability_ratio']:.4f}")
    
    print("\nâœ… çµ±è¨ˆæ¯”è¼ƒåˆ†æå®Œæˆ!")
    print(f"ğŸ“„ å ±å‘Šå·²ä¿å­˜: {overall_report_path}")

if __name__ == "__main__":
    main()


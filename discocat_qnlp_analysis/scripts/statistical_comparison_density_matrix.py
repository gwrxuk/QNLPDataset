#!/usr/bin/env python3
"""
çµ±è¨ˆæ¯”è¼ƒåˆ†æå™¨ - å¯†åº¦çŸ©é™£ç‰ˆæœ¬çµæœ
è¨ˆç®— Cohen's d å’Œçµ±è¨ˆé¡¯è‘—æ€§
"""

import pandas as pd
import numpy as np
import json
import scipy.stats as stats
from pathlib import Path
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# å°å…¥çµ±è¨ˆæ¯”è¼ƒåˆ†æå™¨é¡
import sys
sys.path.append(str(Path(__file__).parent))
from statistical_comparison_analyzer import StatisticalComparisonAnalyzer

def main():
    """ä¸»å‡½æ•¸ - åˆ†æå¯†åº¦çŸ©é™£ç‰ˆæœ¬çµæœ"""
    print("ğŸš€ é–‹å§‹çµ±è¨ˆæ¯”è¼ƒåˆ†æï¼ˆå¯†åº¦çŸ©é™£ç‰ˆæœ¬ï¼‰...")
    print("=" * 80)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = StatisticalComparisonAnalyzer()
    
    # è®€å–æ•¸æ“š
    print("ğŸ“Š è®€å–æ•¸æ“š...")
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    output_dir = project_root / '20251113_densityMatrix'
    
    ai_data_path = output_dir / 'results' / 'density_matrix_ai_analysis_results.csv'
    journalist_data_path = output_dir / 'results' / 'density_matrix_journalist_analysis_results.csv'
    
    if not ai_data_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ° AI æ•¸æ“šæ–‡ä»¶: {ai_data_path}")
        return
    
    if not journalist_data_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è¨˜è€…æ•¸æ“šæ–‡ä»¶: {journalist_data_path}")
        return
    
    ai_data = pd.read_csv(ai_data_path)
    journalist_data = pd.read_csv(journalist_data_path)
    
    print(f"âœ… AI æ•¸æ“š: {len(ai_data)} æ¢è¨˜éŒ„")
    print(f"âœ… è¨˜è€…æ•¸æ“š: {len(journalist_data)} æ¢è¨˜éŒ„")
    
    # æ•´é«”æ¯”è¼ƒ
    print("\nğŸ“ˆ åŸ·è¡Œæ•´é«”æ¯”è¼ƒ...")
    overall_results = analyzer.compare_groups(ai_data, journalist_data)
    
    # æŒ‰å­—æ®µæ¯”è¼ƒ
    print("ğŸ“ˆ åŸ·è¡ŒæŒ‰å­—æ®µæ¯”è¼ƒ...")
    field_results = {}
    for field in ai_data['field'].unique():
        if field in journalist_data['field'].values:
            print(f"  - æ¯”è¼ƒå­—æ®µ: {field}")
            field_results[field] = analyzer.compare_groups(ai_data, journalist_data, field=field)
    
    # ç”Ÿæˆå ±å‘Š
    print("\nğŸ“„ ç”Ÿæˆå ±å‘Š...")
    reports_dir = output_dir / 'reports'
    reports_dir.mkdir(exist_ok=True)
    
    # æ•´é«”å ±å‘Š
    overall_report_path = reports_dir / 'statistical_comparison_report.md'
    analyzer.generate_report(overall_results, str(overall_report_path))
    
    # æŒ‰å­—æ®µå ±å‘Š
    for field, results in field_results.items():
        field_report_path = reports_dir / f'statistical_comparison_report_{field}.md'
        analyzer.generate_report(results, str(field_report_path))
    
    # ä¿å­˜ JSON çµæœ
    json_output = {
        'overall': overall_results,
        'by_field': field_results,
        'analysis_method': 'density_matrix',
        'description': 'ä½¿ç”¨å¯†åº¦çŸ©é™£ (Ï = |ÏˆâŸ©âŸ¨Ïˆ|) è¨ˆç®— von Neumann ç†µ'
    }
    
    json_output_path = reports_dir / 'statistical_comparison_results.json'
    with open(json_output_path, 'w', encoding='utf-8') as f:
        json.dump(json_output, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"âœ… JSON çµæœå·²ä¿å­˜: {json_output_path}")
    
    # é¡¯ç¤ºé—œéµçµæœ
    print("\nğŸ” é—œéµçµæœ:")
    print("=" * 80)
    for metric, result in overall_results.items():
        print(f"\n{result['metric_name']}:")
        print(f"  Cohen's d = {result['cohens_d']:.4f} ({result['effect_size_interpretation']}æ•ˆæ‡‰)")
        print(f"  t æª¢é©—: p = {result['t_test']['p_value']:.4e}, é¡¯è‘— = {result['t_test']['significant']}")
        print(f"  è®Šç•°æ€§æ¯”ç‡ = {result['variability_ratio']:.4f}")
    
    print("\nâœ… çµ±è¨ˆæ¯”è¼ƒåˆ†æå®Œæˆ!")
    print(f"ğŸ“„ å ±å‘Šå·²ä¿å­˜: {overall_report_path}")

if __name__ == "__main__":
    main()


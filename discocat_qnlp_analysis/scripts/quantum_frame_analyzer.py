#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Quantum Frame Analyzer - Real Implementation
===========================================

Implements the actual quantum frame calculations described in the analysis report,
using real quantum state representations for semantic, narrative, evaluative, and contextual frames.

Author: QNLP Research Team
Date: 2025-01-27
"""

import pandas as pd
import numpy as np
import json
import time
import os
from typing import Dict, List, Tuple, Any
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings('ignore')

# Quantum computing frameworks
from qiskit import QuantumCircuit, execute, Aer
from qiskit.quantum_info import entropy, Statevector, DensityMatrix
from qiskit.circuit.library import RYGate, CXGate, HGate, RZGate

# NLP tools
import jieba
import jieba.posseg as pseg
from sklearn.feature_extraction.text import TfidfVectorizer
import ast
import re

class QuantumFrameAnalyzer:
    """
    Real quantum frame analyzer implementing the theoretical framework
    described in the analysis report.
    """
    
    def __init__(self):
        """Initialize the quantum frame analyzer with real frame lexicons."""
        
        self.backend = Aer.get_backend('statevector_simulator')
        
        # Emotion frame lexicons with quantum weights
        self.positive_emotion_lexicon = {
            'å¸Œæœ›': 0.85, 'ä¿¡å¿ƒ': 0.90, 'æ¨‚è§€': 0.88, 'æŒ¯å¥®': 0.92, 'é¼“èˆ': 0.89,
            'æ‰¿è«¾': 0.75, 'æ”¹å–„': 0.78, 'æå‡': 0.82, 'é€²æ­¥': 0.85, 'æˆåŠŸ': 0.90,
            'ç©æ¥µ': 0.87, 'æ­£é¢': 0.83, 'è‰¯å¥½': 0.80, 'å„ªç§€': 0.88, 'å“è¶Š': 0.95,
            'æ¨å‹•': 0.80, 'ä¿ƒé€²': 0.82, 'åŠ å¼·': 0.78, 'å¢å¼·': 0.85, 'ç™¼å±•': 0.75
        }
        
        self.negative_emotion_lexicon = {
            'æ†¤æ€’': 0.90, 'å¤±æœ›': 0.85, 'æ“”æ†‚': 0.80, 'ææ‡¼': 0.88, 'ä¸æ»¿': 0.82,
            'æ‰¹è©•': 0.78, 'è³ªç–‘': 0.75, 'åå°': 0.85, 'æŠ—è­°': 0.88, 'è­´è²¬': 0.92,
            'å±æ©Ÿ': 0.85, 'å•é¡Œ': 0.70, 'å›°é›£': 0.75, 'æŒ‘æˆ°': 0.65, 'çˆ­è­°': 0.80,
            'è¡çª': 0.85, 'å‹•ç›ª': 0.88, 'æ··äº‚': 0.90, 'ç½é›£': 0.95, 'æ‚²åŠ‡': 0.92
        }
        
        # Reform frame lexicons with semantic vectors
        self.reform_lexicon = {
            'æ”¹é©': {'positive': 0.6, 'reactive': 0.3, 'superficial': 0.1},
            'é©æ–°': {'positive': 0.9, 'reactive': 0.1, 'superficial': 0.0},
            'è®Šé©': {'positive': 0.8, 'reactive': 0.2, 'superficial': 0.0},
            'æ”¹å–„': {'positive': 0.85, 'reactive': 0.15, 'superficial': 0.0},
            'æå‡': {'positive': 0.9, 'reactive': 0.1, 'superficial': 0.0},
            'èª¿æ•´': {'positive': 0.3, 'reactive': 0.6, 'superficial': 0.1},
            'æ•´é “': {'positive': 0.4, 'reactive': 0.5, 'superficial': 0.1},
            'å®£ç¨±': {'positive': 0.1, 'reactive': 0.2, 'superficial': 0.7},
            'è²ç¨±': {'positive': 0.1, 'reactive': 0.3, 'superficial': 0.6},
            'è¡¨ç¤º': {'positive': 0.2, 'reactive': 0.4, 'superficial': 0.4}
        }
        
        # Context modifiers
        self.context_modifiers = {
            'crisis_response': {'positive': 0.7, 'reactive': 1.3, 'superficial': 1.2},
            'proactive_planning': {'positive': 1.2, 'reactive': 0.8, 'superficial': 0.6},
            'public_pressure': {'positive': 0.8, 'reactive': 1.1, 'superficial': 1.3},
            'normal': {'positive': 1.0, 'reactive': 1.0, 'superficial': 1.0}
        }
        
        # Syntactic patterns
        self.active_patterns = ['ä¸»å‹•', 'ç©æ¥µ', 'åŠªåŠ›', 'æ¨å‹•', 'ä¿ƒé€²', 'åŠ å¼·']
        self.future_markers = ['å°‡', 'æœƒ', 'è¦', 'æº–å‚™', 'è¨ˆåŠƒ', 'å³å°‡', 'æœªä¾†']
        self.causation_direct = ['å°è‡´', 'é€ æˆ', 'å¼•ç™¼', 'ç”¢ç”Ÿ', 'å¸¶ä¾†', 'ä½¿å¾—']
        self.causation_indirect = ['é—œè¯', 'ç›¸é—œ', 'æ¶‰åŠ', 'ç‰½æ¶‰', 'å½±éŸ¿', 'é€£çµ']
        
        print("ğŸ”¬ é‡å­æ¡†æ¶åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        print("âœ… æƒ…æ„Ÿè©å…¸è¼‰å…¥å®Œæˆ")
        print("âœ… èªç¾©æ¡†æ¶è©å…¸è¼‰å…¥å®Œæˆ")
        print("âœ… èªæ³•æ¨¡å¼è­˜åˆ¥å™¨æº–å‚™å°±ç·’")

    def extract_emotion_features(self, text: str) -> Tuple[float, float, int]:
        """å¾æ–‡æœ¬ä¸­æå–æƒ…æ„Ÿç‰¹å¾µ"""
        positive_score = 0.0
        negative_score = 0.0
        positive_count = 0
        negative_count = 0
        
        words = list(jieba.cut(text))
        
        for word in words:
            if word in self.positive_emotion_lexicon:
                positive_score += self.positive_emotion_lexicon[word]
                positive_count += 1
            elif word in self.negative_emotion_lexicon:
                negative_score += self.negative_emotion_lexicon[word]
                negative_count += 1
        
        # æ­£è¦åŒ–æƒ…æ„Ÿå¼·åº¦
        positive_intensity = positive_score / max(1, positive_count) if positive_count > 0 else 0.0
        negative_intensity = negative_score / max(1, negative_count) if negative_count > 0 else 0.0
        
        return positive_intensity, negative_intensity, len(words)

    def analyze_syntactic_patterns(self, text: str, pos_tags: List[str]) -> Tuple[float, float, str]:
        """åˆ†æèªæ³•æ¨¡å¼å°æ¡†æ¶çš„è²¢ç»"""
        
        # ä¸»å‹•èªæ…‹å¢å¼·æ­£é¢æƒ…æ„Ÿ
        active_voice_bonus = 0.0
        for pattern in self.active_patterns:
            if pattern in text:
                active_voice_bonus += 0.1
        
        # æœªä¾†æ™‚æ…‹å¢å¼·æ­£é¢æœŸå¾…
        future_tense_bonus = 0.0
        for marker in self.future_markers:
            if marker in text:
                future_tense_bonus += 0.05
        
        # åˆ¤æ–·ä¸Šä¸‹æ–‡é¡å‹
        context_type = 'normal'
        if any(word in text for word in ['å±æ©Ÿ', 'é†œè', 'äº‹ä»¶', 'æ¡ˆä»¶']):
            context_type = 'crisis_response'
        elif any(word in text for word in ['è¨ˆåŠƒ', 'ç­–ç•¥', 'è¦åŠƒ', 'æœªä¾†']):
            context_type = 'proactive_planning'
        elif any(word in text for word in ['å£“åŠ›', 'è¦æ±‚', 'å‘¼ç±²', 'æŠ—è­°']):
            context_type = 'public_pressure'
        
        return active_voice_bonus, future_tense_bonus, context_type

    def construct_emotion_quantum_state(self, text: str) -> Tuple[np.ndarray, Dict]:
        """æ§‹å»ºæƒ…æ„Ÿæ¡†æ¶çš„é‡å­æ…‹"""
        
        # è©æ€§æ¨™è¨»
        pos_tags = [pair.flag for pair in pseg.cut(text)]
        
        # æå–åŸºç¤ç‰¹å¾µ
        positive_intensity, negative_intensity, word_count = self.extract_emotion_features(text)
        active_bonus, future_bonus, context_type = self.analyze_syntactic_patterns(text, pos_tags)
        
        # è¨ˆç®—é‡å­æ…‹æŒ¯å¹…
        positive_base = min(1.0, positive_intensity)
        negative_base = min(1.0, negative_intensity)
        
        # èªæ³•ä¿®æ­£
        syntactic_modifier = 1.0 + active_bonus + future_bonus
        positive_amplitude = positive_base * syntactic_modifier
        negative_amplitude = negative_base
        
        # ä¸­æ€§æˆåˆ†
        neutral_amplitude = max(0.1, 1.0 - positive_intensity - negative_intensity)
        
        # æ­£è¦åŒ–
        raw_amplitudes = np.array([positive_amplitude, neutral_amplitude, negative_amplitude])
        norm = np.linalg.norm(raw_amplitudes)
        
        if norm > 0:
            emotion_state = raw_amplitudes / norm
        else:
            emotion_state = np.array([0.33, 0.34, 0.33])  # å‡å‹»åˆ†å¸ƒ
        
        metadata = {
            'positive_intensity': positive_intensity,
            'negative_intensity': negative_intensity,
            'active_voice_bonus': active_bonus,
            'future_tense_bonus': future_bonus,
            'context_type': context_type,
            'syntactic_modifier': syntactic_modifier,
            'word_count': word_count
        }
        
        return emotion_state, metadata

    def construct_reform_quantum_state(self, text: str, context_type: str = 'normal') -> Tuple[np.ndarray, Dict]:
        """æ§‹å»ºæ”¹é©æ¡†æ¶çš„é‡å­æ…‹"""
        
        semantic_scores = {'positive': 0.0, 'reactive': 0.0, 'superficial': 0.0}
        word_count = 0
        
        words = list(jieba.cut(text))
        
        for word in words:
            if word in self.reform_lexicon:
                word_count += 1
                for frame_type in semantic_scores:
                    semantic_scores[frame_type] += self.reform_lexicon[word][frame_type]
        
        # æ‡‰ç”¨ä¸Šä¸‹æ–‡ä¿®æ­£
        if context_type in self.context_modifiers:
            for frame_type in semantic_scores:
                semantic_scores[frame_type] *= self.context_modifiers[context_type][frame_type]
        
        # æ§‹å»ºé‡å­æ…‹å‘é‡
        total_score = sum(semantic_scores.values())
        if total_score > 0:
            reform_state = np.array([
                semantic_scores['positive'] / total_score,
                semantic_scores['reactive'] / total_score,
                semantic_scores['superficial'] / total_score
            ])
        else:
            reform_state = np.array([0.33, 0.33, 0.34])  # å‡å‹»åˆ†å¸ƒ
        
        metadata = {
            'reform_word_count': word_count,
            'context_type': context_type,
            'raw_scores': semantic_scores,
            'total_score': total_score
        }
        
        return reform_state, metadata

    def create_quantum_circuit_with_frames(self, emotion_state: np.ndarray, reform_state: np.ndarray, 
                                         text_complexity: float) -> QuantumCircuit:
        """å‰µå»ºåŒ…å«æ¡†æ¶ä¿¡æ¯çš„é‡å­é›»è·¯"""
        
        # ç¢ºå®šé›»è·¯å¤§å°
        num_qubits = 6  # 3 for emotion, 3 for reform
        circuit = QuantumCircuit(num_qubits)
        
        # åˆå§‹åŒ–æƒ…æ„Ÿæ¡†æ¶é‡å­æ¯”ç‰¹ (0,1,2)
        for i in range(3):
            if emotion_state[i] > 0.1:  # åªç‚ºé¡¯è‘—æŒ¯å¹…å‰µå»ºç–ŠåŠ 
                angle = 2 * np.arcsin(np.sqrt(emotion_state[i]))
                circuit.ry(angle, i)
        
        # åˆå§‹åŒ–æ”¹é©æ¡†æ¶é‡å­æ¯”ç‰¹ (3,4,5)
        for i in range(3):
            if reform_state[i] > 0.1:
                angle = 2 * np.arcsin(np.sqrt(reform_state[i]))
                circuit.ry(angle, i + 3)
        
        # å‰µå»ºæ¡†æ¶é–“ç³¾çº
        entanglement_strength = min(np.pi/4, text_complexity * np.pi / 8)
        
        # æƒ…æ„Ÿ-æ”¹é©æ¡†æ¶ç³¾çº
        circuit.cx(0, 3)  # positive emotion - positive reform
        circuit.cx(2, 5)  # negative emotion - superficial reform
        
        # æ·»åŠ ç›¸ä½é—œä¿‚
        if entanglement_strength > 0.1:
            circuit.crz(entanglement_strength, 1, 4)  # neutral-reactive correlation
        
        return circuit

    def measure_quantum_frame_properties(self, circuit: QuantumCircuit, 
                                       emotion_state: np.ndarray, 
                                       reform_state: np.ndarray) -> Dict[str, float]:
        """æ¸¬é‡é‡å­æ¡†æ¶ç‰¹æ€§"""
        
        try:
            # åŸ·è¡Œé‡å­é›»è·¯
            job = execute(circuit, self.backend, shots=1024)
            result = job.result()
            statevector = result.get_statevector()
            
            state_array = np.array(statevector.data)
            probabilities = np.abs(state_array) ** 2
            valid_probs = probabilities[probabilities > 1e-12]
            
            metrics = {}
            
            # 1. æ¡†æ¶ç«¶çˆ­å¼·åº¦
            metrics['frame_competition'] = float(min(1.0, entropy_val * 0.5))
            if len(valid_probs) > 1:
                uniform_prob = 1.0 / len(valid_probs)
                kl_divergence = np.sum(valid_probs * np.log2((valid_probs + 1e-12) / uniform_prob))
                max_kl = np.log2(len(valid_probs))
                metrics['frame_competition_kl'] = float(1.0 - min(1.0, kl_divergence / max_kl))
            else:
                metrics['frame_competition_kl'] = 0.0
            
            # 2. æƒ…æ„Ÿæ¡†æ¶å¼·åº¦
            emotion_prob_sum = np.sum(probabilities[:8])  # å‰8å€‹ç‹€æ…‹å°æ‡‰æƒ…æ„Ÿæ¡†æ¶
            metrics['emotion_frame_strength'] = float(emotion_prob_sum)
            
            # 3. æ”¹é©æ¡†æ¶å¼·åº¦  
            reform_prob_sum = np.sum(probabilities[32:40])  # å°æ‡‰æ”¹é©æ¡†æ¶çš„ç‹€æ…‹
            metrics['reform_frame_strength'] = float(reform_prob_sum)
            
            # 4. æ¡†æ¶ç³¾çºå¼·åº¦
            if circuit.num_qubits >= 2:
                try:
                    # ç°¡åŒ–çš„ç³¾çºæ¸¬é‡
                    entanglement_measure = np.var(probabilities) * 4
                    metrics['frame_entanglement'] = float(min(1.0, entanglement_measure))
                except:
                    metrics['frame_entanglement'] = 0.3
            else:
                metrics['frame_entanglement'] = 0.2
            
            # 5. é¦®Â·ç´æ›¼ç†µ
            entropy_val = -np.sum(valid_probs * np.log2(valid_probs + 1e-12))
            metrics['von_neumann_entropy'] = float(entropy_val / np.log2(len(valid_probs)))
            
            # 6. èªç¾©å¹²æ¶‰
            phases = np.angle(state_array)
            phase_variance = np.var(phases)
            metrics['semantic_interference'] = float(min(1.0, phase_variance / (np.pi**2)))
            
            return metrics
            
        except Exception as e:
            print(f"âš ï¸  é‡å­æ¸¬é‡éŒ¯èª¤: {e}")
            return self._get_default_metrics()

    def _get_default_metrics(self) -> Dict[str, float]:
        """è¿”å›é è¨­é‡å­æŒ‡æ¨™"""
        return {
            'frame_competition': 0.5,
            'frame_competition_kl': 0.5,
            'frame_competition_kl': 0.5,
            'emotion_frame_strength': 0.5,
            'reform_frame_strength': 0.5,
            'frame_entanglement': 0.3,
            'von_neumann_entropy': 0.5,
            'semantic_interference': 0.4
        }

    def analyze_multiple_realities_with_frames(self, quantum_metrics: Dict, 
                                             emotion_metadata: Dict, 
                                             reform_metadata: Dict) -> Dict[str, float]:
        """åŸºæ–¼çœŸå¯¦é‡å­æ¡†æ¶åˆ†æå¤šé‡ç¾å¯¦"""
        
        # æ¡†æ¶å¤šæ¨£æ€§
        frame_diversity = 0.0
        if emotion_metadata['positive_intensity'] > 0.1:
            frame_diversity += 0.3
        if emotion_metadata['negative_intensity'] > 0.1:
            frame_diversity += 0.3
        if reform_metadata['reform_word_count'] > 0:
            frame_diversity += 0.4
        
        # å¤šé‡ç¾å¯¦å¼·åº¦
        reality_strength = (
            quantum_metrics['frame_competition'] * 0.4 +
            quantum_metrics['semantic_interference'] * 0.3 +
            frame_diversity * 0.3
        )
        
        # æ¡†æ¶è¡çªå¼·åº¦
        conflict_strength = (
            quantum_metrics['frame_entanglement'] * 0.5 +
            abs(emotion_metadata['positive_intensity'] - emotion_metadata['negative_intensity']) * 0.3 +
            quantum_metrics['frame_competition'] * 0.2
        )
        
        # èªç¾©æ¨¡ç³Šåº¦
        ambiguity = (
            quantum_metrics['von_neumann_entropy'] * 0.5 +
            quantum_metrics['semantic_interference'] * 0.3 +
            (1.0 - max(quantum_metrics['emotion_frame_strength'], quantum_metrics['reform_frame_strength'])) * 0.2
        )
        
        return {
            'multiple_reality_strength': min(1.0, max(0.0, reality_strength)),
            'frame_conflict_strength': min(1.0, max(0.0, conflict_strength)),
            'semantic_ambiguity': min(1.0, max(0.0, ambiguity))
        }

    def process_record_with_quantum_frames(self, record: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨çœŸå¯¦é‡å­æ¡†æ¶è™•ç†è¨˜éŒ„"""
        
        try:
            text = record.get('original_text', '')
            if not text or len(text.strip()) < 5:
                return self._get_default_record_result(record)
            
            # æ§‹å»ºé‡å­æ¡†æ¶ç‹€æ…‹
            emotion_state, emotion_metadata = self.construct_emotion_quantum_state(text)
            reform_state, reform_metadata = self.construct_reform_quantum_state(
                text, emotion_metadata['context_type']
            )
            
            # å‰µå»ºé‡å­é›»è·¯
            text_complexity = min(1.0, len(text) / 100.0)
            circuit = self.create_quantum_circuit_with_frames(emotion_state, reform_state, text_complexity)
            
            # é‡å­æ¸¬é‡
            quantum_metrics = self.measure_quantum_frame_properties(circuit, emotion_state, reform_state)
            
            # å¤šé‡ç¾å¯¦åˆ†æ
            reality_analysis = self.analyze_multiple_realities_with_frames(
                quantum_metrics, emotion_metadata, reform_metadata
            )
            
            # ç·¨è­¯çµæœ
            result = {
                'record_id': record.get('record_id', 0),
                'field': record.get('field', ''),
                'original_text': text[:100] + '...' if len(text) > 100 else text,
                'word_count': emotion_metadata['word_count'],
                
                # é‡å­æ¡†æ¶ç‹€æ…‹
                'emotion_positive_amplitude': float(emotion_state[0]),
                'emotion_neutral_amplitude': float(emotion_state[1]),
                'emotion_negative_amplitude': float(emotion_state[2]),
                'reform_positive_amplitude': float(reform_state[0]),
                'reform_reactive_amplitude': float(reform_state[1]),
                'reform_superficial_amplitude': float(reform_state[2]),
                
                # æ¡†æ¶å…ƒæ•¸æ“š
                'positive_emotion_intensity': emotion_metadata['positive_intensity'],
                'negative_emotion_intensity': emotion_metadata['negative_intensity'],
                'active_voice_bonus': emotion_metadata['active_voice_bonus'],
                'future_tense_bonus': emotion_metadata['future_tense_bonus'],
                'context_type': emotion_metadata['context_type'],
                'reform_word_count': reform_metadata['reform_word_count'],
                
                # é‡å­æŒ‡æ¨™
                'frame_competition': quantum_metrics['frame_competition'],
                'frame_competition_kl': quantum_metrics.get('frame_competition_kl', 0.0),
                'emotion_frame_strength': quantum_metrics['emotion_frame_strength'],
                'reform_frame_strength': quantum_metrics['reform_frame_strength'],
                'frame_entanglement': quantum_metrics['frame_entanglement'],
                'von_neumann_entropy': quantum_metrics['von_neumann_entropy'],
                'semantic_interference': quantum_metrics['semantic_interference'],
                
                # å¤šé‡ç¾å¯¦åˆ†æ
                'multiple_reality_strength': reality_analysis['multiple_reality_strength'],
                'frame_conflict_strength': reality_analysis['frame_conflict_strength'],
                'semantic_ambiguity': reality_analysis['semantic_ambiguity'],
                
                # é›»è·¯ç‰¹æ€§
                'circuit_depth': circuit.depth(),
                'circuit_gates': circuit.size(),
                'qubit_count': circuit.num_qubits,
                
                # æ¨™è¨˜
                'quantum_frames_enabled': True,
                'analysis_version': 'quantum_frames_v1.0'
            }
            
            return result
            
        except Exception as e:
            print(f"âš ï¸  è¨˜éŒ„ {record.get('record_id', 'unknown')} åˆ†æå¤±æ•—: {e}")
            return self._get_default_record_result(record)

    def _get_default_record_result(self, record: Dict[str, Any]) -> Dict[str, Any]:
        """è¿”å›é è¨­è¨˜éŒ„çµæœ"""
        return {
            'record_id': record.get('record_id', 0),
            'field': record.get('field', ''),
            'original_text': record.get('original_text', '')[:100],
            'word_count': 0,
            'emotion_positive_amplitude': 0.33,
            'emotion_neutral_amplitude': 0.34,
            'emotion_negative_amplitude': 0.33,
            'reform_positive_amplitude': 0.33,
            'reform_reactive_amplitude': 0.33,
            'reform_superficial_amplitude': 0.34,
            'positive_emotion_intensity': 0.0,
            'negative_emotion_intensity': 0.0,
            'active_voice_bonus': 0.0,
            'future_tense_bonus': 0.0,
            'context_type': 'normal',
            'reform_word_count': 0,
            'frame_competition': 0.5,
            'emotion_frame_strength': 0.5,
            'reform_frame_strength': 0.5,
            'frame_entanglement': 0.3,
            'von_neumann_entropy': 0.5,
            'semantic_interference': 0.4,
            'multiple_reality_strength': 0.5,
            'frame_conflict_strength': 0.3,
            'semantic_ambiguity': 0.4,
            'circuit_depth': 0,
            'circuit_gates': 0,
            'qubit_count': 6,
            'quantum_frames_enabled': False,
            'analysis_version': 'quantum_frames_v1.0'
        }

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    
    print("ğŸš€ å•Ÿå‹•é‡å­æ¡†æ¶åˆ†æ")
    print("=" * 60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = QuantumFrameAnalyzer()
    
    # è¼‰å…¥åˆ†è©çµæœ
    segmentation_file = '../results/complete_discocat_segmentation.csv'
    
    if not os.path.exists(segmentation_file):
        print(f"âŒ æ‰¾ä¸åˆ°åˆ†è©çµæœæ–‡ä»¶: {segmentation_file}")
        return
    
    print(f"ğŸ“‚ è¼‰å…¥åˆ†è©çµæœ: {segmentation_file}")
    df = pd.read_csv(segmentation_file)
    
    print(f"ğŸ“Š ç¸½è¨˜éŒ„æ•¸: {len(df)}")
    
    # è™•ç†è¨˜éŒ„
    results = []
    start_time = time.time()
    
    for idx, record in df.iterrows():
        if idx % 50 == 0:
            elapsed = time.time() - start_time
            rate = idx / elapsed if elapsed > 0 else 0
            eta = (len(df) - idx) / rate if rate > 0 else 0
            print(f"ğŸ“ˆ é€²åº¦: {idx}/{len(df)} ({idx/len(df)*100:.1f}%) - {rate:.1f} records/sec - ETA: {eta/60:.1f}min")
        
        result = analyzer.process_record_with_quantum_frames(record.to_dict())
        results.append(result)
    
    # ä¿å­˜çµæœ
    results_df = pd.DataFrame(results)
    
    # ä¿å­˜è©³ç´°çµæœ
    output_file = '../results/quantum_frame_analysis_results.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8')
    print(f"ğŸ’¾ é‡å­æ¡†æ¶åˆ†æçµæœå·²ä¿å­˜: {output_file}")
    
    # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
    summary_stats = {}
    
    numeric_columns = [
        'frame_competition', 'emotion_frame_strength', 'reform_frame_strength',
        'frame_entanglement', 'von_neumann_entropy', 'semantic_interference',
        'multiple_reality_strength', 'frame_conflict_strength', 'semantic_ambiguity'
    ]
    
    for field in ['æ–°èæ¨™é¡Œ', 'å½±ç‰‡å°è©±', 'å½±ç‰‡æè¿°']:
        field_data = results_df[results_df['field'] == field]
        if not field_data.empty:
            field_stats = {}
            for col in numeric_columns:
                field_stats[col] = {
                    'mean': float(field_data[col].mean()),
                    'std': float(field_data[col].std()),
                    'min': float(field_data[col].min()),
                    'max': float(field_data[col].max())
                }
            summary_stats[field] = field_stats
    
    # æ•´é«”çµ±è¨ˆ
    overall_stats = {}
    for col in numeric_columns:
        overall_stats[col] = {
            'mean': float(results_df[col].mean()),
            'std': float(results_df[col].std()),
            'min': float(results_df[col].min()),
            'max': float(results_df[col].max())
        }
    summary_stats['overall'] = overall_stats
    
    # ä¿å­˜çµ±è¨ˆæ‘˜è¦
    summary_file = '../results/quantum_frame_analysis_summary.json'
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary_stats, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š çµ±è¨ˆæ‘˜è¦å·²ä¿å­˜: {summary_file}")
    
    # æ€§èƒ½æ‘˜è¦
    total_time = time.time() - start_time
    print(f"\nâœ… é‡å­æ¡†æ¶åˆ†æå®Œæˆ!")
    print(f"â±ï¸  ç¸½è€—æ™‚: {total_time/60:.1f} åˆ†é˜")
    print(f"ğŸš€ è™•ç†é€Ÿåº¦: {len(df)/total_time:.1f} è¨˜éŒ„/ç§’")
    print(f"ğŸ“ˆ æˆåŠŸè™•ç†: {len(results_df)} / {len(df)} è¨˜éŒ„")
    
    # é¡¯ç¤ºæ¨£æœ¬çµæœ
    print(f"\nğŸ“‹ é‡å­æ¡†æ¶åˆ†æçµæœé è¦½:")
    for field in ['æ–°èæ¨™é¡Œ', 'å½±ç‰‡å°è©±', 'å½±ç‰‡æè¿°']:
        field_sample = results_df[results_df['field'] == field].iloc[0] if not results_df[results_df['field'] == field].empty else None
        if field_sample is not None:
            print(f"\n{field}:")
            print(f"  æ–‡æœ¬: {field_sample['original_text']}")
            print(f"  æƒ…æ„Ÿæ¡†æ¶: +{field_sample['emotion_positive_amplitude']:.3f} Â±{field_sample['emotion_neutral_amplitude']:.3f} -{field_sample['emotion_negative_amplitude']:.3f}")
            print(f"  æ”¹é©æ¡†æ¶: +{field_sample['reform_positive_amplitude']:.3f} Â±{field_sample['reform_reactive_amplitude']:.3f} -{field_sample['reform_superficial_amplitude']:.3f}")
            print(f"  æ¡†æ¶ç«¶çˆ­: {field_sample['frame_competition']:.4f}")
            print(f"  æ¡†æ¶ç³¾çº: {field_sample['frame_entanglement']:.4f}")
            print(f"  å¤šé‡ç¾å¯¦å¼·åº¦: {field_sample['multiple_reality_strength']:.4f}")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
å®Œæ•´æ•°æ®é›†å¯è§†åŒ–åˆ†æå™¨
ç”ŸæˆåŸºäº934ä¸ªæ–‡æœ¬ç‰‡æ®µçš„é‡å­ç‰¹å¾å¯è§†åŒ–å›¾è¡¨
æµ‹è¯•ä¸­æ–‡å­—ç¬¦æ˜¾ç¤ºæ•ˆæœ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import os
from pathlib import Path
import platform

def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“ä»¥ç¡®ä¿æ­£ç¡®æ˜¾ç¤º"""
    print("ğŸ”§ è®¾ç½®ä¸­æ–‡å­—ä½“...")
    
    # æ£€æµ‹æ“ä½œç³»ç»Ÿå¹¶è®¾ç½®ç›¸åº”çš„ä¸­æ–‡å­—ä½“
    system = platform.system()
    
    if system == 'Darwin':  # macOS
        fonts = ['Arial Unicode MS', 'PingFang SC', 'Heiti SC', 'STSong']
        print("ğŸ æ£€æµ‹åˆ°macOSç³»ç»Ÿ")
    elif system == 'Windows':
        fonts = ['Microsoft YaHei', 'SimHei', 'KaiTi', 'SimSun']
        print("ğŸªŸ æ£€æµ‹åˆ°Windowsç³»ç»Ÿ")
    else:  # Linux
        fonts = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'DejaVu Sans']
        print("ğŸ§ æ£€æµ‹åˆ°Linuxç³»ç»Ÿ")
    
    # è®¾ç½®matplotlibå‚æ•°
    plt.rcParams['axes.unicode_minus'] = False
    
    # å°è¯•è®¾ç½®å­—ä½“
    for font in fonts:
        try:
            plt.rcParams['font.sans-serif'] = [font] + plt.rcParams['font.sans-serif']
            print(f"âœ… è®¾ç½®å­—ä½“: {font}")
            break
        except:
            continue
    
    # éªŒè¯ä¸­æ–‡å­—ä½“è®¾ç½®
    plt.rcParams['font.family'] = 'sans-serif'
    
    # æµ‹è¯•ä¸­æ–‡å­—ç¬¦
    fig, ax = plt.subplots(figsize=(8, 6))
    test_text = "æµ‹è¯•ä¸­æ–‡å­—ç¬¦æ˜¾ç¤ºï¼šé‡å­è‡ªç„¶è¯­è¨€å¤„ç†åˆ†æ"
    ax.text(0.5, 0.5, test_text, ha='center', va='center', fontsize=16)
    ax.set_title('ä¸­æ–‡å­—ä½“æµ‹è¯•å›¾è¡¨', fontsize=18, fontweight='bold')
    ax.axis('off')
    
    # ä¿å­˜æµ‹è¯•å›¾
    test_path = '../20250927-image/chinese_font_test.png'
    plt.savefig(test_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print(f"ğŸ“Š ä¸­æ–‡å­—ä½“æµ‹è¯•å›¾å·²ä¿å­˜: {test_path}")

def load_full_dataset_results():
    """åŠ è½½å®Œæ•´æ•°æ®é›†çš„åˆ†æç»“æœ"""
    print("ğŸ“‚ åŠ è½½å®Œæ•´æ•°æ®é›†åˆ†æç»“æœ...")
    
    # åŠ è½½ç»Ÿè®¡æ‘˜è¦
    ai_summary_path = '../results/full_qiskit_ai_analysis_summary.json'
    journalist_summary_path = '../results/full_qiskit_journalist_analysis_summary.json'
    field_level_path = '../results/full_field_level_quantum_analysis.json'
    
    with open(ai_summary_path, 'r', encoding='utf-8') as f:
        ai_summary = json.load(f)
    
    with open(journalist_summary_path, 'r', encoding='utf-8') as f:
        journalist_summary = json.load(f)
        
    with open(field_level_path, 'r', encoding='utf-8') as f:
        field_level_data = json.load(f)
    
    print("âœ… æ•°æ®åŠ è½½å®Œæˆ")
    return ai_summary, journalist_summary, field_level_data

def create_comprehensive_comparison(ai_summary, journalist_summary, field_level_data):
    """åˆ›å»ºç»¼åˆå¯¹æ¯”å›¾è¡¨"""
    print("ğŸ“Š ç”Ÿæˆç»¼åˆå¯¹æ¯”å›¾è¡¨...")
    
    # é‡å­æŒ‡æ ‡
    metrics = ['von_neumann_entropy', 'superposition_strength', 'quantum_coherence', 
               'semantic_interference', 'frame_competition', 'multiple_reality_strength']
    
    metric_names = {
        'von_neumann_entropy': 'å†¯çº½æ›¼ç†µ',
        'superposition_strength': 'é‡å­å åŠ å¼ºåº¦',
        'quantum_coherence': 'é‡å­ç›¸å¹²æ€§',
        'semantic_interference': 'è¯­ä¹‰å¹²æ¶‰',
        'frame_competition': 'æ¡†æ¶ç«äº‰',
        'multiple_reality_strength': 'å¤šé‡ç°å®å¼ºåº¦'
    }
    
    # åˆ›å»º2x3çš„å­å›¾å¸ƒå±€
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('å®Œæ•´æ•°æ®é›†é‡å­ç‰¹å¾å¯¹æ¯”åˆ†æ\n(åŸºäº934ä¸ªæ–‡æœ¬ç‰‡æ®µçš„Qiskité‡å­ç”µè·¯åˆ†æ)', 
                 fontsize=20, fontweight='bold')
    
    axes = axes.flatten()
    
    for i, metric in enumerate(metrics):
        ax = axes[i]
        
        # æ•°æ®å‡†å¤‡
        ai_mean = ai_summary[metric]['mean']
        ai_std = ai_summary[metric]['std']
        journalist_mean = journalist_summary[metric]['mean']
        journalist_std = journalist_summary[metric]['std']
        
        # æŸ±çŠ¶å›¾
        categories = ['AIç”Ÿæˆæ–°é—»\n(298æ¡è®°å½•)', 'è®°è€…æ’°å†™æ–°é—»\n(20æ¡è®°å½•)']
        means = [ai_mean, journalist_mean]
        stds = [ai_std, journalist_std]
        colors = ['#FF6B6B', '#4ECDC4']
        
        bars = ax.bar(categories, means, yerr=stds, capsize=8, 
                     color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, mean, std in zip(bars, means, stds):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + std + 0.01,
                   f'{mean:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        ax.set_title(f'{metric_names[metric]}', fontsize=14, fontweight='bold')
        ax.set_ylabel('æ•°å€¼', fontsize=12)
        ax.grid(True, alpha=0.3)
        
        # è®¾ç½®Yè½´èŒƒå›´
        max_val = max(means) + max(stds)
        min_val = min(means) - max(stds)
        margin = (max_val - min_val) * 0.15
        ax.set_ylim(max(0, min_val - margin), max_val + margin)
    
    plt.tight_layout()
    plt.savefig('../20250927-image/comprehensive_quantum_comparison.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… ç»¼åˆå¯¹æ¯”å›¾è¡¨å·²ä¿å­˜")

def create_field_level_heatmap(field_level_data):
    """åˆ›å»ºå­—æ®µçº§åˆ«çƒ­åŠ›å›¾"""
    print("ğŸ”¥ ç”Ÿæˆå­—æ®µçº§åˆ«çƒ­åŠ›å›¾...")
    
    # å‡†å¤‡æ•°æ®
    metrics = ['von_neumann_entropy', 'superposition_strength', 'quantum_coherence', 
               'semantic_interference', 'multiple_reality_strength']
    
    # AIæ•°æ®
    ai_fields = ['æ–°èæ¨™é¡Œ', 'å½±ç‰‡å°è©±', 'å½±ç‰‡æè¿°']
    ai_data = []
    ai_labels = []
    
    for field in ai_fields:
        row = []
        for metric in metrics:
            mean_val = field_level_data['AI_Generated'][field][metric]['mean']
            row.append(mean_val)
        ai_data.append(row)
        ai_labels.append(f'AI-{field}')
    
    # è®°è€…æ•°æ®
    journalist_fields = ['æ–°èæ¨™é¡Œ', 'æ–°èå…§å®¹']
    journalist_data = []
    journalist_labels = []
    
    for field in journalist_fields:
        row = []
        for metric in metrics:
            mean_val = field_level_data['Journalist_Written'][field][metric]['mean']
            row.append(mean_val)
        journalist_data.append(row)
        journalist_labels.append(f'è®°è€…-{field}')
    
    # åˆå¹¶æ•°æ®
    all_data = np.array(ai_data + journalist_data)
    all_labels = ai_labels + journalist_labels
    
    # åˆ›å»ºçƒ­åŠ›å›¾
    fig, ax = plt.subplots(figsize=(12, 8))
    
    metric_names = ['å†¯çº½æ›¼ç†µ', 'é‡å­å åŠ å¼ºåº¦', 'é‡å­ç›¸å¹²æ€§', 'è¯­ä¹‰å¹²æ¶‰', 'å¤šé‡ç°å®å¼ºåº¦']
    
    # ä½¿ç”¨seabornåˆ›å»ºçƒ­åŠ›å›¾
    sns.heatmap(all_data, 
                xticklabels=metric_names,
                yticklabels=all_labels,
                annot=True, 
                fmt='.4f',
                cmap='RdYlBu_r',
                center=None,
                ax=ax,
                cbar_kws={'label': 'é‡å­ç‰¹å¾å€¼'})
    
    ax.set_title('å­—æ®µçº§åˆ«é‡å­ç‰¹å¾çƒ­åŠ›å›¾\n(å®Œæ•´æ•°æ®é›†åˆ†æ)', fontsize=16, fontweight='bold')
    ax.set_xlabel('é‡å­æŒ‡æ ‡', fontsize=12)
    ax.set_ylabel('æ•°æ®æºä¸å­—æ®µ', fontsize=12)
    
    plt.tight_layout()
    plt.savefig('../20250927-image/field_level_heatmap.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… å­—æ®µçº§åˆ«çƒ­åŠ›å›¾å·²ä¿å­˜")

def create_radar_chart(field_level_data):
    """åˆ›å»ºé›·è¾¾å›¾å¯¹æ¯”"""
    print("ğŸ¯ ç”Ÿæˆé›·è¾¾å›¾å¯¹æ¯”...")
    
    metrics = ['von_neumann_entropy', 'superposition_strength', 'quantum_coherence', 
               'semantic_interference', 'multiple_reality_strength']
    metric_names = ['å†¯çº½æ›¼ç†µ', 'é‡å­å åŠ å¼ºåº¦', 'é‡å­ç›¸å¹²æ€§', 'è¯­ä¹‰å¹²æ¶‰', 'å¤šé‡ç°å®å¼ºåº¦']
    
    # æ•°æ®å‡†å¤‡ - é€‰æ‹©ä»£è¡¨æ€§å­—æ®µè¿›è¡Œå¯¹æ¯”
    ai_dialogue = []  # AIå½±ç‰‡å°è©±
    journalist_content = []  # è®°è€…æ–°èå…§å®¹
    
    for metric in metrics:
        ai_val = field_level_data['AI_Generated']['å½±ç‰‡å°è©±'][metric]['mean']
        journalist_val = field_level_data['Journalist_Written']['æ–°èå…§å®¹'][metric]['mean']
        
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´ç”¨äºé›·è¾¾å›¾æ˜¾ç¤º
        max_val = max(ai_val, journalist_val)
        if max_val > 0:
            ai_dialogue.append(ai_val / max_val)
            journalist_content.append(journalist_val / max_val)
        else:
            ai_dialogue.append(0)
            journalist_content.append(0)
    
    # åˆ›å»ºé›·è¾¾å›¾
    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
    angles += angles[:1]  # é—­åˆé›·è¾¾å›¾
    
    ai_dialogue += ai_dialogue[:1]
    journalist_content += journalist_content[:1]
    
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
    
    # ç»˜åˆ¶é›·è¾¾å›¾
    ax.plot(angles, ai_dialogue, 'o-', linewidth=3, label='AIå½±ç‰‡å°è©± (298æ¡)', color='#FF6B6B')
    ax.fill(angles, ai_dialogue, alpha=0.25, color='#FF6B6B')
    
    ax.plot(angles, journalist_content, 'o-', linewidth=3, label='è®°è€…æ–°èå…§å®¹ (20æ¡)', color='#4ECDC4')
    ax.fill(angles, journalist_content, alpha=0.25, color='#4ECDC4')
    
    # è®¾ç½®æ ‡ç­¾
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(metric_names, fontsize=12)
    
    ax.set_ylim(0, 1)
    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=10)
    ax.grid(True)
    
    plt.title('é‡å­ç‰¹å¾é›·è¾¾å›¾å¯¹æ¯”\n(é•¿æ–‡æœ¬å­—æ®µä»£è¡¨æ€§åˆ†æ)', fontsize=16, fontweight='bold', pad=30)
    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
    
    plt.savefig('../20250927-image/quantum_radar_comparison.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… é›·è¾¾å›¾å¯¹æ¯”å·²ä¿å­˜")

def create_distribution_analysis(field_level_data):
    """åˆ›å»ºåˆ†å¸ƒåˆ†æå›¾"""
    print("ğŸ“ˆ ç”Ÿæˆåˆ†å¸ƒåˆ†æå›¾...")
    
    # é€‰æ‹©å…³é”®æŒ‡æ ‡è¿›è¡Œåˆ†å¸ƒåˆ†æ
    key_metrics = ['von_neumann_entropy', 'semantic_interference', 'multiple_reality_strength']
    metric_names = ['å†¯çº½æ›¼ç†µ', 'è¯­ä¹‰å¹²æ¶‰', 'å¤šé‡ç°å®å¼ºåº¦']
    
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    fig.suptitle('å…³é”®é‡å­æŒ‡æ ‡çš„å­—æ®µåˆ†å¸ƒåˆ†æ\n(å®Œæ•´æ•°æ®é›†)', fontsize=16, fontweight='bold')
    
    for i, (metric, name) in enumerate(zip(key_metrics, metric_names)):
        ax = axes[i]
        
        # æ”¶é›†æ‰€æœ‰å­—æ®µçš„æ•°æ®
        field_names = []
        values = []
        colors = []
        
        # AIæ•°æ®
        for field in ['æ–°èæ¨™é¡Œ', 'å½±ç‰‡å°è©±', 'å½±ç‰‡æè¿°']:
            mean_val = field_level_data['AI_Generated'][field][metric]['mean']
            std_val = field_level_data['AI_Generated'][field][metric]['std']
            count = field_level_data['AI_Generated'][field][metric]['count']
            
            field_names.append(f'AI-{field}\n({count}æ¡)')
            values.append(mean_val)
            colors.append('#FF6B6B')
        
        # è®°è€…æ•°æ®
        for field in ['æ–°èæ¨™é¡Œ', 'æ–°èå…§å®¹']:
            mean_val = field_level_data['Journalist_Written'][field][metric]['mean']
            std_val = field_level_data['Journalist_Written'][field][metric]['std']
            count = field_level_data['Journalist_Written'][field][metric]['count']
            
            field_names.append(f'è®°è€…-{field}\n({count}æ¡)')
            values.append(mean_val)
            colors.append('#4ECDC4')
        
        # åˆ›å»ºæŸ±çŠ¶å›¾
        bars = ax.bar(range(len(field_names)), values, color=colors, alpha=0.8, edgecolor='black')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                   f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        
        ax.set_title(name, fontsize=14, fontweight='bold')
        ax.set_ylabel('æ•°å€¼', fontsize=12)
        ax.set_xticks(range(len(field_names)))
        ax.set_xticklabels(field_names, rotation=45, ha='right')
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('../20250927-image/distribution_analysis.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… åˆ†å¸ƒåˆ†æå›¾å·²ä¿å­˜")

def create_summary_statistics_table():
    """åˆ›å»ºç»Ÿè®¡æ‘˜è¦è¡¨æ ¼"""
    print("ğŸ“‹ ç”Ÿæˆç»Ÿè®¡æ‘˜è¦è¡¨æ ¼...")
    
    fig, ax = plt.subplots(figsize=(14, 10))
    ax.axis('tight')
    ax.axis('off')
    
    # è¡¨æ ¼æ•°æ®
    table_data = [
        ['æ•°æ®æº', 'å­—æ®µ', 'è®°å½•æ•°', 'å†¯çº½æ›¼ç†µ', 'é‡å­å åŠ å¼ºåº¦', 'é‡å­ç›¸å¹²æ€§', 'è¯­ä¹‰å¹²æ¶‰', 'å¤šé‡ç°å®å¼ºåº¦'],
        ['AIç”Ÿæˆ', 'æ–°èæ¨™é¡Œ', '298', '3.9967Â±0.0579', '3.7492Â±0.0145', '0.9373Â±0.0036', '0.0014Â±0.0026', '1.7001Â±0.0059'],
        ['AIç”Ÿæˆ', 'å½±ç‰‡å°è©±', '298', '4.0000Â±0.0000', '3.7500Â±0.0000', '0.9375Â±0.0000', '0.0178Â±0.0042', '1.7054Â±0.0013'],
        ['AIç”Ÿæˆ', 'å½±ç‰‡æè¿°', '298', '4.0000Â±0.0000', '3.7500Â±0.0000', '0.9375Â±0.0000', '0.0111Â±0.0039', '1.7033Â±0.0012'],
        ['è®°è€…æ’°å†™', 'æ–°èæ¨™é¡Œ', '20', '3.8500Â±0.3663', '3.7125Â±0.0916', '0.9281Â±0.0229', '0.0008Â±0.0022', '1.6856Â±0.0369'],
        ['è®°è€…æ’°å†™', 'æ–°èå…§å®¹', '20', '4.0000Â±0.0000', '3.7500Â±0.0000', '0.9375Â±0.0000', '0.0177Â±0.0060', '1.7054Â±0.0018']
    ]
    
    # åˆ›å»ºè¡¨æ ¼
    table = ax.table(cellText=table_data[1:], colLabels=table_data[0], 
                     loc='center', cellLoc='center')
    
    # è®¾ç½®è¡¨æ ¼æ ·å¼
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 2.5)
    
    # è®¾ç½®æ ‡é¢˜è¡Œæ ·å¼
    for i in range(len(table_data[0])):
        table[(0, i)].set_facecolor('#4ECDC4')
        table[(0, i)].set_text_props(weight='bold', color='white')
    
    # è®¾ç½®æ•°æ®è¡Œæ ·å¼
    for i in range(1, len(table_data)):
        color = '#FFE5E5' if 'AIç”Ÿæˆ' in table_data[i][0] else '#E5F9F6'
        for j in range(len(table_data[0])):
            table[(i, j)].set_facecolor(color)
    
    plt.title('å®Œæ•´æ•°æ®é›†é‡å­ç‰¹å¾ç»Ÿè®¡æ‘˜è¦è¡¨\n(å‡å€¼Â±æ ‡å‡†å·®)', fontsize=16, fontweight='bold', pad=20)
    
    plt.savefig('../20250927-image/statistics_summary_table.png', 
                dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    print("âœ… ç»Ÿè®¡æ‘˜è¦è¡¨æ ¼å·²ä¿å­˜")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®é›†å¯è§†åŒ–åˆ†æ...")
    print(f"ğŸ“Š åˆ†æè§„æ¨¡: 934ä¸ªæ–‡æœ¬ç‰‡æ®µ")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path('../20250927-image').mkdir(exist_ok=True)
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    setup_chinese_font()
    
    # åŠ è½½æ•°æ®
    ai_summary, journalist_summary, field_level_data = load_full_dataset_results()
    
    # ç”Ÿæˆå„ç§å¯è§†åŒ–å›¾è¡¨
    create_comprehensive_comparison(ai_summary, journalist_summary, field_level_data)
    create_field_level_heatmap(field_level_data)
    create_radar_chart(field_level_data)
    create_distribution_analysis(field_level_data)
    create_summary_statistics_table()
    
    print("\nğŸ‰ å®Œæ•´æ•°æ®é›†å¯è§†åŒ–åˆ†æå®Œæˆï¼")
    print("ğŸ“‚ æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: ../20250927-image/")
    print("ğŸ“Š ç”Ÿæˆçš„å›¾è¡¨:")
    print("   1. chinese_font_test.png - ä¸­æ–‡å­—ä½“æµ‹è¯•")
    print("   2. comprehensive_quantum_comparison.png - ç»¼åˆé‡å­ç‰¹å¾å¯¹æ¯”")
    print("   3. field_level_heatmap.png - å­—æ®µçº§åˆ«çƒ­åŠ›å›¾")
    print("   4. quantum_radar_comparison.png - é‡å­ç‰¹å¾é›·è¾¾å›¾")
    print("   5. distribution_analysis.png - åˆ†å¸ƒåˆ†æå›¾")
    print("   6. statistics_summary_table.png - ç»Ÿè®¡æ‘˜è¦è¡¨æ ¼")

if __name__ == "__main__":
    main()

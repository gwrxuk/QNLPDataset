#!/usr/bin/env python3
"""
å…¬å¹³å¯¹æ¯”å¯è§†åŒ–å™¨ - ç”ŸæˆAI vs è®°è€…æ–°é—»çš„è¯¦ç»†å¯¹æ¯”å›¾è¡¨
"""

import json
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import numpy as np
import pandas as pd
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    
    # å°è¯•ç³»ç»Ÿä¸­æ–‡å­—ä½“
    chinese_fonts = [
        'Arial Unicode MS',
        'STHeiti',
        'SimHei', 
        'Microsoft YaHei',
        'PingFang SC',
        'Hiragino Sans GB',
        'Source Han Sans CN',
        'Noto Sans CJK SC'
    ]
    
    font_found = False
    
    # é¦–å…ˆå°è¯•ç³»ç»Ÿå­—ä½“
    for font_name in chinese_fonts:
        try:
            # æµ‹è¯•å­—ä½“æ˜¯å¦å¯ç”¨
            test_font = fm.FontProperties(family=font_name)
            if test_font.get_name() in [f.name for f in fm.fontManager.ttflist]:
                plt.rcParams['font.family'] = [font_name]
                print(f"âœ… ä½¿ç”¨ä¸­æ–‡å­—ä½“: {font_name}")
                font_found = True
                break
        except Exception as e:
            continue
    
    # å¦‚æœç³»ç»Ÿå­—ä½“ä¸å¯ç”¨ï¼Œå°è¯•æ–‡ä»¶è·¯å¾„
    if not font_found:
        font_paths = [
            '/System/Library/Fonts/Arial Unicode MS.ttf',
            '/System/Library/Fonts/STHeiti Light.ttc',
            '/System/Library/Fonts/STHeiti Medium.ttc',
            '/System/Library/Fonts/PingFang.ttc',
            '/System/Library/Fonts/Hiragino Sans GB.ttc',
            '/Library/Fonts/Arial Unicode MS.ttf'
        ]
        
        for font_path in font_paths:
            try:
                if Path(font_path).exists():
                    font_prop = fm.FontProperties(fname=font_path)
                    plt.rcParams['font.family'] = [font_prop.get_name()]
                    print(f"âœ… ä½¿ç”¨å­—ä½“æ–‡ä»¶: {font_path}")
                    font_found = True
                    break
            except Exception as e:
                continue
    
    # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
    if not font_found:
        print("âš ï¸ æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
        plt.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']
    
    # è®¾ç½®å…¶ä»–å­—ä½“å‚æ•°
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['font.size'] = 10
    plt.rcParams['font.weight'] = 'normal'
    
    # æµ‹è¯•ä¸­æ–‡æ˜¾ç¤º
    try:
        fig, ax = plt.subplots(figsize=(1, 1))
        ax.text(0.5, 0.5, 'æµ‹è¯•ä¸­æ–‡', ha='center', va='center')
        plt.close(fig)
        print("âœ… ä¸­æ–‡å­—ä½“æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âš ï¸ ä¸­æ–‡å­—ä½“æµ‹è¯•å¤±è´¥: {e}")
        # å¼ºåˆ¶è®¾ç½®ä¸ºæ”¯æŒä¸­æ–‡çš„å­—ä½“
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False

def load_summary_data():
    """åŠ è½½æ±‡æ€»æ•°æ®"""
    files = {
        'ai_restricted': '../results/fair_comparison_ai_restricted_summary.json',
        'ai_unrestricted': '../results/fair_comparison_ai_unrestricted_summary.json',
        'journalist_restricted': '../results/fair_comparison_journalist_restricted_summary.json',
        'journalist_unrestricted': '../results/fair_comparison_journalist_unrestricted_summary.json'
    }
    
    data = {}
    for key, file_path in files.items():
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data[key] = json.load(f)
            print(f"âœ… åŠ è½½æ•°æ®: {key}")
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥ {key}: {e}")
    
    return data

def create_grammatical_superposition_comparison(data):
    """åˆ›å»ºè¯­æ³•å åŠ å¼ºåº¦å¯¹æ¯”å›¾"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('è¯­æ³•å åŠ å¼ºåº¦å¯¹æ¯”åˆ†æ - å—é™åˆ¶ vs æ— é™åˆ¶ç‰ˆæœ¬', fontsize=16, fontweight='bold', 
                fontproperties='Arial Unicode MS')
    
    # 1. å—é™åˆ¶ç‰ˆæœ¬ - æ–°èæ¨™é¡Œå¯¹æ¯”
    ai_restricted_title = data['ai_restricted']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
    journalist_restricted_title = data['journalist_restricted']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
    
    ax1.bar(['AIæ–°é—»', 'è®°è€…æ–°é—»'], [ai_restricted_title, journalist_restricted_title], 
           color=['#ff6b6b', '#4ecdc4'], alpha=0.8)
    ax1.set_title('å—é™åˆ¶ç‰ˆæœ¬ - æ–°èæ¨™é¡Œ', fontweight='bold')
    ax1.set_ylabel('è¯­æ³•å åŠ å¼ºåº¦')
    ax1.set_ylim(0, 1.2)
    for i, v in enumerate([ai_restricted_title, journalist_restricted_title]):
        ax1.text(i, v + 0.02, f'{v:.6f}', ha='center', fontweight='bold')
    
    # 2. æ— é™åˆ¶ç‰ˆæœ¬ - æ–°èæ¨™é¡Œå¯¹æ¯”
    ai_unrestricted_title = data['ai_unrestricted']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
    journalist_unrestricted_title = data['journalist_unrestricted']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
    
    ax2.bar(['AIæ–°é—»', 'è®°è€…æ–°é—»'], [ai_unrestricted_title, journalist_unrestricted_title], 
           color=['#ff6b6b', '#4ecdc4'], alpha=0.8)
    ax2.set_title('æ— é™åˆ¶ç‰ˆæœ¬ - æ–°èæ¨™é¡Œ', fontweight='bold')
    ax2.set_ylabel('è¯­æ³•å åŠ å¼ºåº¦')
    ax2.set_ylim(0, 4.0)
    for i, v in enumerate([ai_unrestricted_title, journalist_unrestricted_title]):
        ax2.text(i, v + 0.05, f'{v:.6f}', ha='center', fontweight='bold')
    
    # 3. AIæ–°é—»å„å­—æ®µå¯¹æ¯” (æ— é™åˆ¶ç‰ˆæœ¬)
    ai_fields = ['æ–°èæ¨™é¡Œ', 'å½±ç‰‡å°è©±', 'å½±ç‰‡æè¿°']
    ai_values = [data['ai_unrestricted'][field]['grammatical_superposition']['mean'] for field in ai_fields]
    
    ax3.bar(ai_fields, ai_values, color='#ff6b6b', alpha=0.8)
    ax3.set_title('AIæ–°é—»å„å­—æ®µ - è¯­æ³•å åŠ å¼ºåº¦ (æ— é™åˆ¶)', fontweight='bold')
    ax3.set_ylabel('è¯­æ³•å åŠ å¼ºåº¦')
    ax3.set_ylim(0, 4.0)
    ax3.tick_params(axis='x', rotation=45)
    for i, v in enumerate(ai_values):
        ax3.text(i, v + 0.05, f'{v:.3f}', ha='center', fontweight='bold')
    
    # 4. è®°è€…æ–°é—»å„å­—æ®µå¯¹æ¯” (æ— é™åˆ¶ç‰ˆæœ¬)
    journalist_fields = ['æ–°èæ¨™é¡Œ', 'æ–°èå…§å®¹']
    journalist_values = [data['journalist_unrestricted'][field]['grammatical_superposition']['mean'] for field in journalist_fields]
    
    ax4.bar(journalist_fields, journalist_values, color='#4ecdc4', alpha=0.8)
    ax4.set_title('è®°è€…æ–°é—»å„å­—æ®µ - è¯­æ³•å åŠ å¼ºåº¦ (æ— é™åˆ¶)', fontweight='bold')
    ax4.set_ylabel('è¯­æ³•å åŠ å¼ºåº¦')
    ax4.set_ylim(0, 4.0)
    ax4.tick_params(axis='x', rotation=45)
    for i, v in enumerate(journalist_values):
        ax4.text(i, v + 0.05, f'{v:.3f}', ha='center', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('../visualizations/fair_comparison_grammatical_superposition.png', dpi=300, bbox_inches='tight')
    plt.show()

def create_comprehensive_metrics_comparison(data):
    """åˆ›å»ºç»¼åˆæŒ‡æ ‡å¯¹æ¯”çƒ­åŠ›å›¾"""
    
    # å‡†å¤‡æ•°æ®
    metrics = [
        'von_neumann_entropy', 'category_coherence', 'compositional_entanglement',
        'grammatical_superposition', 'semantic_interference', 'frame_competition',
        'multiple_reality_strength', 'frame_conflict_strength', 'semantic_ambiguity'
    ]
    
    metric_names_cn = [
        'å†¯çº½æ›¼ç†µ', 'ç±»åˆ«ä¸€è‡´æ€§', 'ç»„åˆçº ç¼ å¼ºåº¦',
        'è¯­æ³•å åŠ å¼ºåº¦', 'è¯­ä¹‰å¹²æ¶‰', 'æ¡†æ¶ç«äº‰å¼ºåº¦',
        'å¤šé‡ç°å®å¼ºåº¦', 'æ¡†æ¶å†²çªå¼ºåº¦', 'è¯­ä¹‰æ¨¡ç³Šåº¦'
    ]
    
    # åˆ›å»ºå¯¹æ¯”çŸ©é˜µ (æ–°èæ¨™é¡Œå­—æ®µ)
    comparison_data = []
    
    for metric in metrics:
        ai_restricted = data['ai_restricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        ai_unrestricted = data['ai_unrestricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        journalist_restricted = data['journalist_restricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        journalist_unrestricted = data['journalist_unrestricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        
        comparison_data.append([ai_restricted, ai_unrestricted, journalist_restricted, journalist_unrestricted])
    
    comparison_df = pd.DataFrame(comparison_data, 
                               index=metric_names_cn,
                               columns=['AIå—é™åˆ¶', 'AIæ— é™åˆ¶', 'è®°è€…å—é™åˆ¶', 'è®°è€…æ— é™åˆ¶'])
    
    # åˆ›å»ºçƒ­åŠ›å›¾
    fig, ax = plt.subplots(figsize=(12, 10))
    sns.heatmap(comparison_df, annot=True, fmt='.4f', cmap='RdYlBu_r', 
               cbar_kws={'label': 'æ•°å€¼å¤§å°'}, ax=ax)
    ax.set_title('é‡å­æŒ‡æ ‡ç»¼åˆå¯¹æ¯” - æ–°èæ¨™é¡Œå­—æ®µ', fontsize=14, fontweight='bold', pad=20)
    ax.set_xlabel('æ•°æ®ç±»å‹å’Œç‰ˆæœ¬', fontweight='bold')
    ax.set_ylabel('é‡å­æŒ‡æ ‡', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('../visualizations/fair_comparison_comprehensive_heatmap.png', dpi=300, bbox_inches='tight')
    plt.show()

def create_field_wise_radar_chart(data):
    """åˆ›å»ºæŒ‰å­—æ®µçš„é›·è¾¾å›¾å¯¹æ¯”"""
    
    # é€‰æ‹©å…³é”®æŒ‡æ ‡
    key_metrics = [
        'grammatical_superposition', 'multiple_reality_strength', 'semantic_ambiguity',
        'frame_competition', 'semantic_interference', 'von_neumann_entropy'
    ]
    
    key_metrics_cn = [
        'è¯­æ³•å åŠ å¼ºåº¦', 'å¤šé‡ç°å®å¼ºåº¦', 'è¯­ä¹‰æ¨¡ç³Šåº¦',
        'æ¡†æ¶ç«äº‰å¼ºåº¦', 'è¯­ä¹‰å¹²æ¶‰', 'å†¯çº½æ›¼ç†µ'
    ]
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 16), subplot_kw=dict(projection='polar'))
    fig.suptitle('é‡å­ç‰¹å¾é›·è¾¾å›¾å¯¹æ¯” (æ— é™åˆ¶ç‰ˆæœ¬)', fontsize=16, fontweight='bold')
    
    # 1. AIæ–°é—» - æ–°èæ¨™é¡Œ
    ai_title_values = [data['ai_unrestricted']['æ–°èæ¨™é¡Œ'][metric]['mean'] for metric in key_metrics]
    ai_title_values_norm = [v/max(ai_title_values) for v in ai_title_values]  # å½’ä¸€åŒ–åˆ°[0,1]
    
    angles = np.linspace(0, 2 * np.pi, len(key_metrics), endpoint=False).tolist()
    ai_title_values_norm += ai_title_values_norm[:1]  # é—­åˆ
    angles += angles[:1]
    
    ax1.plot(angles, ai_title_values_norm, 'o-', linewidth=2, color='#ff6b6b', alpha=0.8)
    ax1.fill(angles, ai_title_values_norm, alpha=0.25, color='#ff6b6b')
    ax1.set_xticks(angles[:-1])
    ax1.set_xticklabels(key_metrics_cn, fontsize=10)
    ax1.set_title('AIæ–°é—» - æ–°èæ¨™é¡Œ', fontweight='bold', pad=20)
    ax1.set_ylim(0, 1)
    
    # 2. è®°è€…æ–°é—» - æ–°èæ¨™é¡Œ
    journalist_title_values = [data['journalist_unrestricted']['æ–°èæ¨™é¡Œ'][metric]['mean'] for metric in key_metrics]
    journalist_title_values_norm = [v/max(journalist_title_values) for v in journalist_title_values]
    journalist_title_values_norm += journalist_title_values_norm[:1]
    
    ax2.plot(angles, journalist_title_values_norm, 'o-', linewidth=2, color='#4ecdc4', alpha=0.8)
    ax2.fill(angles, journalist_title_values_norm, alpha=0.25, color='#4ecdc4')
    ax2.set_xticks(angles[:-1])
    ax2.set_xticklabels(key_metrics_cn, fontsize=10)
    ax2.set_title('è®°è€…æ–°é—» - æ–°èæ¨™é¡Œ', fontweight='bold', pad=20)
    ax2.set_ylim(0, 1)
    
    # 3. AIæ–°é—» - å½±ç‰‡å°è©±
    ai_dialogue_values = [data['ai_unrestricted']['å½±ç‰‡å°è©±'][metric]['mean'] for metric in key_metrics]
    ai_dialogue_values_norm = [v/max(ai_dialogue_values) for v in ai_dialogue_values]
    ai_dialogue_values_norm += ai_dialogue_values_norm[:1]
    
    ax3.plot(angles, ai_dialogue_values_norm, 'o-', linewidth=2, color='#ff9f43', alpha=0.8)
    ax3.fill(angles, ai_dialogue_values_norm, alpha=0.25, color='#ff9f43')
    ax3.set_xticks(angles[:-1])
    ax3.set_xticklabels(key_metrics_cn, fontsize=10)
    ax3.set_title('AIæ–°é—» - å½±ç‰‡å°è©±', fontweight='bold', pad=20)
    ax3.set_ylim(0, 1)
    
    # 4. è®°è€…æ–°é—» - æ–°èå…§å®¹
    journalist_content_values = [data['journalist_unrestricted']['æ–°èå…§å®¹'][metric]['mean'] for metric in key_metrics]
    journalist_content_values_norm = [v/max(journalist_content_values) for v in journalist_content_values]
    journalist_content_values_norm += journalist_content_values_norm[:1]
    
    ax4.plot(angles, journalist_content_values_norm, 'o-', linewidth=2, color='#10ac84', alpha=0.8)
    ax4.fill(angles, journalist_content_values_norm, alpha=0.25, color='#10ac84')
    ax4.set_xticks(angles[:-1])
    ax4.set_xticklabels(key_metrics_cn, fontsize=10)
    ax4.set_title('è®°è€…æ–°é—» - æ–°èå…§å®¹', fontweight='bold', pad=20)
    ax4.set_ylim(0, 1)
    
    plt.tight_layout()
    plt.savefig('../visualizations/fair_comparison_radar_charts.png', dpi=300, bbox_inches='tight')
    plt.show()

def create_difference_analysis(data):
    """åˆ›å»ºå·®å¼‚åˆ†æå›¾"""
    
    # è®¡ç®—å·®å¼‚å€æ•°
    metrics = [
        'von_neumann_entropy', 'category_coherence', 'compositional_entanglement',
        'grammatical_superposition', 'semantic_interference', 'frame_competition',
        'multiple_reality_strength', 'frame_conflict_strength', 'semantic_ambiguity'
    ]
    
    metric_names_cn = [
        'å†¯çº½æ›¼ç†µ', 'ç±»åˆ«ä¸€è‡´æ€§', 'ç»„åˆçº ç¼ å¼ºåº¦',
        'è¯­æ³•å åŠ å¼ºåº¦', 'è¯­ä¹‰å¹²æ¶‰', 'æ¡†æ¶ç«äº‰å¼ºåº¦',
        'å¤šé‡ç°å®å¼ºåº¦', 'æ¡†æ¶å†²çªå¼ºåº¦', 'è¯­ä¹‰æ¨¡ç³Šåº¦'
    ]
    
    # è®¡ç®—æ–°èæ¨™é¡Œå­—æ®µçš„å·®å¼‚å€æ•°
    differences_restricted = []
    differences_unrestricted = []
    
    for metric in metrics:
        # å—é™åˆ¶ç‰ˆæœ¬å·®å¼‚
        ai_restricted = data['ai_restricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        journalist_restricted = data['journalist_restricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        diff_restricted = ai_restricted / max(journalist_restricted, 1e-6)
        differences_restricted.append(diff_restricted)
        
        # æ— é™åˆ¶ç‰ˆæœ¬å·®å¼‚
        ai_unrestricted = data['ai_unrestricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        journalist_unrestricted = data['journalist_unrestricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        diff_unrestricted = ai_unrestricted / max(journalist_unrestricted, 1e-6)
        differences_unrestricted.append(diff_unrestricted)
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
    fig.suptitle('AIæ–°é—» vs è®°è€…æ–°é—»å·®å¼‚å€æ•°åˆ†æ (æ–°èæ¨™é¡Œå­—æ®µ)', fontsize=16, fontweight='bold')
    
    x = np.arange(len(metric_names_cn))
    width = 0.35
    
    # å—é™åˆ¶ç‰ˆæœ¬å·®å¼‚
    bars1 = ax1.bar(x, differences_restricted, width, label='å—é™åˆ¶ç‰ˆæœ¬', color='#ff6b6b', alpha=0.8)
    ax1.set_title('å—é™åˆ¶ç‰ˆæœ¬å·®å¼‚å€æ•°', fontweight='bold')
    ax1.set_ylabel('å·®å¼‚å€æ•° (AI/è®°è€…)')
    ax1.set_xlabel('é‡å­æŒ‡æ ‡')
    ax1.set_xticks(x)
    ax1.set_xticklabels(metric_names_cn, rotation=45, ha='right')
    ax1.axhline(y=1, color='black', linestyle='--', alpha=0.5)
    ax1.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, diff in zip(bars1, differences_restricted):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{diff:.3f}', ha='center', va='bottom', fontweight='bold')
    
    # æ— é™åˆ¶ç‰ˆæœ¬å·®å¼‚
    bars2 = ax2.bar(x, differences_unrestricted, width, label='æ— é™åˆ¶ç‰ˆæœ¬', color='#4ecdc4', alpha=0.8)
    ax2.set_title('æ— é™åˆ¶ç‰ˆæœ¬å·®å¼‚å€æ•°', fontweight='bold')
    ax2.set_ylabel('å·®å¼‚å€æ•° (AI/è®°è€…)')
    ax2.set_xlabel('é‡å­æŒ‡æ ‡')
    ax2.set_xticks(x)
    ax2.set_xticklabels(metric_names_cn, rotation=45, ha='right')
    ax2.axhline(y=1, color='black', linestyle='--', alpha=0.5)
    ax2.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, diff in zip(bars2, differences_unrestricted):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{diff:.3f}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('../visualizations/fair_comparison_difference_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def create_summary_table(data):
    """åˆ›å»ºæ±‡æ€»å¯¹æ¯”è¡¨"""
    
    print("\n" + "="*100)
    print("ğŸ¯ å…¬å¹³å¯¹æ¯”åˆ†æ - è¯¦ç»†æ•°å€¼å¯¹æ¯”è¡¨")
    print("="*100)
    
    # æ–°èæ¨™é¡Œå­—æ®µå¯¹æ¯”
    print("\nğŸ“Š æ–°èæ¨™é¡Œå­—æ®µå¯¹æ¯”:")
    print("-"*80)
    print(f"{'æŒ‡æ ‡':<20} {'AIå—é™åˆ¶':<12} {'AIæ— é™åˆ¶':<12} {'è®°è€…å—é™åˆ¶':<12} {'è®°è€…æ— é™åˆ¶':<12} {'å·®å¼‚å€æ•°':<10}")
    print("-"*80)
    
    metrics = [
        ('è¯­æ³•å åŠ å¼ºåº¦', 'grammatical_superposition'),
        ('å¤šé‡ç°å®å¼ºåº¦', 'multiple_reality_strength'),
        ('è¯­ä¹‰æ¨¡ç³Šåº¦', 'semantic_ambiguity'),
        ('æ¡†æ¶ç«äº‰å¼ºåº¦', 'frame_competition'),
        ('è¯­ä¹‰å¹²æ¶‰', 'semantic_interference'),
        ('å†¯çº½æ›¼ç†µ', 'von_neumann_entropy')
    ]
    
    for cn_name, metric in metrics:
        ai_r = data['ai_restricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        ai_u = data['ai_unrestricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        j_r = data['journalist_restricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        j_u = data['journalist_unrestricted']['æ–°èæ¨™é¡Œ'][metric]['mean']
        diff = ai_u / j_u
        
        print(f"{cn_name:<20} {ai_r:<12.6f} {ai_u:<12.6f} {j_r:<12.6f} {j_u:<12.6f} {diff:<10.3f}Ã—")
    
    print("\nğŸ“ˆ å…³é”®å‘ç°:")
    print("-"*50)
    
    # è¯­æ³•å åŠ å¼ºåº¦åˆ†æ
    ai_sup_u = data['ai_unrestricted']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
    j_sup_u = data['journalist_unrestricted']['æ–°èæ¨™é¡Œ']['grammatical_superposition']['mean']
    sup_diff = ((ai_sup_u - j_sup_u) / j_sup_u) * 100
    
    print(f"â€¢ è¯­æ³•å åŠ å¼ºåº¦: AIæ¯”è®°è€…é«˜ {sup_diff:.2f}%")
    print(f"â€¢ AIè¾¾åˆ°ç†è®ºæœ€å¤§å€¼çš„ {(ai_sup_u/4.0)*100:.1f}%")
    print(f"â€¢ è®°è€…è¾¾åˆ°ç†è®ºæœ€å¤§å€¼çš„ {(j_sup_u/4.0)*100:.1f}%")
    
    # å¤šé‡ç°å®å¼ºåº¦åˆ†æ
    ai_mr_u = data['ai_unrestricted']['æ–°èæ¨™é¡Œ']['multiple_reality_strength']['mean']
    j_mr_u = data['journalist_unrestricted']['æ–°èæ¨™é¡Œ']['multiple_reality_strength']['mean']
    mr_diff = ((ai_mr_u - j_mr_u) / j_mr_u) * 100
    
    print(f"â€¢ å¤šé‡ç°å®å¼ºåº¦: AIæ¯”è®°è€…é«˜ {mr_diff:.2f}%")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ¨ å¼€å§‹ç”Ÿæˆå…¬å¹³å¯¹æ¯”å¯è§†åŒ–...")
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    setup_chinese_font()
    
    # åˆ›å»ºå¯è§†åŒ–ç›®å½•
    Path('../visualizations').mkdir(exist_ok=True)
    
    # åŠ è½½æ•°æ®
    data = load_summary_data()
    
    if not data:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®ï¼Œé€€å‡ºç¨‹åº")
        return
    
    # ç”Ÿæˆå„ç§å¯è§†åŒ–
    print("\nğŸ“Š ç”Ÿæˆè¯­æ³•å åŠ å¼ºåº¦å¯¹æ¯”å›¾...")
    create_grammatical_superposition_comparison(data)
    
    print("\nğŸ”¥ ç”Ÿæˆç»¼åˆæŒ‡æ ‡çƒ­åŠ›å›¾...")
    create_comprehensive_metrics_comparison(data)
    
    print("\nğŸ“¡ ç”Ÿæˆé›·è¾¾å›¾å¯¹æ¯”...")
    create_field_wise_radar_chart(data)
    
    print("\nğŸ“ˆ ç”Ÿæˆå·®å¼‚åˆ†æå›¾...")
    create_difference_analysis(data)
    
    print("\nğŸ“‹ ç”Ÿæˆæ±‡æ€»å¯¹æ¯”è¡¨...")
    create_summary_table(data)
    
    print(f"\nâœ… æ‰€æœ‰å¯è§†åŒ–å·²ç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“ ä¿å­˜ä½ç½®: ../visualizations/")
    print(f"   â€¢ fair_comparison_grammatical_superposition.png")
    print(f"   â€¢ fair_comparison_comprehensive_heatmap.png") 
    print(f"   â€¢ fair_comparison_radar_charts.png")
    print(f"   â€¢ fair_comparison_difference_analysis.png")

if __name__ == "__main__":
    main()

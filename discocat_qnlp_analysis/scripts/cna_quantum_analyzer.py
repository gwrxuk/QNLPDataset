#!/usr/bin/env python3
"""
ä¸­å¤®ç¤¾æ–°èé‡å­æ¡†æ¶åˆ†æå™¨
å°ˆé–€ç”¨æ–¼åˆ†æå°ç£ä¸­å¤®ç¤¾è¨˜è€…æ’°å¯«çš„æ–°èå…§å®¹
"""

import pandas as pd
import numpy as np
import json
import time
import os
from typing import Dict, List, Any, Tuple
import jieba
import jieba.posseg as pseg
from qiskit import QuantumCircuit, Aer, execute
from qiskit.circuit.library import RealAmplitudes
import warnings
warnings.filterwarnings('ignore')

# è¨­ç½®ä¸­æ–‡åˆ†è©
jieba.set_dictionary('../data/dict.txt.big') if os.path.exists('../data/dict.txt.big') else None

class CNAQuantumFrameAnalyzer:
    """ä¸­å¤®ç¤¾æ–°èé‡å­æ¡†æ¶åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        print("ğŸ”§ åˆå§‹åŒ–ä¸­å¤®ç¤¾é‡å­æ¡†æ¶åˆ†æå™¨...")
        
        # åˆå§‹åŒ–é‡å­å¾Œç«¯
        self.backend = Aer.get_backend('statevector_simulator')
        
        # æƒ…æ„Ÿè©å…¸
        self.emotion_lexicon = {
            'positive': ['æˆåŠŸ', 'ç²å¾—', 'å„ªç§€', 'çªç ´', 'å‰µæ–°', 'ç™¼å±•', 'æ”¹å–„', 'æå‡', 'æ¦®ç²', 
                        'å“è¶Š', 'é ˜å…ˆ', 'é€²æ­¥', 'å¢é•·', 'ç²ç', 'è‚¯å®š', 'æ”¯æŒ', 'åˆä½œ', 'å…±è´'],
            'negative': ['å¤±æ•—', 'å•é¡Œ', 'å›°é›£', 'å±æ©Ÿ', 'è¡çª', 'çˆ­è­°', 'æ‰¹è©•', 'è³ªç–‘', 'æ“”æ†‚',
                        'ä¸‹é™', 'æ¸›å°‘', 'æå¤±', 'é¢¨éšª', 'å¨è„…', 'æŒ‘æˆ°', 'é˜»ç¤™', 'å»¶é²', 'å–æ¶ˆ']
        }
        
        # æ”¹é©æ¡†æ¶è©å…¸
        self.reform_lexicon = {
            'positive': ['æ”¹é©', 'å‰µæ–°', 'è®Šé©', 'è½‰å‹', 'å‡ç´š', 'å„ªåŒ–', 'æ”¹é€²', 'æå‡', 'ç™¼å±•'],
            'reactive': ['æ‡‰å°', 'å›æ‡‰', 'è™•ç†', 'è§£æ±º', 'å› æ‡‰', 'èª¿æ•´', 'ä¿®æ­£', 'è£œæ•‘', 'æ”¹å–„'],
            'superficial': ['å®£å¸ƒ', 'è²æ˜', 'è¡¨ç¤º', 'èªªæ˜', 'æ¾„æ¸…', 'å›è¦†', 'æ‰¿è«¾', 'ä¿è­‰', 'å¼·èª¿']
        }
        
        # èªå¢ƒä¿®é£¾è©
        self.context_modifiers = {
            'intensifiers': ['éå¸¸', 'æ¥µå…¶', 'ååˆ†', 'ç›¸ç•¶', 'ç‰¹åˆ¥', 'å°¤å…¶', 'æ ¼å¤–'],
            'diminishers': ['ç¨å¾®', 'ç•¥å¾®', 'æœ‰é»', 'äº›è¨±', 'è¼•å¾®', 'ä¸€å®šç¨‹åº¦']
        }
        
        print("âœ… ä¸­å¤®ç¤¾é‡å­æ¡†æ¶åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def extract_emotion_features(self, text: str) -> Tuple[float, float, int]:
        """æå–æƒ…æ„Ÿç‰¹å¾µ"""
        words = list(jieba.cut(text))
        word_count = len(words)
        
        positive_count = sum(1 for word in words if word in self.emotion_lexicon['positive'])
        negative_count = sum(1 for word in words if word in self.emotion_lexicon['negative'])
        
        # æ­£è¦åŒ–
        positive_intensity = positive_count / max(word_count, 1)
        negative_intensity = negative_count / max(word_count, 1)
        
        return positive_intensity, negative_intensity, word_count

    def analyze_syntactic_patterns(self, text: str, pos_tags: List[str]) -> Tuple[float, float, str]:
        """åˆ†æèªæ³•æ¨¡å¼"""
        # ä¸»å‹•èªæ…‹æª¢æ¸¬
        active_indicators = ['VV', 'VC', 'VE']  # å‹•è©é¡åˆ¥
        active_count = sum(1 for tag in pos_tags if tag in active_indicators)
        active_bonus = min(0.2, active_count / max(len(pos_tags), 1))
        
        # æœªä¾†æ™‚æ…‹æª¢æ¸¬
        future_words = ['å°‡', 'æœƒ', 'è¦', 'å³å°‡', 'é è¨ˆ', 'è¨ˆåŠƒ', 'æº–å‚™']
        future_count = sum(1 for word in jieba.cut(text) if word in future_words)
        future_bonus = min(0.1, future_count / max(len(pos_tags), 1))
        
        # èªå¢ƒé¡å‹
        context_type = 'normal'
        if any(word in text for word in ['æ”¿åºœ', 'å®˜æ–¹', 'éƒ¨é–€']):
            context_type = 'official'
        elif any(word in text for word in ['æ°‘çœ¾', 'å…¬çœ¾', 'ç¤¾æœƒ']):
            context_type = 'public'
            
        return active_bonus, future_bonus, context_type

    def construct_emotion_quantum_state(self, text: str) -> Tuple[np.ndarray, Dict]:
        """æ§‹å»ºæƒ…æ„Ÿé‡å­æ…‹"""
        # è©æ€§æ¨™è¨»
        pos_tags = [pair.flag for pair in pseg.cut(text)]
        
        # æå–åŸºç¤ç‰¹å¾µ
        positive_intensity, negative_intensity, word_count = self.extract_emotion_features(text)
        active_bonus, future_bonus, context_type = self.analyze_syntactic_patterns(text, pos_tags)
        
        # è¨ˆç®—é‡å­æ…‹æŒ¯å¹…
        positive_base = min(1.0, positive_intensity)
        negative_base = min(1.0, negative_intensity)
        
        # èªæ³•ä¿®æ­£
        syntactic_modifier = 1.0 + active_bonus + future_bonus
        positive_amplitude = positive_base * syntactic_modifier
        negative_amplitude = negative_base
        
        # ä¸­æ€§æˆåˆ†
        neutral_amplitude = max(0.1, 1.0 - positive_intensity - negative_intensity)
        
        # æ­£è¦åŒ–
        raw_amplitudes = np.array([positive_amplitude, neutral_amplitude, negative_amplitude])
        norm = np.linalg.norm(raw_amplitudes)
        
        if norm > 0:
            emotion_state = raw_amplitudes / norm
        else:
            emotion_state = np.array([0.33, 0.34, 0.33])  # å‡å‹»åˆ†å¸ƒ
        
        metadata = {
            'positive_intensity': positive_intensity,
            'negative_intensity': negative_intensity,
            'active_voice_bonus': active_bonus,
            'future_tense_bonus': future_bonus,
            'context_type': context_type
        }
        
        return emotion_state, metadata

    def construct_reform_quantum_state(self, text: str, context: str) -> Tuple[np.ndarray, Dict]:
        """æ§‹å»ºæ”¹é©é‡å­æ…‹"""
        words = list(jieba.cut(text))
        
        # è¨ˆç®—å„æ¡†æ¶è©é »
        positive_count = sum(1 for word in words if word in self.reform_lexicon['positive'])
        reactive_count = sum(1 for word in words if word in self.reform_lexicon['reactive'])
        superficial_count = sum(1 for word in words if word in self.reform_lexicon['superficial'])
        
        total_reform_words = positive_count + reactive_count + superficial_count
        
        if total_reform_words > 0:
            # åŸºæ–¼è©é »åˆ†å¸ƒ
            positive_ratio = positive_count / total_reform_words
            reactive_ratio = reactive_count / total_reform_words
            superficial_ratio = superficial_count / total_reform_words
        else:
            # é»˜èªå‡å‹»åˆ†å¸ƒ
            positive_ratio = reactive_ratio = superficial_ratio = 1/3
        
        # èªå¢ƒèª¿æ•´
        context_modifier = 1.0
        if context == 'official':
            positive_ratio *= 1.2  # å®˜æ–¹èªå¢ƒå¢å¼·ç©æ¥µæ”¹é©
        elif context == 'public':
            reactive_ratio *= 1.1  # æ°‘çœ¾èªå¢ƒå¢å¼·åæ‡‰æ€§
        
        # æ§‹å»ºé‡å­æ…‹
        reform_amplitudes = np.array([positive_ratio, reactive_ratio, superficial_ratio])
        reform_amplitudes = reform_amplitudes / np.linalg.norm(reform_amplitudes)
        
        metadata = {
            'reform_word_count': total_reform_words,
            'positive_reform_ratio': positive_ratio,
            'reactive_reform_ratio': reactive_ratio,
            'superficial_reform_ratio': superficial_ratio
        }
        
        return reform_amplitudes, metadata

    def create_quantum_circuit_with_frames(self, emotion_state: np.ndarray, 
                                         reform_state: np.ndarray, 
                                         text_complexity: float) -> QuantumCircuit:
        """å‰µå»ºé‡å­é›»è·¯"""
        circuit = QuantumCircuit(6)
        
        # ä½¿ç”¨æ—‹è½‰é–€ä¾†è¨­ç½®é‡å­æ…‹ï¼Œè€Œä¸æ˜¯ç›´æ¥åˆå§‹åŒ–
        # æƒ…æ„Ÿæ¡†æ¶ (qubits 0-2)
        theta_emotion = np.arccos(np.sqrt(emotion_state[0])) * 2
        phi_emotion = np.arccos(np.sqrt(emotion_state[1] / (emotion_state[1] + emotion_state[2] + 1e-10))) * 2
        
        circuit.ry(theta_emotion, 0)
        circuit.ry(phi_emotion, 1)
        
        # æ”¹é©æ¡†æ¶ (qubits 3-5)
        theta_reform = np.arccos(np.sqrt(reform_state[0])) * 2
        phi_reform = np.arccos(np.sqrt(reform_state[1] / (reform_state[1] + reform_state[2] + 1e-10))) * 2
        
        circuit.ry(theta_reform, 3)
        circuit.ry(phi_reform, 4)
        
        # æ ¹æ“šæ–‡æœ¬è¤‡é›œåº¦æ·»åŠ ç³¾çº
        if text_complexity > 0.5:
            circuit.cx(0, 3)  # æƒ…æ„Ÿ-æ”¹é©ç³¾çº
            circuit.cx(1, 4)
        
        return circuit

    def measure_quantum_frame_properties(self, circuit: QuantumCircuit, 
                                       emotion_state: np.ndarray, 
                                       reform_state: np.ndarray) -> Dict[str, float]:
        """æ¸¬é‡é‡å­æ¡†æ¶å±¬æ€§ - ç°¡åŒ–ç‰ˆæœ¬"""
        try:
            # åŸ·è¡Œé‡å­é›»è·¯
            job = execute(circuit, self.backend, shots=1)
            result = job.result()
            statevector = result.get_statevector()
            
            # è¨ˆç®—æ©Ÿç‡åˆ†å¸ƒ
            probabilities = np.abs(statevector) ** 2
            valid_probs = probabilities[probabilities > 1e-10]
        except Exception as e:
            print(f"âš ï¸ é‡å­é›»è·¯åŸ·è¡Œå¤±æ•—ï¼Œä½¿ç”¨ç¶“å…¸è¿‘ä¼¼: {e}")
            # ä½¿ç”¨ç¶“å…¸è¿‘ä¼¼
            combined_state = np.concatenate([emotion_state, reform_state])
            probabilities = combined_state ** 2
            valid_probs = probabilities[probabilities > 1e-10]
        
        metrics = {}
        
        # 1. æ¡†æ¶ç«¶çˆ­å¼·åº¦ (å†¯çº½æ›¼ç†µ + KL åƒè€ƒ)
        emotion_entropy = -np.sum(emotion_state**2 * np.log2(emotion_state**2 + 1e-12))
        reform_entropy = -np.sum(reform_state**2 * np.log2(reform_state**2 + 1e-12))
        total_entropy = -np.sum(valid_probs * np.log2(valid_probs + 1e-12))
        metrics['frame_competition'] = float(min(1.0, total_entropy * 0.5))
        if len(valid_probs) > 1:
            uniform_prob = 1.0 / len(valid_probs)
            kl_divergence = np.sum(valid_probs * np.log2((valid_probs + 1e-12) / uniform_prob))
            max_kl = np.log2(len(valid_probs))
            metrics['frame_competition_kl'] = float(1.0 - min(1.0, kl_divergence / max_kl))
        else:
            metrics['frame_competition_kl'] = 0.0
        
        # 2. æ¡†æ¶ç³¾çºå¼·åº¦
        metrics['frame_entanglement'] = float(max(0.0, total_entropy - emotion_entropy - reform_entropy))
        
        # 3. é¦®ç´æ›¼ç†µ
        metrics['von_neumann_entropy'] = float(total_entropy)
        
        # 4. èªç¾©å¹²æ¶‰
        phase_variance = np.var(np.angle(statevector[np.abs(statevector) > 1e-10]))
        metrics['semantic_interference'] = float(phase_variance / (np.pi**2))
        
        # 5. æ¡†æ¶å¼·åº¦
        metrics['emotion_frame_strength'] = float(np.max(emotion_state))
        metrics['reform_frame_strength'] = float(np.max(reform_state))
        
        return metrics

    def analyze_multiple_realities_with_frames(self, quantum_metrics: Dict, 
                                             emotion_metadata: Dict, 
                                             reform_metadata: Dict) -> Dict[str, float]:
        """åŸºæ–¼é‡å­æ¡†æ¶åˆ†æå¤šé‡ç¾å¯¦"""
        
        # æ¡†æ¶å¤šæ¨£æ€§
        frame_diversity = 0.0
        if emotion_metadata['positive_intensity'] > 0.1:
            frame_diversity += 0.3
        if emotion_metadata['negative_intensity'] > 0.1:
            frame_diversity += 0.3
        if reform_metadata['reform_word_count'] > 0:
            frame_diversity += 0.4
        
        # å¤šé‡ç¾å¯¦å¼·åº¦
        reality_strength = (
            quantum_metrics['frame_competition'] * 0.4 +
            quantum_metrics['semantic_interference'] * 0.3 +
            frame_diversity * 0.3
        )
        
        # æ¡†æ¶è¡çªå¼·åº¦
        conflict_strength = (
            quantum_metrics['frame_entanglement'] * 0.5 +
            abs(emotion_metadata['positive_intensity'] - emotion_metadata['negative_intensity']) * 0.3 +
            quantum_metrics['frame_competition'] * 0.2
        )
        
        # èªç¾©æ¨¡ç³Šåº¦
        ambiguity = (
            quantum_metrics['von_neumann_entropy'] * 0.5 +
            quantum_metrics['semantic_interference'] * 0.3 +
            (1.0 - max(quantum_metrics['emotion_frame_strength'], quantum_metrics['reform_frame_strength'])) * 0.2
        )
        
        return {
            'multiple_reality_strength': min(1.0, max(0.0, reality_strength)),
            'frame_conflict_strength': min(1.0, max(0.0, conflict_strength)),
            'semantic_ambiguity': min(1.0, max(0.0, ambiguity))
        }

    def process_cna_record(self, record: Dict[str, Any]) -> Dict[str, Any]:
        """è™•ç†å–®æ¢ä¸­å¤®ç¤¾è¨˜éŒ„"""
        try:
            # æå–æ–‡æœ¬
            title = str(record.get('title', ''))
            content = str(record.get('content', ''))
            
            # åˆ†ææ¨™é¡Œ
            title_emotion_state, title_emotion_meta = self.construct_emotion_quantum_state(title)
            title_reform_state, title_reform_meta = self.construct_reform_quantum_state(
                title, title_emotion_meta['context_type'])
            
            # å‰µå»ºé‡å­é›»è·¯
            title_complexity = len(title) / 100.0  # ç°¡å–®çš„è¤‡é›œåº¦æŒ‡æ¨™
            title_circuit = self.create_quantum_circuit_with_frames(
                title_emotion_state, title_reform_state, title_complexity)
            
            # æ¸¬é‡é‡å­å±¬æ€§
            title_quantum_metrics = self.measure_quantum_frame_properties(
                title_circuit, title_emotion_state, title_reform_state)
            
            # åˆ†æå¤šé‡ç¾å¯¦
            title_reality_metrics = self.analyze_multiple_realities_with_frames(
                title_quantum_metrics, title_emotion_meta, title_reform_meta)
            
            # åˆ†æå…§å®¹ (å¦‚æœæœ‰)
            if content and len(content) > 10:
                content_emotion_state, content_emotion_meta = self.construct_emotion_quantum_state(content)
                content_reform_state, content_reform_meta = self.construct_reform_quantum_state(
                    content, content_emotion_meta['context_type'])
                
                content_complexity = len(content) / 1000.0
                content_circuit = self.create_quantum_circuit_with_frames(
                    content_emotion_state, content_reform_state, content_complexity)
                
                content_quantum_metrics = self.measure_quantum_frame_properties(
                    content_circuit, content_emotion_state, content_reform_state)
                
                content_reality_metrics = self.analyze_multiple_realities_with_frames(
                    content_quantum_metrics, content_emotion_meta, content_reform_meta)
            else:
                # ä½¿ç”¨æ¨™é¡Œæ•¸æ“š
                content_emotion_state = title_emotion_state
                content_emotion_meta = title_emotion_meta
                content_reform_state = title_reform_state
                content_reform_meta = title_reform_meta
                content_quantum_metrics = title_quantum_metrics
                content_reality_metrics = title_reality_metrics
            
            # çµ„åˆçµæœ
            results = []
            
            # æ¨™é¡Œçµæœ
            title_result = {
                'record_id': record.get('record_id', 0),
                'field': 'æ–°èæ¨™é¡Œ',
                'original_text': title,
                'word_count': len(list(jieba.cut(title))),
                'emotion_positive_amplitude': float(title_emotion_state[0]),
                'emotion_neutral_amplitude': float(title_emotion_state[1]),
                'emotion_negative_amplitude': float(title_emotion_state[2]),
                'reform_positive_amplitude': float(title_reform_state[0]),
                'reform_reactive_amplitude': float(title_reform_state[1]),
                'reform_superficial_amplitude': float(title_reform_state[2]),
                'positive_emotion_intensity': title_emotion_meta['positive_intensity'],
                'negative_emotion_intensity': title_emotion_meta['negative_intensity'],
                'active_voice_bonus': title_emotion_meta['active_voice_bonus'],
                'future_tense_bonus': title_emotion_meta['future_tense_bonus'],
                'context_type': title_emotion_meta['context_type'],
                'reform_word_count': title_reform_meta['reform_word_count'],
                **title_quantum_metrics,
                **title_reality_metrics,
                'circuit_depth': 2,
                'circuit_gates': 7,
                'qubit_count': 6,
                'quantum_frames_enabled': True,
                'analysis_version': 'cna_quantum_frames_v1.0'
            }
            results.append(title_result)
            
            # å…§å®¹çµæœ
            content_result = {
                'record_id': record.get('record_id', 0),
                'field': 'æ–°èå…§å®¹',
                'original_text': content[:200] + '...' if len(content) > 200 else content,
                'word_count': len(list(jieba.cut(content))),
                'emotion_positive_amplitude': float(content_emotion_state[0]),
                'emotion_neutral_amplitude': float(content_emotion_state[1]),
                'emotion_negative_amplitude': float(content_emotion_state[2]),
                'reform_positive_amplitude': float(content_reform_state[0]),
                'reform_reactive_amplitude': float(content_reform_state[1]),
                'reform_superficial_amplitude': float(content_reform_state[2]),
                'positive_emotion_intensity': content_emotion_meta['positive_intensity'],
                'negative_emotion_intensity': content_emotion_meta['negative_intensity'],
                'active_voice_bonus': content_emotion_meta['active_voice_bonus'],
                'future_tense_bonus': content_emotion_meta['future_tense_bonus'],
                'context_type': content_emotion_meta['context_type'],
                'reform_word_count': content_reform_meta['reform_word_count'],
                **content_quantum_metrics,
                **content_reality_metrics,
                'circuit_depth': 2,
                'circuit_gates': 7,
                'qubit_count': 6,
                'quantum_frames_enabled': True,
                'analysis_version': 'cna_quantum_frames_v1.0'
            }
            results.append(content_result)
            
            return results
            
        except Exception as e:
            print(f"âŒ è™•ç†è¨˜éŒ„æ™‚å‡ºéŒ¯: {e}")
            return []

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    
    print("ğŸš€ å•Ÿå‹•ä¸­å¤®ç¤¾æ–°èé‡å­æ¡†æ¶åˆ†æ")
    print("=" * 60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = CNAQuantumFrameAnalyzer()
    
    # è¼‰å…¥ä¸­å¤®ç¤¾æ•¸æ“š
    data_file = '../data/cna.csv'
    
    if not os.path.exists(data_file):
        print(f"âŒ æ‰¾ä¸åˆ°ä¸­å¤®ç¤¾æ•¸æ“šæ–‡ä»¶: {data_file}")
        return
    
    print(f"ğŸ“‚ è¼‰å…¥ä¸­å¤®ç¤¾æ•¸æ“š: {data_file}")
    df = pd.read_csv(data_file)
    
    print(f"ğŸ“Š ç¸½è¨˜éŒ„æ•¸: {len(df)}")
    
    # æ·»åŠ è¨˜éŒ„ID
    df['record_id'] = range(len(df))
    
    # è™•ç†æ•¸æ“š
    all_results = []
    processed_count = 0
    
    start_time = time.time()
    
    for idx, record in df.iterrows():
        try:
            results = analyzer.process_cna_record(record.to_dict())
            all_results.extend(results)
            processed_count += 1
            
            if processed_count % 50 == 0:
                elapsed = time.time() - start_time
                rate = processed_count / elapsed
                print(f"ğŸ”„ å·²è™•ç† {processed_count}/{len(df)} æ¢è¨˜éŒ„ ({rate:.1f} è¨˜éŒ„/ç§’)")
                
        except Exception as e:
            print(f"âŒ è™•ç†è¨˜éŒ„ {idx} æ™‚å‡ºéŒ¯: {e}")
            continue
    
    # è½‰æ›ç‚ºDataFrame
    if all_results:
        results_df = pd.DataFrame(all_results)
    else:
        # å‰µå»ºç©ºçš„DataFrame
        results_df = pd.DataFrame()
        print("âš ï¸  æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•è¨˜éŒ„")
        return
    
    print(f"\nğŸ“Š è™•ç†å®Œæˆçµ±è¨ˆ:")
    print(f"   - æˆåŠŸè™•ç†: {processed_count}/{len(df)} æ¢åŸå§‹è¨˜éŒ„")
    print(f"   - ç”Ÿæˆçµæœ: {len(results_df)} æ¢åˆ†æè¨˜éŒ„")
    
    # ä¿å­˜çµæœ
    results_file = '../results/cna_quantum_frame_analysis_results.csv'
    results_df.to_csv(results_file, index=False, encoding='utf-8')
    print(f"ğŸ’¾ è©³ç´°çµæœå·²ä¿å­˜: {results_file}")
    
    # è¨ˆç®—çµ±è¨ˆæ‘˜è¦
    numeric_columns = [
        'emotion_positive_amplitude', 'emotion_neutral_amplitude', 'emotion_negative_amplitude',
        'reform_positive_amplitude', 'reform_reactive_amplitude', 'reform_superficial_amplitude',
        'positive_emotion_intensity', 'negative_emotion_intensity',
        'frame_competition', 'emotion_frame_strength', 'reform_frame_strength',
        'frame_entanglement', 'von_neumann_entropy', 'semantic_interference',
        'multiple_reality_strength', 'frame_conflict_strength', 'semantic_ambiguity'
    ]
    
    summary_stats = {}
    
    # æŒ‰å­—æ®µçµ±è¨ˆ
    for field in ['æ–°èæ¨™é¡Œ', 'æ–°èå…§å®¹']:
        field_data = results_df[results_df['field'] == field]
        if not field_data.empty:
            field_stats = {}
            for col in numeric_columns:
                if col in field_data.columns:
                    field_stats[col] = {
                        'mean': float(field_data[col].mean()),
                        'std': float(field_data[col].std()),
                        'min': float(field_data[col].min()),
                        'max': float(field_data[col].max())
                    }
            summary_stats[field] = field_stats
    
    # æ•´é«”çµ±è¨ˆ
    overall_stats = {}
    for col in numeric_columns:
        if col in results_df.columns:
            overall_stats[col] = {
                'mean': float(results_df[col].mean()),
                'std': float(results_df[col].std()),
                'min': float(results_df[col].min()),
                'max': float(results_df[col].max())
            }
    summary_stats['overall'] = overall_stats
    
    # ä¿å­˜çµ±è¨ˆæ‘˜è¦
    summary_file = '../results/cna_quantum_frame_analysis_summary.json'
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary_stats, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š çµ±è¨ˆæ‘˜è¦å·²ä¿å­˜: {summary_file}")
    
    # æ€§èƒ½æ‘˜è¦
    total_time = time.time() - start_time
    print(f"\nâœ… ä¸­å¤®ç¤¾é‡å­æ¡†æ¶åˆ†æå®Œæˆ!")
    print(f"â±ï¸  ç¸½è€—æ™‚: {total_time/60:.1f} åˆ†é˜")
    print(f"ğŸš€ è™•ç†é€Ÿåº¦: {processed_count/total_time:.1f} è¨˜éŒ„/ç§’")
    print(f"ğŸ“ˆ æˆåŠŸè™•ç†: {len(results_df)} æ¢åˆ†æè¨˜éŒ„")
    
    # é¡¯ç¤ºæ¨£æœ¬çµæœ
    print(f"\nğŸ“‹ ä¸­å¤®ç¤¾é‡å­æ¡†æ¶åˆ†æçµæœé è¦½:")
    for field in ['æ–°èæ¨™é¡Œ', 'æ–°èå…§å®¹']:
        field_sample = results_df[results_df['field'] == field].iloc[0] if not results_df[results_df['field'] == field].empty else None
        if field_sample is not None:
            print(f"\n{field}:")
            print(f"  æ–‡æœ¬: {field_sample['original_text'][:100]}...")
            print(f"  æƒ…æ„Ÿæ¡†æ¶: +{field_sample['emotion_positive_amplitude']:.3f} Â±{field_sample['emotion_neutral_amplitude']:.3f} -{field_sample['emotion_negative_amplitude']:.3f}")
            print(f"  æ”¹é©æ¡†æ¶: +{field_sample['reform_positive_amplitude']:.3f} Â±{field_sample['reform_reactive_amplitude']:.3f} -{field_sample['reform_superficial_amplitude']:.3f}")
            print(f"  æ¡†æ¶ç«¶çˆ­: {field_sample['frame_competition']:.4f}")
            print(f"  æ¡†æ¶ç³¾çº: {field_sample['frame_entanglement']:.4f}")
            print(f"  å¤šé‡ç¾å¯¦å¼·åº¦: {field_sample['multiple_reality_strength']:.4f}")

if __name__ == "__main__":
    main()
